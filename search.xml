<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[树]]></title>
    <url>%2F2019%2F05%2F29%2F%E6%A0%91%2F</url>
    <content type="text"><![CDATA[前言对leetcode上树的题解的总结。 树的高度public int maxDepth(TreeNode root) { if (root == null) return 0; return Math.max(maxDepth(root.left), maxDepth(root.right)) + 1; } 平衡树 3 / \ 9 20 / \ 15 7 平衡树左右子树高度差都小于等于 1 private boolean result = true; public boolean isBalanced(TreeNode root) { maxDepth(root); return result; } public int maxDepth(TreeNode root) { if (root == null) return 0; int l = maxDepth(root.left); int r = maxDepth(root.right); if (Math.abs(l - r) &gt; 1) result = false; return 1 + Math.max(l, r); } 两节点的最长路径private int max = 0; public int diameterOfBinaryTree(TreeNode root) { depth(root); return max; } private int depth(TreeNode root) { if (root == null) return 0; int leftDepth = depth(root.left); int rightDepth = depth(root.right); max = Math.max(max, leftDepth + rightDepth); return Math.max(leftDepth, rightDepth) + 1; } 翻转树public TreeNode invertTree(TreeNode root) { if (root == null) return null; TreeNode left = root.left; // 后面的操作会改变 left 指针，因此先保存下来 root.left = invertTree(root.right); root.right = invertTree(left); return root; } 归并两棵树Input: Tree 1 Tree 2 1 2 / \ / \ 3 2 1 3 / \ \ 5 4 7 Output: 3 / \ 4 5 / \ \ 5 4 7 public TreeNode mergeTrees(TreeNode t1, TreeNode t2) { if (t1 == null &amp;&amp; t2 == null) return null; if (t1 == null) return t2; if (t2 == null) return t1; TreeNode root = new TreeNode(t1.val + t2.val); root.left = mergeTrees(t1.left, t2.left); root.right = mergeTrees(t1.right, t2.right); return root; } 判断路径和是否等于一个数Given the below binary tree and sum = 22, 5 / \ 4 8 / / \ 11 13 4 / \ \ 7 2 1 return true, as there exist a root-to-leaf path 5-&gt;4-&gt;11-&gt;2 which sum is 22. 路径和定义为从 root 到 leaf 的所有节点的和。 巧妙运用逆向思维，用sum减去遍历过的node public boolean hasPathSum(TreeNode root, int sum) { if (root == null) return false; if (root.left == null &amp;&amp; root.right == null &amp;&amp; root.val == sum) return true; return hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val); } 统计路径和等于一个数的路径数量root = [10,5,-3,3,2,null,11,3,-2,null,1], sum = 8 10 / \ 5 -3 / \ \ 3 2 11 / \ \ 3 -2 1 Return 3. The paths that sum to 8 are: 1. 5 -&gt; 3 2. 5 -&gt; 2 -&gt; 1 3. -3 -&gt; 11 路径不一定以 root 开头，也不一定以 leaf 结尾，但是必须连续。 其实这题和上一题的区别是在于不一定以root开头，所以开始的时候就分成三份，root，root.left,root.right public int pathSum(TreeNode root, int sum) { if (root == null) return 0; int ret = pathSumStartWithRoot(root, sum) + pathSum(root.left, sum) + pathSum(root.right, sum); return ret; } private int pathSumStartWithRoot(TreeNode root, int sum) { if (root == null) return 0; int ret = 0; if (root.val == sum) ret++; ret += pathSumStartWithRoot(root.left, sum - root.val) + pathSumStartWithRoot(root.right, sum - root.val); return ret; } 是否包含子树Given tree s: 3 / \ 4 5 / \ 1 2 Given tree t: 4 / \ 1 2 Return true, because t has the same structure and node values with a subtree of s. Given tree s: 3 / \ 4 5 / \ 1 2 / 0 Given tree t: 4 / \ 1 2 Return false. 其实就是遍历比较，相同就继续左左右右，不同就返回false，其中一个为null就false，只有同时为null才返回true public boolean isSubtree(TreeNode s, TreeNode t) { if (s == null) return false; return isSubtreeWithRoot(s, t) || isSubtree(s.left, t) || isSubtree(s.right, t); } private boolean isSubtreeWithRoot(TreeNode s, TreeNode t) { if (t == null &amp;&amp; s == null) return true; if (t == null || s == null) return false; if (t.val != s.val) return false; return isSubtreeWithRoot(s.left, t.left) &amp;&amp; isSubtreeWithRoot(s.right, t.right); } 镜像树 1 / \ 2 2 / \ / \ 3 4 4 3 没什么好说的，就是左右对调比较。 public boolean isSymmetric(TreeNode root) { if (root == null) return true; return isSymmetric(root.left, root.right); } private boolean isSymmetric(TreeNode t1, TreeNode t2) { if (t1 == null &amp;&amp; t2 == null) return true; if (t1 == null || t2 == null) return false; if (t1.val != t2.val) return false; return isSymmetric(t1.left, t2.right) &amp;&amp; isSymmetric(t1.right, t2.left); } 最小路径树的根节点到叶子节点的最小路径长度 和最大深度差不多，只是这里是当left或right的深度为0时，返回和+1。 public int minDepth(TreeNode root) { if (root == null) return 0; int left = minDepth(root.left); int right = minDepth(root.right); if (left == 0 || right == 0) return left + right + 1; return Math.min(left, right) + 1; } 返回左叶子节点的和 3 / \ 9 20 / \ 15 7 There are two left leaves in the binary tree, with values 9 and 15 respectively. Return 24. 简单来说，先判断该节点的左节点是否叶子节点，是就返回val和sumof(root.right)。 不是就继续寻找，sumof(root.left)+sumof(root.right). public int sumOfLeftLeaves(TreeNode root) { if (root == null) return 0; if (isLeaf(root.left)) return root.left.val + sumOfLeftLeaves(root.right); return sumOfLeftLeaves(root.left) + sumOfLeftLeaves(root.right); } private boolean isLeaf(TreeNode node){ if (node == null) return false; return node.left == null &amp;&amp; node.right == null; } 间隔遍历 3 / \ 2 3 \ \ 3 1 Maximum amount of money the thief can rob = 3 + 3 + 1 = 7. 其实这题就是比较偷当前的和不偷当前的值。 public int rob(TreeNode root) { if (root == null) return 0; int val1 = root.val; if (root.left != null) val1 += rob(root.left.left) + rob(root.left.right); if (root.right != null) val1 += rob(root.right.left) + rob(root.right.right); int val2 = rob(root.left) + rob(root.right); return Math.max(val1, val2); } 层次遍历使用 BFS 进行层次遍历。不需要使用两个队列来分别存储当前层的节点和下一层的节点，因为在开始遍历一层的节点时，当前队列中的节点数就是当前层的节点数，只要控制遍历这么多节点数，就能保证这次遍历的都是当前层的节点。 一棵树每层节点的平均数public List&lt;Double&gt; averageOfLevels(TreeNode root) { List&lt;Double&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while (!queue.isEmpty()) { int cnt = queue.size(); double sum = 0; for (int i = 0; i &lt; cnt; i++) { TreeNode node = queue.poll(); sum += node.val; if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } ret.add(sum / cnt); } return ret; } 得到左下角的节点Input: 1 / \ 2 3 / / \ 4 5 6 / 7 Output:7 其实这题运用逆向思维，先遍历right，再遍历left。 public int findBottomLeftValue(TreeNode root) { Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while (!queue.isEmpty()) { root = queue.poll(); if (root.right != null) queue.add(root.right); if (root.left != null) queue.add(root.left); } return root.val; } 前中后序遍历 1 / \ 2 3 / \ \ 4 5 6 层次遍历顺序：[1 2 3 4 5 6] 前序遍历顺序：[1 2 4 5 3 6] 中序遍历顺序：[4 2 5 1 3 6] 后序遍历顺序：[4 5 2 6 3 1] 层次遍历使用 BFS 实现，利用的就是 BFS 一层一层遍历的特性；而前序、中序、后序遍历利用了 DFS 实现。 前序、中序、后序遍只是在对节点访问的顺序有一点不同，其它都相同。 ① 前序 void dfs(TreeNode root) { visit(root); dfs(root.left); dfs(root.right); } ② 中序 void dfs(TreeNode root) { dfs(root.left); visit(root); dfs(root.right); } ③ 后序 void dfs(TreeNode root) { dfs(root.left); dfs(root.right); visit(root); } 非递归实现二叉树的前序遍历public List&lt;Integer&gt; preorderTraversal(TreeNode root) { List&lt;Integer&gt; ret = new ArrayList&lt;&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()) { TreeNode node = stack.pop(); if (node == null) continue; ret.add(node.val); stack.push(node.right); // 先右后左，保证左子树先遍历 stack.push(node.left); } return ret; } 非递归实现二叉树的后序遍历前序遍历为 root -&gt; left -&gt; right，后序遍历为 left -&gt; right -&gt; root。可以修改前序遍历成为 root -&gt; right -&gt; left，那么这个顺序就和后序遍历正好相反。 public List&lt;Integer&gt; postorderTraversal(TreeNode root) { List&lt;Integer&gt; ret = new ArrayList&lt;&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()) { TreeNode node = stack.pop(); if (node == null) continue; ret.add(node.val); stack.push(node.left); stack.push(node.right); } Collections.reverse(ret); return ret; } 非递归实现二叉树的中序遍历public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; ret = new ArrayList&lt;&gt;(); if (root == null) return ret; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) { while (cur != null) { stack.push(cur); cur = cur.left; } TreeNode node = stack.pop(); ret.add(node.val); cur = node.right; } return ret; } BST二叉查找树（BST）：根节点大于等于左子树所有节点，小于等于右子树所有节点。 二叉查找树中序遍历有序。 修剪二叉查找树Input: 3 / \ 0 4 \ 2 / 1 L = 1 R = 3 Output: 3 / 2 / 1 题目描述：只保留值在 L ~ R 之间的节点 public TreeNode trimBST(TreeNode root, int L, int R) { if (root == null) return null; if (root.val &gt; R) return trimBST(root.left, L, R); if (root.val &lt; L) return trimBST(root.right, L, R); root.left = trimBST(root.left, L, R); root.right = trimBST(root.right, L, R); return root; } 寻找二叉查找树的第 k 个元素中序遍历解法： private int cnt = 0; private int val; public int kthSmallest(TreeNode root, int k) { inOrder(root, k); return val; } private void inOrder(TreeNode node, int k) { if (node == null) return; inOrder(node.left, k); cnt++; if (cnt == k) { val = node.val; return; } inOrder(node.right, k); }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程和线程]]></title>
    <url>%2F2019%2F05%2F28%2F%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言其实对操作系统已经复习了一遍，但总是对相关术语比较模糊，上次面试的时候，完全把这部分忘了，唉，头铁。再复习一次进程和线程。 进程进程是资源分配的基本单位。 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。 下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。 线程线程是独立调度的基本单位。 一个进程中可以有多个线程，它们共享进程资源。 QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。 区别拥有资源进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 调度线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 系统开销由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信方面线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 进程调度算法不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。 批处理系统批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。 先来先服务短作业优先最短剩余时间优先交互式系统交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应 时间片轮转优先级调度多级反馈队列个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合 进程同步临界区对临界资源进行访问的那段代码称为临界区。 为了互斥访问临界资源，每个进程在进入临界区之前，需要进行检查。 同步与互斥 同步：多个进程按一定顺序执行 互斥：多个进程在同一时刻只有一个进程能进入临界区。 信号量信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。 如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 使用信号量实现生产者-消费者问题 问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。 为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。 注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。 #define N 100 typedef int semaphore; semaphore mutex = 1; semaphore empty = N; semaphore full = 0; void producer() { while(TRUE) { int item = produce_item(); down(&amp;empty); down(&amp;mutex); insert_item(item); up(&amp;mutex); up(&amp;full); } } void consumer() { while(TRUE) { down(&amp;full); down(&amp;mutex); int item = remove_item(); consume_item(item); up(&amp;mutex); up(&amp;empty); } } 管程使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。 管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 进程通信进程同步和进程通信的区别： 进程同步：控制多个进程按一定的顺序执行 进程通信：进程间传输信息 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 管道管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。 #include &lt;unistd.h&gt; int pipe(int fd[2]); Copy to clipboardErrorCopied 它具有以下限制： 只支持半双工通信（单向交替传输）；只能在父子进程中使用。 FIFO也称为命名管道，去除了管道只能在父子进程中使用的限制。 #include &lt;sys/stat.h&gt; int mkfifo(const char *path, mode_t mode); int mkfifoat(int fd, const char *path, mode_t mode); Copy to clipboardErrorCopied FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 消息队列相比于 FIFO，消息队列具有以下优点： 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 信号量它是一个计数器，用于为多个进程提供对共享数据对象的访问。 共享存储允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。 需要使用信号量用来同步对共享存储的访问。 多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>进线程管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法]]></title>
    <url>%2F2019%2F05%2F28%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言对贪心算法题的总结 分配饼干Input: [1,2], [1,2,3]Output: 2 Explanation: You have 2 children and 3 cookies. The greed factors of 2 children are 1, 2. You have 3 cookies and their sizes are big enough to gratify all of the children,You need to output 2. 题目描述：每个孩子都有一个满足度，每个饼干都有一个大小，只有饼干的大小大于等于一个孩子的满足度，该孩子才会获得满足。求解最多可以获得满足的孩子数量。 给一个孩子的饼干应当尽量小又能满足该孩子，这样大饼干就能拿来给满足度比较大的孩子。因为最小的孩子最容易得到满足，所以先满足最小的孩子。 证明：假设在某次选择中，贪心策略选择给当前满足度最小的孩子分配第 m 个饼干，第 m 个饼干为可以满足该孩子的最小饼干。假设存在一种最优策略，给该孩子分配第 n 个饼干，并且 m &lt; n。我们可以发现，经过这一轮分配，贪心策略分配后剩下的饼干一定有一个比最优策略来得大。因此在后续的分配中，贪心策略一定能满足更多的孩子。也就是说不存在比贪心策略更优的策略，即贪心策略就是最优策略。 public int findContentChildren(int[] g, int[] s) { Arrays.sort(g); Arrays.sort(s); int gi = 0, si = 0; while (gi &lt; g.length &amp;&amp; si &lt; s.length) { if (g[gi] &lt;= s[si]) { gi++; } si++; } return gi; } 不重叠的区间个数Input: [ [1,2], [1,2], [1,2] ] Output: 2 Explanation: You need to remove two [1,2] to make the rest of intervals non-overlapping.Input: [ [1,2], [2,3] ] Output: 0 Explanation: You don’t need to remove any of the intervals since they’re already non-overlapping. 题目描述：计算让一组区间不重叠所需要移除的区间个数。 先计算最多能组成的不重叠区间个数，然后用区间总个数减去不重叠区间的个数。 在每次选择中，区间的结尾最为重要，选择的区间结尾越小，留给后面的区间的空间越大，那么后面能够选择的区间个数也就越大。 按区间的结尾进行排序，每次选择结尾最小，并且和前一个区间不重叠的区间。 public int eraseOverlapIntervals(Interval[] intervals) { if(intervals == null || intervals.length == 0) return 0; Arrays.sort(intervals, Comparator.comparingInt(o-&gt;o.end)); int end = intervals[0].end; int cnt = 1; for (int i = 1; i &lt; intervals.length; i++) { if (intervals[i].start&lt;end) { continue; } end = intervals[i].end; cnt++; } return intervals.length - cnt; } class Interval { int start; int end; Interval() { start = 0; end = 0; } Interval(int s, int e) { start = s; end = e; } } 投飞镖刺破气球题目描述：气球在一个水平数轴上摆放，可以重叠，飞镖垂直投向坐标轴，使得路径上的气球都被刺破。求解最小的投飞镖次数使所有气球都被刺破。 也是计算不重叠的区间个数，不过和 Non-overlapping Intervals 的区别在于，[1, 2] 和 [2, 3] 在本题中算是重叠区间。 public int findMinArrowShots(int[][] points) { if (points.length == 0) { return 0; } Arrays.sort(points, Comparator.comparingInt(o -&gt; o[1])); int cnt = 1, end = points[0][1]; for (int i = 1; i &lt; points.length; i++) { if (points[i][0] &lt;= end) { continue; } cnt++; end = points[i][1]; } return cnt; } 根据身高和序号重组队列Input:[[7,0], [4,4], [7,1], [5,0], [6,1], [5,2]] Output:[[5,0], [7,0], [5,2], [6,1], [4,4], [7,1]]题目描述：一个学生用两个分量 (h, k) 描述，h 表示身高，k 表示排在前面的有 k 个学生的身高比他高或者和他一样高。 为了使插入操作不影响后续的操作，身高较高的学生应该先做插入操作，否则身高较小的学生原先正确插入的第 k 个位置可能会变成第 k+1 个位置。 身高 h 降序、个数 k 值升序，然后将某个学生插入队列的第 k 个位置中。 public int[][] reconstructQueue(int[][] people) { if (people == null || people.length == 0 || people[0].length == 0) { return new int[0][0]; } Arrays.sort(people, (a, b) -&gt; (a[0] == b[0] ? a[1] - b[1] : b[0] - a[0])); List&lt;int[]&gt; queue = new ArrayList&lt;&gt;(); for (int[] p : people) { queue.add(p[1], p); } return queue.toArray(new int[queue.size()][]); } 买卖股票最大的收益题目描述：一次股票交易包含买入和卖出，只进行一次交易，求最大收益。 只要记录前面的最小价格，将这个最小价格作为买入价格，然后将当前的价格作为售出价格，查看当前收益是不是最大收益。 public int maxProfit(int[] prices) { int n = prices.length; if (n == 0) return 0; int soFarMin = prices[0]; int max = 0; for (int i = 1; i &lt; n; i++) { if (soFarMin &gt; prices[i]) soFarMin = prices[i]; else max = Math.max(max, prices[i] - soFarMin); } return max; } 买卖股票的最大收益 II题目描述：一次股票交易包含买入和卖出，只进行一次交易，求最大收益。 只要记录前面的最小价格，将这个最小价格作为买入价格，然后将当前的价格作为售出价格，查看当前收益是不是最大收益。 class Solution { public int maxProfit(int[] prices) { if (prices == null || prices.length == 0) { return 0; } int sofarmin = prices[0]; int max = 0; for (int i = 1; i &lt; prices.length; i++) { if (prices[i]&lt;sofarmin) { sofarmin= prices[i]; }else { max = Math.max(max,prices[i]-sofarmin); } } return max; } } 买卖股票的最大收益 II题目描述：可以进行多次交易，多次交易之间不能交叉进行，可以进行多次交易。 对于 [a, b, c, d]，如果有 a &lt;= b &lt;= c &lt;= d ，那么最大收益为 d - a。而 d - a = (d - c) + (c - b) + (b - a) ，因此当访问到一个 prices[i] 且 prices[i] - prices[i-1] &gt; 0，那么就把 prices[i] - prices[i-1] 添加到收益中。 public int maxProfit(int[] prices) { int profit = 0; for (int i = 1; i &lt; prices.length; i++) { if (prices[i] &gt; prices[i - 1]) { profit += (prices[i] - prices[i - 1]); } } return profit; } 种植花朵Input: flowerbed = [1,0,0,0,1], n = 1Output: True 题目描述：flowerbed 数组中 1 表示已经种下了花朵。花朵之间至少需要一个单位的间隔，求解是否能种下 n 朵花。 class Solution { public boolean canPlaceFlowers(int[] flowerbed, int n) { int len = flowerbed.length; int cnt = 0; for (int i = 0; i &lt; len&amp;&amp;cnt&lt;n; i++){ if (flowerbed[i] == 1) { continue; } int pre = i==0?0 :flowerbed[i-1]; int next =i == len-1?0:flowerbed[i+1]; if (pre== 0 &amp;&amp; next ==0) { cnt++; flowerbed[i] = 1; } } return cnt&gt;=n; } } 判断是否为子序列s = “abc”, t = “ahbgdc”Return true. class Solution { public boolean isSubsequence(String s, String t) { int index = -1; for (char c: s.toCharArray()) { index = t.indexOf(c,index+1); if (index == -1) { return false; } } return true; } } 修改一个数成为非递减数组Input: [4,2,3] Output: True Explanation: You could modify the first 4 to 1 to get a non-decreasing array. 题目描述：判断一个数组是否能只修改一个数就成为非递减数组。 在出现 nums[i] &lt; nums[i - 1] 时，需要考虑的是应该修改数组的哪个数，使得本次修改能使 i 之前的数组成为非递减数组，并且 不影响后续的操作 。优先考虑令 nums[i - 1] = nums[i]，因为如果修改 nums[i] = nums[i - 1] 的话，那么 nums[i] 这个数会变大，就有可能比 nums[i + 1] 大，从而影响了后续操作。 还有一个比较特别的情况就是 nums[i] &lt; nums[i - 2]，修改 nums[i - 1] = nums[i] 不能使数组成为非递减数组，只能修改 nums[i] = nums[i - 1]。 public boolean checkPossibility(int[] nums) { int cnt = 0; for (int i = 1; i &lt; nums.length &amp;&amp; cnt &lt; 2; i++) { if (nums[i] &gt;= nums[i - 1]) { continue; } cnt++; if (i - 2 &gt;= 0 &amp;&amp; nums[i - 2] &gt; nums[i]) { nums[i] = nums[i - 1]; } else { nums[i - 1] = nums[i]; } } return cnt &lt;= 1; } 子数组最大的和For example, given the array [-2,1,-3,4,-1,2,1,-5,4],the contiguous subarray [4,-1,2,1] has the largest sum = 6. public int maxSubArray(int[] nums) { if (nums == null || nums.length == 0) { return 0; } int preSum = nums[0]; int maxSum = preSum; for (int i = 1; i &lt; nums.length; i++) { preSum = preSum &gt; 0 ? preSum + nums[i] : nums[i]; maxSum = Math.max(maxSum, preSum); } return maxSum; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>贪心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划-3]]></title>
    <url>%2F2019%2F05%2F27%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-3%2F</url>
    <content type="text"><![CDATA[前言dp算法总结3 找零钱的最少硬币数Example 1: coins = [1, 2, 5], amount = 11 return 3 (11 = 5 + 5 + 1) Example 2: coins = [2], amount = 3 return -1. 题目描述：给一些面额的硬币，要求用这些硬币来组成给定面额的钱数，并且使得硬币数量最少。硬币可以重复使用。 物品：硬币 物品大小：面额 物品价值：数量 因为硬币可以重复使用，因此这是一个完全背包问题。完全背包只需要将 0-1 背包中逆序遍历 dp 数组改为正序遍历即可。 class Solution { public int coinChange(int[] coins, int amount) { if(coins == null || coins.length == 0 || amount&lt;=0) return 0; int[] dp = new int[amount+1]; for (int coin: coins) { for (int i = coin; i&lt;=amount;i++) { if (i==coin) { dp[i] = 1; }else if (dp[i]==0 &amp;&amp;dp[i-coin]!=0) { dp[i] = dp[i-coin]+1; }else if (dp[i-coin]!=0){ dp[i]= Math.min(dp[i],dp[i-coin]+1); } } } return dp[amount]==0?-1:dp[amount]; } } 找零钱的硬币数组合Input: amount = 5, coins = [1, 2, 5] Output: 4 Explanation: there are four ways to make up the amount: 5=5 5=2+2+1 5=2+1+1+1 5=1+1+1+1+1 完全背包问题，使用 dp 记录可达成目标的组合数目。 public int change(int amount, int[] coins) { if (amount == 0 || coins == null || coins.length == 0) { return 0; } int[] dp = new int[amount + 1]; dp[0] = 1; for (int coin : coins) { for (int i = coin; i &lt;= amount; i++) { dp[i] += dp[i - coin]; } } return dp[amount]; } 字符串按单词列表分割s = “leetcode”, dict = [“leet”, “code”]. Return true because “leetcode” can be segmented as “leetcode”. dict 中的单词没有使用次数的限制，因此这是一个完全背包问题。该问题涉及到字典中单词的使用顺序，因此可理解为涉及顺序的完全背包问题。 求解顺序的完全背包问题时，对物品的迭代应该放在最里层。 public boolean wordBreak(String s, List&lt;String&gt; wordDict) { int n = s.length(); boolean[] dp = new boolean[n + 1]; dp[0] = true; for (int i = 1; i &lt;= n; i++) { for (String word : wordDict) { // 对物品的迭代应该放在最里层 int len = word.length(); if (len &lt;= i &amp;&amp; word.equals(s.substring(i - len, i))) { dp[i] = dp[i] || dp[i - len]; } } } return dp[n]; } 组合总和nums = [1, 2, 3] target = 4 The possible combination ways are: (1, 1, 1, 1) (1, 1, 2) (1, 2, 1) (1, 3) (2, 1, 1) (2, 2) (3, 1) Note that different sequences are counted as different combinations. Therefore the output is 7. 和硬币组合总数很像，不够这里要先排序 class Solution { public int combinationSum4(int[] nums, int target) { if (nums == null || nums.length ==0 ) return 0; int dp[] = new int[target+1]; dp[0] = 1; Arrays.sort(nums); for (int i = 1; i &lt;= target; i++) { for (int j = 0; j &lt; nums.length&amp;&amp;nums[j]&lt;=i; j++) { dp[i] += dp[i-nums[j]]; } } return dp[target]; } } 需要冷却期的股票交易题目描述：交易之后需要有一天的冷却时间。 图解： 状态解释： S2:初始状态||股票卖后的cooldown状态 Buy: 购买股票 -price S1: 购买股票后的等待卖股票状态 Sell： 卖掉股票 +price public int maxProfit(int[] prices) { if (prices == null || prices.length == 0) { return 0; } int N = prices.length; int[] buy = new int[N]; int[] s1 = new int[N]; int[] sell = new int[N]; int[] s2 = new int[N]; s1[0] = buy[0] = -prices[0]; sell[0] = s2[0] = 0; for (int i = 1; i &lt; N; i++) { buy[i] = s2[i - 1] - prices[i]; s1[i] = Math.max(buy[i - 1], s1[i - 1]); sell[i] = Math.max(buy[i - 1], s1[i - 1]) + prices[i]; s2[i] = Math.max(s2[i - 1], sell[i - 1]); } return Math.max(sell[N - 1], s2[N - 1]); } 需要交易费用的股票交易Input: prices = [1, 3, 2, 8, 4, 9], fee = 2 Output: 8 Explanation: The maximum profit can be achieved by: Buying at prices[0] = 1 Selling at prices[3] = 8 Buying at prices[4] = 4 Selling at prices[5] = 9 The total profit is ((8 - 1) - 2) + ((9 - 4) - 2) = 8. 题目描述：每交易一次，都要支付一定的费用。 public int maxProfit(int[] prices, int fee) { int N = prices.length; int[] buy = new int[N]; int[] s1 = new int[N]; int[] sell = new int[N]; int[] s2 = new int[N]; s1[0] = buy[0] = -prices[0]; sell[0] = s2[0] = 0; for (int i = 1; i &lt; N; i++) { buy[i] = Math.max(sell[i - 1], s2[i - 1]) - prices[i]; s1[i] = Math.max(buy[i - 1], s1[i - 1]); sell[i] = Math.max(buy[i - 1], s1[i - 1]) - fee + prices[i]; s2[i] = Math.max(s2[i - 1], sell[i - 1]); } return Math.max(sell[N - 1], s2[N - 1]); }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划-2]]></title>
    <url>%2F2019%2F05%2F27%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-2%2F</url>
    <content type="text"><![CDATA[前言动态规划算法总结-2 一组整数对能够构成的最长链Input: [[1,2], [2,3], [3,4]] Output: 2 Explanation: The longest chain is [1,2] -&gt; [3,4] 题目描述：对于 (a, b) 和 (c, d) ，如果 b &lt; c，则它们可以构成一条链。 solution：先根据a[0]排序，然后比较b[0]和a[1]的大小，进行累加。 class Solution { public int findLongestChain(int[][] pairs) { if(pairs== null || pairs.length ==0 ) return 0; int[] dp = new int[pairs.length]; Arrays.fill(dp,1); Arrays.sort(pairs,(a,b)-&gt;(a[0]-b[0])); for (int i = 0; i &lt; pairs.length; i++) { for (int j = 0; j &lt; i; j++) { if (pairs[i][0]&gt;pairs[j][1]) { dp[i] = Math.max(dp[i],dp[j]+1); } } } int res = 0; for (int i: dp) { if (res&lt;i){ res = i; } } return res; } } 最长摆动子序列Input: [1,7,4,9,2,5] Output: 6 The entire sequence is a wiggle sequence. Input: [1,17,5,10,13,15,10,5,16,8] Output: 7 There are several subsequences that achieve this length.One is [1,17,10,13,10,16,8]. Input: [1,2,3,4,5,6,7,8,9] Output: 2 要求：使用 O(N) 时间复杂度求解。 solution: 巧妙运用dp class Solution { public int wiggleMaxLength(int[] nums) { if (nums==null || nums.length ==0 ) { return 0; } int up =1; int down = 1; for (int i = 1; i &lt; nums.length; i++) { if (nums[i]&gt;nums[i-1]) { up = down+1; }else if (nums[i]&lt;nums[i-1]) { down = up+1; } } return Math.max(up,down); } } 最长公共子序列对于两个子序列 S1 和 S2，找出它们最长的公共子序列。 定义一个二维数组 dp 用来存储最长公共子序列的长度，其中 dp[i][j] 表示 S1 的前 i 个字符与 S2 的前 j 个字符最长公共子序列的长度。考虑 S1i 与 S2j 值是否相等，分为两种情况： 当 S1i==S2j 时，那么就能在 S1 的前 i-1 个字符与 S2 的前 j-1 个字符最长公共子序列的基础上再加上 S1i 这个值，最长公共子序列长度加 1，即 dp[i][j] = dp[i-1][j-1] + 1。当 S1i != S2j 时，此时最长公共子序列为 S1 的前 i-1 个字符和 S2 的前 j 个字符最长公共子序列，或者 S1 的前 i 个字符和 S2 的前 j-1 个字符最长公共子序列，取它们的最大者，即 dp[i][j] = max{ dp[i-1][j], dp[i][j-1] }。综上，最长公共子序列的状态转移方程为： dp[i][j] = { dp[i-1][j-1]+1; S1i==S2j; max(dp[i-1][j],dp[i][j-1]); S1i!=S2j; } 与最长递增子序列相比，最长公共子序列有以下不同点： 针对的是两个序列，求它们的最长公共子序列。 在最长递增子序列中，dp[i] 表示以 Si 为结尾的最长递增子序列长度，子序列必须包含 Si ；在最长公共子序列中，dp[i][j] 表示 S1 中前 i 个字符与 S2 中前 j 个字符的最长公共子序列长度，不一定包含 S1i 和 S2j。 在求最终解时，最长公共子序列中 dp[N][M] 就是最终解，而最长递增子序列中 dp[N] 不是最终解，因为以 SN 为结尾的最长递增子序列不一定是整个序列最长递增子序列，需要遍历一遍 dp 数组找到最大者。 public int lengthOfLCS(int[] nums1, int[] nums2) { int n1 = nums1.length, n2 = nums2.length; int[][] dp = new int[n1 + 1][n2 + 1]; for (int i = 1; i &lt;= n1; i++) { for (int j = 1; j &lt;= n2; j++) { if (nums1[i - 1] == nums2[j - 1]) { dp[i][j] = dp[i - 1][j - 1] + 1; } else { dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); } } } return dp[n1][n2]; } 0-1 背包有一个容量为 N 的背包，要用这个背包装下物品的价值最大，这些物品有两个属性：体积 w 和价值 v。 定义一个二维数组 dp 存储最大价值，其中 dp[i][j] 表示前 i 件物品体积不超过 j 的情况下能达到的最大价值。设第 i 件物品体积为 w，价值为 v，根据第 i 件物品是否添加到背包中，可以分两种情况讨论： 第 i 件物品没添加到背包，总体积不超过 j 的前 i 件物品的最大价值就是总体积不超过 j 的前 i-1 件物品的最大价值，dp[i][j] = dp[i-1][j]。 第 i 件物品添加到背包中，dp[i][j] = dp[i-1][j-w] + v。 第 i 件物品可添加也可以不添加，取决于哪种情况下最大价值更大。因此，0-1 背包的状态转移方程为： dp[i][j] = max{dp[i-1][j], dp[i-1][j-w]+v}; public int knapsack(int W, int N, int[] weights, int[] values) { int[][] dp = new int[N + 1][W + 1]; for (int i = 1; i &lt;= N; i++) { int w = weights[i - 1], v = values[i - 1]; for (int j = 1; j &lt;= W; j++) { if (j &gt;= w) { dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - w] + v); } else { dp[i][j] = dp[i - 1][j]; } } } return dp[N][W]; } 空间优化在程序实现时可以对 0-1 背包做优化。观察状态转移方程可以知道，前 i 件物品的状态仅与前 i-1 件物品的状态有关，因此可以将 dp 定义为一维数组，其中 dp[j] 既可以表示 dp[i-1][j] 也可以表示 dp[i][j]。此时， dp[j] = max{dp[j],dp[j-w]+v}; 因为 dp[j-w] 表示 dp[i-1][j-w]，因此不能先求 dp[i][j-w]，以防将 dp[i-1][j-w] 覆盖。也就是说要先计算 dp[i][j] 再计算 dp[i][j-w]，在程序实现时需要按倒序来循环求解。 变种 完全背包：物品数量为无限个 多重背包：物品数量有限制 多维费用背包：物品不仅有重量，还有体积，同时考虑这两种限制 其它：物品之间相互约束或者依赖 划分数组为和相等的两部分Input: [1, 5, 11, 5] Output: true Explanation: The array can be partitioned as [1, 5, 5] and [11].可以看成一个背包大小为 sum/2 的 0-1 背包问题。 /** * 划分数组为和相等的两部分 * solution： 先判断sum的奇偶性 * 从和的一半开始计算，如果可以把dp[mid]变成true，就是可以有数字达到目的 * @param nums * @return */ public boolean canPartition(int[] nums) { int sum = getSum(nums); if (sum%2!=0) return false; int mid = sum/2; boolean dp[] = new boolean[mid+1]; dp[0] = true; for (int x:nums) { for (int i = mid; i &gt;=x; i--) { dp[i] = dp[i] || dp[i-x]; } } return dp[mid]; } public static int getSum(int []nums) { int res = 0; for (int i:nums) res+=i; return res; } 改变一组数的正负号使得它们的和为一给定数Input: nums is [1, 1, 1, 1, 1], S is 3. Output: 5Explanation: -1+1+1+1+1 = 3 +1-1+1+1+1 = 3 +1+1-1+1+1 = 3 +1+1+1-1+1 = 3 +1+1+1+1-1 = 3 There are 5 ways to assign symbols to make the sum of nums be target 3.该问题可以转换为 Subset Sum 问题，从而使用 0-1 背包的方法来求解。 可以将这组数看成两部分，P 和 N，其中 P 使用正号，N 使用负号，有以下推导： sum(P) - sum(N) = target sum(P) + sum(N) + sum(P) - sum(N) = target + sum(P) + sum(N) 2 * sum(P) = target + sum(nums) 因此只要找到一个子集，令它们都取正号，并且和等于 (target + sum(nums))/2，就证明存在解。 public int findTargetSumWays(int[] nums, int S) { int sum = computeArraySum(nums); if (sum &lt; S || (sum + S) % 2 == 1) { return 0; } int W = (sum + S) / 2; int[] dp = new int[W + 1]; dp[0] = 1; for (int num : nums) { for (int i = W; i &gt;= num; i--) { dp[i] = dp[i] + dp[i - num]; } } return dp[W]; } private int computeArraySum(int[] nums) { int sum = 0; for (int num : nums) { sum += num; } return sum; } DFS 解法： public int findTargetSumWays(int[] nums, int S) { return findTargetSumWays(nums, 0, S); } private int findTargetSumWays(int[] nums, int start, int S) { if (start == nums.length) { return S == 0 ? 1 : 0; } return findTargetSumWays(nums, start + 1, S + nums[start]) + findTargetSumWays(nums, start + 1, S - nums[start]); } 01 字符构成最多的字符串Input: Array = {“10”, “0001”, “111001”, “1”, “0”}, m = 5, n = 3Output: 4 Explanation: There are totally 4 strings can be formed by the using of 5 0s and 3 1s, which are “10”,”0001”,”1”,”0” 这是一个多维费用的 0-1 背包问题，有两个背包大小，0 的数量和 1 的数量。 public int findMaxForm(String[] strs, int m, int n) { if (strs == null || strs.length == 0) { return 0; } int[][] dp = new int[m + 1][n + 1]; for (String s : strs) { // 每个字符串只能用一次 int ones = 0, zeros = 0; for (char c : s.toCharArray()) { if (c == &apos;0&apos;) { zeros++; } else { ones++; } } for (int i = m; i &gt;= zeros; i--) { for (int j = n; j &gt;= ones; j--) { dp[i][j] = Math.max(dp[i][j], dp[i - zeros][j - ones] + 1); } } } return dp[m][n]; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划-1]]></title>
    <url>%2F2019%2F05%2F26%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-1%2F</url>
    <content type="text"><![CDATA[爬楼梯 题目描述：有 N 阶楼梯，每次可以上一阶或者两阶，求有多少种上楼梯的方法。 定义一个数组 dp 存储上楼梯的方法数（为了方便讨论，数组下标从 1 开始），dp[i] 表示走到第 i 个楼梯的方法数目。 第 i 个楼梯可以从第 i-1 和 i-2 个楼梯再走一步到达，走到第 i 个楼梯的方法数为走到第 i-1 和第 i-2 个楼梯的方法数之和。 考虑到 dp[i] 只与 dp[i - 1] 和 dp[i - 2] 有关，因此可以只用两个变量来存储 dp[i - 1] 和 dp[i - 2]，使得原来的 O(N) 空间复杂度优化为 O(1) 复杂度。 public int climbStairs(int n) { if (n &lt;= 2) { return n; } int pre2 = 1, pre1 = 2; for (int i = 2; i &lt; n; i++) { int cur = pre1 + pre2; pre2 = pre1; pre1 = cur; } return pre1; } 强盗抢劫题目描述：抢劫一排住户，但是不能抢邻近的住户，求最大抢劫量。 定义 dp 数组用来存储最大的抢劫量，其中 dp[i] 表示抢到第 i 个住户时的最大抢劫量。 由于不能抢劫邻近住户，如果抢劫了第 i -1 个住户，那么就不能再抢劫第 i 个住户，所以 dp[i] = max(dp[i-2]+nums[i],dp[i-1]) 数组方法 class Solution { public int rob(int[] nums) { if (nums == null || nums.length == 0) { return 0; } if (nums.length == 1) return nums[0]; if (nums.length == 2) return Math.max(nums[0],nums[1]); int[] dp = new int[nums.length]; dp[0] = nums[0]; dp[1] = Math.max(dp[0],nums[1]); for (int i = 2; i &lt; nums.length; i++) { dp[i] = Math.max(dp[i-1], dp[i-2]+nums[i]); } return dp[nums.length-1]; } } 非数组方法 public int rob(int[] nums) { int pre2 = 0, pre1 = 0; for (int i = 0; i &lt; nums.length; i++) { int cur = Math.max(pre2 + nums[i], pre1); pre2 = pre1; pre1 = cur; } return pre1; } 强盗在环形街区抢劫这个和刚才的没区别，主要是比较，抢不抢第0个，选最大的。 public int rob(int[] nums) { if (nums == null || nums.length == 0) { return 0; } int n = nums.length; if (n == 1) { return nums[0]; } return Math.max(rob(nums, 0, n - 2), rob(nums, 1, n - 1)); } private int rob(int[] nums, int first, int last) { int pre2 = 0, pre1 = 0; for (int i = first; i &lt;= last; i++) { int cur = Math.max(pre1, pre2 + nums[i]); pre2 = pre1; pre1 = cur; } return pre1; } 矩阵的最小路径和[[1,3,1], [1,5,1], [4,2,1]]Given the above grid map, return 7. Because the path 1→3→1→1→1 minimizes the sum.题目描述：求从矩阵的左上角到右下角的最小路径和，每次只能向右和向下移动。 public int minPathSum(int[][] grid) { if (grid.length == 0 || grid[0].length == 0) { return 0; } int m = grid.length, n = grid[0].length; int[] dp = new int[n]; for (int i = 0; i &lt; m; i++) { for (int j = 0; j &lt; n; j++) { if (j == 0) { dp[j] = dp[j]; // 只能从上侧走到该位置 } else if (i == 0) { dp[j] = dp[j - 1]; // 只能从左侧走到该位置 } else { dp[j] = Math.min(dp[j - 1], dp[j]); } dp[j] += grid[i][j]; } } return dp[n - 1]; } 矩阵的总路径数题目描述：统计从矩阵左上角到右下角的路径总数，每次只能向右或者向下移动。 public int uniquePaths(int m, int n) { int[] dp = new int[n]; Arrays.fill(dp, 1); for (int i = 1; i &lt; m; i++) { for (int j = 1; j &lt; n; j++) { dp[j] = dp[j] + dp[j - 1]; } } return dp[n - 1]; } 也可以直接用数学公式求解，这是一个组合问题。机器人总共移动的次数 S=m+n-2，向下移动的次数 D=m-1，那么问题可以看成从 S 中取出 D 个位置的组合数量，这个问题的解为 C(S, D)。 public int uniquePaths(int m, int n) { int S = m + n - 2; // 总共的移动次数 int D = m - 1; // 向下的移动次数 long ret = 1; for (int i = 1; i &lt;= D; i++) { ret = ret * (S - D + i) / i; } return (int) ret; } 数组区间和 Given nums = [-2, 0, 3, -5, 2, -1] sumRange(0, 2) -&gt; 1 sumRange(2, 5) -&gt; -1 sumRange(0, 5) -&gt; -3 class NumArray { private int[] sums; public NumArray(int[] nums) { sums = new int[nums.length + 1]; for (int i = 1; i &lt;= nums.length; i++) { sums[i] = sums[i - 1] + nums[i - 1]; } } public int sumRange(int i, int j) { return sums[j + 1] - sums[i]; } } 数组中等差递增子区间的个数A = [1, 2, 3, 4] return: 3, for 3 arithmetic slices in A: [1, 2, 3], [2, 3, 4] and [1, 2, 3, 4] itself. public int numberOfArithmeticSlices(int[] A) { if (A == null || A.length == 0) { return 0; } int n = A.length; int[] dp = new int[n]; for (int i = 2; i &lt; n; i++) { if (A[i] - A[i - 1] == A[i - 1] - A[i - 2]) { dp[i] = dp[i - 1] + 1; } } int total = 0; for (int cnt : dp) { total += cnt; } return total; } 最长递增子序列已知一个序列 {S1, S2,…,Sn}，取出若干数组成新的序列 {Si1, Si2,…, Sim}，其中 i1、i2 … im 保持递增，即新序列中各个数仍然保持原数列中的先后顺序，称新序列为原序列的一个 子序列 。 如果在子序列中，当下标 ix &gt; iy 时，Six &gt; Siy，称子序列为原序列的一个 递增子序列 。 定义一个数组 dp 存储最长递增子序列的长度，dp[n] 表示以 Sn 结尾的序列的最长递增子序列长度。对于一个递增子序列 {Si1, Si2,…,Sim}，如果 im &lt; n 并且 Sim &lt; Sn，此时 {Si1, Si2,…, Sim, Sn} 为一个递增子序列，递增子序列的长度增加 1。满足上述条件的递增子序列中，长度最长的那个递增子序列就是要找的，在长度最长的递增子序列上加上 Sn 就构成了以 Sn 为结尾的最长递增子序列。因此 dp[n] = max{ dp[i]+1 | Si &lt; Sn &amp;&amp; i &lt; n} 。 因为在求 dp[n] 时可能无法找到一个满足条件的递增子序列，此时 {Sn} 就构成了递增子序列，需要对前面的求解方程做修改，令 dp[n] 最小为 1，即： dp[n] = max(1,dp[i]+1|Si&lt;Sn&amp;&amp;i&lt;n) public int lengthOfLIS(int[] nums) { int n = nums.length; int[] dp = new int[n]; for (int i = 0; i &lt; n; i++) { int max = 1; for (int j = 0; j &lt; i; j++) { if (nums[i] &gt; nums[j]) { max = Math.max(max, dp[j] + 1); } } dp[i] = max; } int ret = 0; for (int i = 0; i &lt; n; i++) { ret = Math.max(ret, dp[i]); } return ret; } 以上解法的时间复杂度为 O(N2)，可以使用二分查找将时间复杂度降低为 O(NlogN)。 定义一个 tails 数组，其中 tails[i] 存储长度为 i + 1 的最长递增子序列的最后一个元素。对于一个元素 x， 如果它大于 tails 数组所有的值，那么把它添加到 tails 后面，表示最长递增子序列长度加 1；如果 tails[i-1] &lt; x &lt;= tails[i]，那么更新 tails[i] = x。例如对于数组 [4,3,6,5]，有： tails len num [] 0 4 [4] 1 3 [3] 1 6 [3,6] 2 5 [3,5] 2 null 可以看出 tails 数组保持有序，因此在查找 Si 位于 tails 数组的位置时就可以使用二分查找。 public int lengthOfLIS(int[] nums) { int n = nums.length; int[] tails = new int[n]; int len = 0; for (int num : nums) { int index = binarySearch(tails, len, num); tails[index] = num; if (index == len) { len++; } } return len; } private int binarySearch(int[] tails, int len, int key) { int l = 0, h = len; while (l &lt; h) { int mid = l + (h - l) / 2; if (tails[mid] == key) { return mid; } else if (tails[mid] &gt; key) { h = mid; } else { l = mid + 1; } } return l; }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表-2]]></title>
    <url>%2F2019%2F05%2F26%2F%E9%93%BE%E8%A1%A8-2%2F</url>
    <content type="text"><![CDATA[前言对leetcode上的链表题目的总结]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表(1)]]></title>
    <url>%2F2019%2F05%2F25%2F%E9%93%BE%E8%A1%A8-1%2F</url>
    <content type="text"><![CDATA[前言对leetcode上的链表题目的总结 找出两个链表的交点A: a1 → a2 ↘ c1 → c2 → c3 ↗B: b1 → b2 → b3要求：时间复杂度为 O(N)，空间复杂度为 O(1) 设 A 的长度为 a + c，B 的长度为 b + c，其中 c 为尾部公共部分长度，可知 a + c + b = b + c + a。 当访问 A 链表的指针访问到链表尾部时，令它从链表 B 的头部开始访问链表 B；同样地，当访问 B 链表的指针访问到链表尾部时，令它从链表 A 的头部开始访问链表 A。这样就能控制访问 A 和 B 两个链表的指针能同时访问到交点。 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { * val = x; * next = null; * } * } */ public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { ListNode l1 = headA,l2 = headB; while (l1!=l2) { l1=(l1 == null)? headB:l1.next; l2=(l2 == null)? headA:l2.next; } return l1; } } 拓展如果只是判断是否存在交点，那么就是另一个问题，即 编程之美 3.6 的问题。有两种解法： 把第一个链表的结尾连接到第二个链表的开头，看第二个链表是否存在环；或者直接比较两个链表的最后一个节点是否相同。 链表反转递归法先找到当前的head和next，递归反转next，让next指向head，让head指向null，返回newHead; /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode reverseList(ListNode head) { if (head == null || head.next == null) return head; ListNode next = head.next; ListNode newHead = reverseList(next); next.next = head; head.next = null; return newHead; } } 非递归版重点是newHead每次更新直到最后，让cur.next = pre;pre = cur,cur = next; public ListNode ReverseList(ListNode head) { if(head == null || head.next == null) { return head; } ListNode cur = head; ListNode reverseHead = null; ListNode pre = null; ListNode next = null; while (cur != null) { reverseHead = cur; next = cur.next; cur.next = pre; pre = cur; cur = next; } return reverseHead; } 合并有序链表每次让小的先动 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode mergeTwoLists(ListNode l1, ListNode l2) { if (l1 == null ) return l2; if (l2 == null) return l1; if (l1.val&lt;l2.val) { l1.next = mergeTwoLists(l1.next,l2); return l1; }else { l2.next = mergeTwoLists(l1,l2.next); return l2; } } } 从有序链表中删除重复节点Given 1-&gt;1-&gt;2, return 1-&gt;2.Given 1-&gt;1-&gt;2-&gt;3-&gt;3, return 1-&gt;2-&gt;3.判断下一个和当前是否相等 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode deleteDuplicates(ListNode head) { if (head == null || head.next ==null) return head; head.next = deleteDuplicates(head.next); return head.val == head.next.val?head.next:head; } } 删除链表的倒数第 n 个节点 Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2.After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5. 重点：快慢指针快指针完后要作判断 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode fast = head; ListNode slow = head; while (n--&gt;0) { fast = fast.next; } if (fast == null) return head.next; while (fast.next != null) { slow = slow.next; fast = fast.next; } slow.next = slow.next.next; return head; } } 交换链表中的相邻结点Given 1-&gt;2-&gt;3-&gt;4, you should return the list as 2-&gt;1-&gt;4-&gt;3. 重点在于如何判断什么时候交换 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode swapPairs(ListNode head) { ListNode node =new ListNode(-1); node.next = head; ListNode pre = node; while (pre.next!=null &amp;&amp; pre.next.next!=null) { ListNode l1 = pre.next, l2 = pre.next.next; ListNode next = l2.next; l1.next = next; l2.next = l1; pre.next = l2; pre = l1; } return node.next; } }]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS正则]]></title>
    <url>%2F2019%2F05%2F25%2FJS%E6%AD%A3%E5%88%99%2F</url>
    <content type="text"><![CDATA[第一章 正则表达式字符匹配攻略两种模糊匹配正则表达式是匹配模式，要么匹配字符，要么匹配位置。 如果正则只有精确匹配是没多大意义的，比如 /hello/，也只能匹配字符串中的 “hello” 这个子串。var regex = /hello/;console.log( regex.test(“hello”) );// =&gt; true正则表达式之所以强大，是因为其能实现模糊匹配。而模糊匹配，有两个方向上的“模糊”：横向模糊和纵向模糊 横向匹配横向模糊指的是，一个正则可匹配的字符串的长度不是固定的，可以是多种情况的。其实现的方式是使用量词。譬如 {m,n}，表示连续出现最少 m 次，最多 n 次。比如正则 /ab{2,5}c/ 表示匹配这样一个字符串：第一个字符是 “a”，接下来是 2 到 5 个字符 “b”，最后是字符 “c”。 var regex = /ab{2,5}c/g; var string = &quot;abc abbc abbbc abbbbc abbbbbc abbbbbbc&quot;; console.log( string.match(regex) ); // =&gt; [&quot;abbc&quot;, &quot;abbbc&quot;, &quot;abbbbc&quot;, &quot;abbbbbc&quot;] 纵向匹配纵向模糊指的是，一个正则匹配的字符串，具体到某一位字符时，它可以不是某个确定的字符，可以有多种可能。其实现的方式是使用字符组。譬如 [abc]，表示该字符是可以字符 “a”、”b”、”c” 中的任何一个。比如 /a[123]b/ 可以匹配如下三种字符串： “a1b”、”a2b”、”a3b”。其可视化形式如下：测试如下： var regex = /a[123]b/g; var string = &quot;a0b a1b a2b a3b a4b&quot;; console.log( string.match(regex) ); // =&gt; [&quot;a1b&quot;, &quot;a2b&quot;, &quot;a3b&quot;] 字符组需要强调的是，虽叫字符组（字符类），但只是其中一个字符。例如 [abc]，表示匹配一个字符，它可以是 “a”、”b”、”c” 之一。 范围表示法如果字符组里的字符特别多的话，怎么办？可以使用范围表示法。比如 [123456abcdefGHIJKLM]，可以写成 [1-6a-fG-M]。用连字符 - 来省略和简写。因为连字符有特殊用途，那么要匹配 “a”、”-“、”z” 这三者中任意一个字符，该怎么做呢？不能写成 [a-z]，因为其表示小写字符中的任何一个字符。可以写成如下的方式：[-az] 或 [az-] 或 [a-z]。即要么放在开头，要么放在结尾，要么转义。总之不会让引擎认为是范围表示法就行了。 排除字符组纵向模糊匹配，还有一种情形就是，某位字符可以是任何东西，但就不能是 “a”、”b”、”c”。此时就是排除字符组（反义字符组）的概念。例如 [^abc]，表示是一个除 “a”、”b”、”c”之外的任意一个字符。字符组的第一位放 ^（脱字符），表示求反的概念。当然，也有相应的范围表示法。 常见的简写形式有了字符组的概念后，一些常见的符号我们也就理解了。因为它们都是系统自带的简写形式。字符组 具体含义 \d 表示 [0-9]。表示是一位数字。 记忆方式：其英文是 digit（数字）。 \D 表示 [^0-9]。表示除数字外的任意字符。 \w 表示 [0-9a-zA-Z_]。表示数字、大小写字母和下划线。 记忆方式：w 是 word 的简写，也称单词字符。 \W 表示 [^0-9a-zA-Z_]。非单词字符。 \s表示 [ \t\v\n\r\f]。表示空白符，包括空格、水平制表符、垂直制表符、换行符、回车符、换页符。记忆方式：s 是 space 的首字母，空白符的单词是 white space。 \S 表示 [^ \t\v\n\r\f]。 非空白符。 . 表示 [^\n\r\u2028\u2029]。通配符，表示几乎任意字符。换行符、回车符、行分隔符和段分隔符除外。记忆方式：想想省略号 … 中的每个点，都可以理解成占位符，表示任何类似的东西。 量词量词也称重复。掌握 {m,n} 的准确含义后，只需要记住一些简写形式。 简写形式量词 具体含义 {m,} 表示至少出现 m 次。 {m} 等价于 {m,m}，表示出现 m 次。 ?等价于 {0,1}，表示出现或者不出现。记忆方式：问号的意思表示，有吗？ +等价于 {1,}，表示出现至少一次。记忆方式：加号是追加的意思，得先有一个，然后才考虑追加。 *等价于 {0,}，表示出现任意次，有可能不出现。记忆方式：看看天上的星星，可能一颗没有，可能零散有几颗，可能数也数不过来。 贪婪匹配与惰性匹配看如下的例子： var regex = /\d{2,5}/g; var string = &quot;123 1234 12345 123456&quot;; console.log( string.match(regex) ); // =&gt; [&quot;123&quot;, &quot;1234&quot;, &quot;12345&quot;, &quot;12345&quot;] 其中正则 /\d{2,5}/，表示数字连续出现 2 到 5 次。会匹配 2 位、3 位、4 位、5 位连续数字。但是其是贪婪的，它会尽可能多的匹配。你能给我 6 个，我就要 5 个。你能给我 3 个，我就要 3 个。反正只要在能力范围内，越多越好。我们知道有时贪婪不是一件好事（请看文章最后一个例子）。而惰性匹配，就是尽可能少的匹配： var regex = /\d{2,5}?/g; var string = &quot;123 1234 12345 123456&quot;; console.log( string.match(regex) ); // =&gt; [&quot;12&quot;, &quot;12&quot;, &quot;34&quot;, &quot;12&quot;, &quot;34&quot;, &quot;12&quot;, &quot;34&quot;, &quot;56&quot;] 其中 /\d{2,5}?/ 表示，虽然 2 到 5 次都行，当 2 个就够的时候，就不再往下尝试了。 通过在量词后面加个问号就能实现惰性匹配，因此所有惰性匹配情形如下： 惰性量词 贪婪量词 {m,n}? {m,n} {m,}? {m,} ?? ? +? + ? 对惰性匹配的记忆方式是：量词后面加个问号，问一问你知足了吗，你很贪婪吗？ 多选分支一个模式可以实现横向和纵向模糊匹配。而多选分支可以支持多个子模式任选其一。具体形式如下：(p1|p2|p3)，其中 p1、p2 和 p3 是子模式，用 |（管道符）分隔，表示其中任何之一。例如要匹配字符串 “good” 和 “nice” 可以使用 /good|nice/。 var regex = /good|nice/g; var string = &quot;good idea, nice try.&quot;; console.log( string.match(regex) ); // =&gt; [&quot;good&quot;, &quot;nice&quot;] 案例分析匹配时间23:59 02:07 分析：共 4 位数字，第一位数字可以为 [0-2]。 当第 1 位为 “2” 时，第 2 位可以为 [0-3]，其他情况时，第 2 位为 [0-9]。 第 3 位数字为 [0-5]，第4位为 [0-9]。正则如下： var regex = /^([01][0-9]|[2][0-3]):[0-5][0-9]$/; console.log( regex.test(&quot;23:59&quot;) ); console.log( regex.test(&quot;02:07&quot;) ); // =&gt; true // =&gt; true 匹配日期比如 yyyy-mm-dd 格式为例。 要求匹配：2017-06-10 分析：年，四位数字即可，可用 [0-9]{4}。月，共 12 个月，分两种情况 “01”、”02”、…、”09” 和 “10”、”11”、”12”，可用 (0[1-9]|1[0-2])。日，最大 31 天，可用 (0[1-9]|[12][0-9]|3[01])。 var regex = /^[0-9]{4}-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])$/; console.log( regex.test(&quot;2017-06-10&quot;) ); window 操作系统文件路径要求匹配： F:\study\javascript\regex\regular expression.pdf F:\study\javascript\regex\ F:\study\javascript F:\ 分析：整体模式是: 盘符:\文件夹\文件夹\文件夹\ 其中匹配 “F:\”，需要使用 [a-zA-Z]:\，其中盘符不区分大小写，注意 \ 字符需要转义。 文件名或者文件夹名，不能包含一些特殊字符，此时我们需要排除字符组 [^\:*&lt;&gt;|”?\r\n/] 来表示合法字符。 另外它们的名字不能为空名，至少有一个字符，也就是要使用量词 +。因此匹配 文件夹\，可用[^\:*&lt;&gt;|”?\r\n/]+\。 另外 文件夹\，可以出现任意次。也就是 ([^\:&lt;&gt;|”?\r\n/]+\)。其中括号表示其内部正则是一个整体。 路径的最后一部分可以是 文件夹，没有 \，因此需要添加 ([^\:*&lt;&gt;|”?\r\n/]+)? var regex = /^[a-zA-Z]:\\([^\\:*&lt;&gt;|&quot;?\r\n/]+\\)*([^\\:*&lt;&gt;|&quot;?\r\n/]+)?$/; console.log( regex.test(&quot;F:\\study\\javascript\\regex\\regular expression.pdf&quot;) ); console.log( regex.test(&quot;F:\\study\\javascript\\regex\\&quot;) ); console.log( regex.test(&quot;F:\\study\\javascript&quot;) ); console.log( regex.test(&quot;F:\\&quot;) ); // =&gt; true // =&gt; true // =&gt; true // =&gt; true 匹配 id要求从 &lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt; 提取出 id=”container”。 可能最开始想到的正则是： var regex = /id=&quot;.*&quot;/ var string = &apos;&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;&apos;; console.log(string.match(regex)[0]); // =&gt; id=&quot;container&quot; class=&quot;main&quot; 因为 . 是通配符，本身就匹配双引号的，而量词 * 又是贪婪的，当遇到 container 后面双引号时，是不会停下来，会继续匹配，直到遇到最后一个双引号为止。 解决之道，可以使用惰性匹配： var regex = /id=&quot;.*?&quot;/ var string = &apos;&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;&apos;; console.log(string.match(regex)[0]); 第二章 正则表达式位置匹配攻略如何匹配位置^ 和 $^（脱字符）匹配开头，在多行匹配中匹配行开头。 $（美元符号）匹配结尾，在多行匹配中匹配行结尾。 比如我们把字符串的开头和结尾用 “#” 替换（位置可以替换成字符的！）： var result = &quot;hello&quot;.replace(/^|$/g, &apos;#&apos;); console.log(result); // =&gt; &quot;#hello#&quot; 多行匹配模式（即有修饰符 m）时，二者是行的概念，这一点需要我们注意： var result = &quot;I\nlove\njavascript&quot;.replace(/^|$/gm, &apos;#&apos;); console.log(result); /* #I# #love# #javascript# */ \b 和 \B\b 是单词边界，具体就是 \w 与 \W 之间的位置，也包括 \w 与 ^ 之间的位置，和 \w 与 $ 之间的位置。 比如考察文件名 “[JS] Lesson_01.mp4” 中的 \b，如下： var result = &quot;[JS] Lesson_01.mp4&quot;.replace(/\b/g, &apos;#&apos;); console.log(result); // =&gt; &quot;[#JS#] #Lesson_01#.#mp4#&quot; 知道了 \b 的概念后，那么 \B 也就相对好理解了。 \B 就是 \b 的反面的意思，非单词边界。例如在字符串中所有位置中，扣掉 \b，剩下的都是 \B 的。 具体说来就是 \w 与 \w、 \W 与 \W、^ 与 \W，\W 与 $ 之间的位置。比如上面的例子，把所有 \B 替换成 “#”： var result = &quot;[JS] Lesson_01.mp4&quot;.replace(/\B/g, &apos;#&apos;); console.log(result); // =&gt; &quot;#[J#S]# L#e#s#s#o#n#_#0#1.m#p#4&quot; (?=p) 和 (?!p)(?=p)，其中 p 是一个子模式，即 p 前面的位置，或者说，该位置后面的字符要匹配 p。 比如 (?=l)，表示 “l” 字符前面的位置，例如： var result = &quot;hello&quot;.replace(/(?=l)/g, &apos;#&apos;); console.log(result); // =&gt; &quot;he#l#lo&quot; 而 (?!p) 就是 (?=p) 的反面意思，比如： var result = &quot;hello&quot;.replace(/(?!l)/g, &apos;#&apos;); console.log(result); // =&gt; &quot;#h#ell#o#&quot; 位置的特性对于位置的理解，我们可以理解成空字 比如 “hello” 字符串等价于如下的形式： &quot;hello&quot; == &quot;&quot; + &quot;h&quot; + &quot;&quot; + &quot;e&quot; + &quot;&quot; + &quot;l&quot; + &quot;&quot; + &quot;l&quot; + &quot;&quot; + &quot;o&quot; + &quot;&quot;; 也等价于： &quot;hello&quot; == &quot;&quot; + &quot;&quot; + &quot;hello&quot; 第三章 正则表达式括号的作用分组和分支结构这二者是括号最直觉的作用，也是最原始的功能，强调括号内的正则是一个整体，即提供子表达式 分组我们知道 /a+/ 匹配连续出现的 “a”，而要匹配连续出现的 “ab” 时，需要使用 /(ab)+/。 其中括号是提供分组功能，使量词 + 作用于 “ab” 这个整体，测试如下： var regex = /(ab)+/g; var string = &quot;ababa abbb ababab&quot;; console.log( string.match(regex) ); // =&gt; [&quot;abab&quot;, &quot;ab&quot;, &quot;ababab&quot;] 分支结构而在多选分支结构 (p1|p2) 中，此处括号的作用也是不言而喻的，提供了分支表达式的所有可能。 比如，要匹配如下的字符串： I love JavaScript I love Regular Expression var regex = /^I love (JavaScript|Regular Expression)$/; console.log( regex.test(&quot;I love JavaScript&quot;) ); console.log( regex.test(&quot;I love Regular Expression&quot;) ); // =&gt; true // =&gt; true 分组引用这是括号一个重要的作用，有了它，我们就可以进行数据提取，以及更强大的替换操作。 而要使用它带来的好处，必须配合使用实现环境的 API。 以日期为例。假设格式是 yyyy-mm-dd 的，我们可以先写一个简单的正则： var regex = /\d{4}-\d{2}-\d{2}/; 然后再修改成括号版的： var regex = /(\d{4})-(\d{2})-(\d{2})/; 提取数据比如提取出年、月、日，可以这么做： var regex = /(\d{4})-(\d{2})-(\d{2})/; var string = &quot;2017-06-12&quot;; console.log( string.match(regex) ); // =&gt; [&quot;2017-06-12&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;12&quot;, index: 0, input: &quot;2017-06-12&quot;] 替换比如，想把 yyyy-mm-dd 格式，替换成 mm/dd/yyyy var regex = /(\d{4})-(\d{2})-(\d{2})/; var string = &quot;2017-06-12&quot;; var result = string.replace(regex, &quot;$2/$3/$1&quot;); console.log(result); // =&gt; &quot;06/12/2017&quot; 其中 replace 中的，第二个参数里用 $1、$2、$3 指代相应的分组。等价于如下的形式： var regex = /(\d{4})-(\d{2})-(\d{2})/; var string = &quot;2017-06-12&quot;; var result = string.replace(regex, function () { return RegExp.$2 + &quot;/&quot; + RegExp.$3 + &quot;/&quot; + RegExp.$1; }); console.log(result); // =&gt; &quot;06/12/2017&quot; 第四章 正则表达式回溯法原理其实回溯法，很容易掌握的。 简单总结就是，正因为有多种可能，所以要一个一个试。直到，要么到某一步时，整体匹配成功了；要么最后都试完后，发现整体匹配不成功。 贪婪量词“试”的策略是：买衣服砍价。价钱太高了，便宜点，不行，再便宜点。 惰性量词“试”的策略是：卖东西加价。给少了，再多给点行不，还有点少啊，再给点。 分支结构“试”的策略是：货比三家。这家不行，换一家吧，还不行，再换。 既然有回溯的过程，那么匹配效率肯定低一些。相对谁呢？相对那些 DFA 引擎, DFA 是“确定型有限自动机”的简写。 而 JavaScript 的正则引擎是 NFA，NFA 是“非确定型有限自动机”的简写。 大部分语言中的正则都是 NFA，为啥它这么流行呢？ 答：你别看我匹配慢，但是我编译快啊，而且我还有趣哦。]]></content>
      <categories>
        <category>Javascript</category>
      </categories>
      <tags>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全与加密]]></title>
    <url>%2F2019%2F05%2F25%2F%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[预防CSRF攻击什么是CSRFCSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。 那么CSRF到底能够干嘛呢？你可以这样简单的理解：攻击者可以盗用你的登陆信息，以你的身份模拟发送各种请求。攻击者只要借助少许的社会工程学的诡计，例如通过QQ等聊天软件发送的链接(有些还伪装成短域名，用户无法分辨)，攻击者就能迫使Web应用的用户去执行攻击者预设的操作。例如，当用户登录网络银行去查看其存款余额，在他没有退出时，就点击了一个QQ好友发来的链接，那么该用户银行帐户中的资金就有可能被转移到攻击者指定的帐户中。 所以遇到CSRF攻击时，将对终端用户的数据和操作指令构成严重的威胁；当受攻击的终端用户具有管理员帐户的时候，CSRF攻击将危及整个Web应用程序。 CSRF的原理 从上图可以看出，要完成一次CSRF攻击，受害者必须依次完成两个步骤 ： 1.登录受信任网站A，并在本地生成Cookie 。 2.在不退出A的情况下，访问危险网站B。 如何预防CSRFCSRF的防御可以从服务端和客户端两方面着手，防御效果是从服务端着手效果比较好，现在一般的CSRF防御也都在服务端进行。 服务端的预防CSRF攻击的方式方法有多种，但思想上都是差不多的，主要从以下2个方面入手： 1、正确使用GET,POST和Cookie；2、在非GET请求中增加伪随机数； 一般而言，普通的Web应用都是以GET、POST为主，还有一种请求是Cookie方式。我们一般都是按照如下方式设计应用： 1、GET常用在查看，列举，展示等不需要改变资源属性的时候； 2、POST常用在下达订单，改变一个资源的属性或者做其他一些事情； 接下来我就以Go语言来举例说明，如何限制对资源的访问方法： mux.Get(&quot;/user/:uid&quot;, getuser) mux.Post(&quot;/user/:uid&quot;, modifyuser) 这样处理后，因为我们限定了修改只能使用POST，当GET方式请求时就拒绝响应，所以上面图示中GET方式的CSRF攻击就可以防止了，但这样就能全部解决问题了吗？当然不是，因为POST也是可以模拟的。 因此我们需要实施第二步，在非GET方式的请求中增加随机数，这个大概有三种方式来进行： 为每个用户生成一个唯一的cookie token，所有表单都包含同一个伪随机值，这种方案最简单，因为攻击者不能获得第三方的Cookie(理论上)，所以表单中的数据也就构造失败，但是由于用户的Cookie很容易由于网站的XSS漏洞而被盗取，所以这个方案必须要在没有XSS的情况下才安全。 每个请求使用验证码，这个方案是完美的，因为要多次输入验证码，所以用户友好性很差，所以不适合实际运用。 不同的表单包含一个不同的伪随机值，我们在4.4小节介绍“如何防止表单多次递交”时介绍过此方案，复用相关代码，实现如下： 生成随机数token h := md5.New() io.WriteString(h, strconv.FormatInt(crutime, 10)) io.WriteString(h, &quot;ganraomaxxxxxxxxx&quot;) token := fmt.Sprintf(&quot;%x&quot;, h.Sum(nil)) t, _ := template.ParseFiles(&quot;login.gtpl&quot;) t.Execute(w, token) 输出token &lt;input type=&quot;hidden&quot; name=&quot;token&quot; value=&quot;{{.}}&quot;&gt; 验证token r.ParseForm() token := r.Form.Get(&quot;token&quot;) if token != &quot;&quot; { //验证token的合法性 } else { //不存在token报错 } 这样基本就实现了安全的POST，但是也许你会说如果破解了token的算法呢，按照理论上是，但是实际上破解是基本不可能的，因为有人曾计算过，暴力破解该串大概需要2的11次方时间。 过滤数据数据过滤在Web安全中起到一个基石的作用，大多数的安全问题都是由于没有过滤数据和验证数据引起的，例如前面小节的CSRF攻击，以及接下来将要介绍的XSS攻击、SQL注入等都是没有认真地过滤数据引起的，因此我们需要特别重视这部分的内容。 避免XSS攻击随着互联网技术的发展，现在的Web应用都含有大量的动态内容以提高用户体验。所谓动态内容，就是应用程序能够根据用户环境和用户请求，输出相应的内容。动态站点会受到一种名为“跨站脚本攻击”（Cross Site Scripting, 安全专家们通常将其缩写成 XSS）的威胁，而静态站点则完全不受其影响。 什么是XSSXSS攻击：跨站脚本攻击(Cross-Site Scripting)，为了不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS。XSS是一种常见的web安全漏洞，它允许攻击者将恶意代码植入到提供给其它用户使用的页面中。不同于大多数攻击(一般只涉及攻击者和受害者)，XSS涉及到三方，即攻击者、客户端与Web应用。XSS的攻击目标是为了盗取存储在客户端的cookie或者其他网站用于识别客户端身份的敏感信息。一旦获取到合法用户的信息后，攻击者甚至可以假冒合法用户与网站进行交互。 XSS通常可以分为两大类：一类是存储型XSS，主要出现在让用户输入数据，供其他浏览此页的用户进行查看的地方，包括留言、评论、博客日志和各类表单等。应用程序从数据库中查询数据，在页面中显示出来，攻击者在相关页面输入恶意的脚本数据后，用户浏览此类页面时就可能受到攻击。这个流程简单可以描述为:恶意用户的Html输入Web程序-&gt;进入数据库-&gt;Web程序-&gt;用户浏览器。另一类是反射型XSS，主要做法是将脚本代码加入URL地址的请求参数里，请求参数进入程序后在页面直接输出，用户点击类似的恶意链接就可能受到攻击。 XSS目前主要的手段和目的如下： 盗用cookie，获取敏感信息。利用植入Flash，通过crossdomain权限设置进一步获取更高权限；或者利用Java等得到类似的操作。利用iframe、frame、XMLHttpRequest或上述Flash等方式，以（被攻击者）用户的身份执行一些管理动作，或执行一些如:发微博、加好友、发私信等常规操作，前段时间新浪微博就遭遇过一次XSS。利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动。在访问量极大的一些页面上的XSS可以攻击一些小型网站，实现DDoS攻击的效果 如何预防XSS答案很简单，坚决不要相信用户的任何输入，并过滤掉输入中的所有特殊字符。这样就能消灭绝大部分的XSS攻击。 目前防御XSS主要有如下几种方式： 过滤特殊字符 避免XSS的方法之一主要是将用户所提供的内容进行过滤，Go语言提供了HTML的过滤函数： text/template包下面的HTMLEscapeString、JSEscapeString等函数 使用HTTP头指定类型 `w.Header().Set(&quot;Content-Type&quot;,&quot;text/javascript&quot;)` 这样就可以让浏览器解析javascript代码，而不会是html输出。 避免SQL注入SQL注入攻击（SQL Injection），简称注入攻击，是Web开发中最常见的一种安全漏洞。可以用它来从数据库获取敏感信息，或者利用数据库的特性执行添加用户，导出文件等一系列恶意操作，甚至有可能获取数据库乃至系统用户最高权限。 而造成SQL注入的原因是因为程序没有有效过滤用户的输入，使攻击者成功的向服务器提交恶意的SQL查询代码，程序在接收后错误的将攻击者的输入作为查询语句的一部分执行，导致原始的查询逻辑被改变，额外的执行了攻击者精心构造的恶意代码。 如何预防SQL注入也许你会说攻击者要知道数据库结构的信息才能实施SQL注入攻击。确实如此，但没人能保证攻击者一定拿不到这些信息，一旦他们拿到了，数据库就存在泄露的危险。如果你在用开放源代码的软件包来访问数据库，比如论坛程序，攻击者就很容易得到相关的代码。如果这些代码设计不良的话，风险就更大了。目前Discuz、phpwind、phpcms等这些流行的开源程序都有被SQL注入攻击的先例。 这些攻击总是发生在安全性不高的代码上。所以，永远不要信任外界输入的数据，特别是来自于用户的数据，包括选择框、表单隐藏域和 cookie。就如上面的第一个例子那样，就算是正常的查询也有可能造成灾难。 SQL注入攻击的危害这么大，那么该如何来防治呢?下面这些建议或许对防治SQL注入有一定的帮助。 严格限制Web应用的数据库的操作权限，给此用户提供仅仅能够满足其工作的最低权限，从而最大限度的减少注入攻击对数据库的危害。检查输入的数据是否具有所期望的数据格式，严格限制变量的类型，例如使用regexp包进行一些匹配处理，或者使用strconv包对字符串转化成其他基本类型的数据进行判断。对进入数据库的特殊字符（’”\尖括号&amp;*;等）进行转义处理，或编码转换。Go 的text/template包里面的HTMLEscapeString函数可以对字符串进行转义处理。所有的查询语句建议使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到SQL语句中，即不要直接拼接SQL语句。例如使用database/sql里面的查询函数Prepare和Query，或者Exec(query string, args …interface{})。在应用发布之前建议使用专业的SQL注入检测工具进行检测，以及时修补被发现的SQL注入漏洞。网上有很多这方面的开源工具，例如sqlmap、SQLninja等。避免网站打印出SQL错误信息，比如类型错误、字段不匹配等，把代码里的SQL语句暴露出来，以防止攻击者利用这些错误信息进行SQL注入。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hibernate配置]]></title>
    <url>%2F2019%2F05%2F16%2Fhibernate%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[核心配置核心apiConfiguration 构造方法：默认加载 hibernate.propertiesconfigure() 方法：默认加载 hibernate.cfg.xmlconfigure(String) 方法：加载指定配置文件 sessionFactory SessionFactory 相当于java web连接池，用于管理所有session 获得方式：config.buildSessionFactory(); sessionFactory hibernate缓存配置信息 （数据库配置信息、映射文件，预定义HQL语句 等） SessionFactory线程安全，可以是成员变量，多个线程同时访问时，不会出现线程并发访问问题 开启一个 session：factory.openSession(); 获取和当前线程绑定的会话（需要配置）：factory.getCurrentSession(); thread Session Session 相当于 JDBC的 Connection – 会话 通过session操作PO对象 –增删改查 session单线程，线程不安全，不能编写成成员变量。 Api: save 保存 update 更新 delete 删除 get 通过id查询，如果没有 null load 通过id查询，如果没有抛异常 createQuery(“hql”) 获得Query对象 createCriteria(Class) 获得Criteria对象 Transaction开启事务 beginTransaction()获得事务 getTransaction() 提交事务：commit()回滚事务：rollback() 和 spring 整合后，无需手动管理 Query hibernate执行hql语句 hql语句：hibernate提供面向对象查询语句，使用对象和属性进行查询，区分大小写 获得session.createQuery(“hql”); 方法： list() 查询所有 uniqueResult() 获得一个结果。如果没有查询到返回null，如果查询多条抛异常。 setFirstResult(int) 分页，开始索引数startIndex setMaxResults(int) 分页，每页显示个数 pageSize Criteria QBC（query by criteria），hibernate提供纯面向对象查询语言，提供直接使用PO对象进行操作。 获得方式：Criteria criteria = session.createCriteria(User.class); 条件 criteria.add(Restrictions.eq(“username”, “tom”)); Restrictions.gt(propertyName, value) 大于 Restrictions.ge(propertyName, value) 大于等于 Restrictions.lt(propertyName, value) 小于 Restrictions.le(propertyName, value) 小于等于 Restrictions.like(propertyName, value) 模糊查询，注意：模糊查询值需要使用 % _ 工具类123456789101112131415161718192021222324252627282930public class HibernateUtils &#123; private static SessionFactory sessionFactory; static &#123; Configuration configuration = new Configuration().configure(); sessionFactory = configuration.buildSessionFactory(); Runtime.getRuntime().addShutdownHook(new Thread()&#123; @Override public void run() &#123; sessionFactory.close(); &#125; &#125;); &#125; public static Session openSession() &#123; return sessionFactory.openSession(); &#125; public static Session getCurrentSession() &#123; return sessionFactory.getCurrentSession(); &#125; public static void main(String[] args) &#123; Session session = openSession(); System.out.println(session); session.close(); &#125;&#125; 基本配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 &lt;!-- SessionFactory，相当于之前学习连接池配置 --&gt;&lt;session-factory&gt; &lt;!-- 1 基本4项 --&gt; &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:mysql:///h_day01_db&lt;/property&gt; &lt;property name=&quot;hibernate.connection.username&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;hibernate.connection.password&quot;&gt;1234&lt;/property&gt; &lt;!-- 2 与本地线程绑定 --&gt; &lt;property name=&quot;hibernate.current_session_context_class&quot;&gt;thread&lt;/property&gt; &lt;!-- 3 方言：为不同的数据库，不同的版本，生成sql语句（DQL查询语句）提供依据 * mysql 字符串 varchar * orcale 字符串 varchar2 --&gt; &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQL5Dialect&lt;/property&gt; &lt;!-- 4 sql语句 --&gt; &lt;!-- 显示sql语句 --&gt; &lt;property name=&quot;hibernate.show_sql&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;hibernate.format_sql&quot;&gt;true&lt;/property&gt; &lt;!-- 5 自动创建表（了解） ，学习中使用，开发不使用的。 * 开发中DBA 先创建表，之后根据表生产 PO类 * 取值： update：【】 如果表不存在，将创建表。 如果表已经存在，通过hbm映射文件更新表（添加）。（映射文件必须是数据库对应） 表中的列可以多，不负责删除。 create ：如果表存在，先删除，再创建。程序结束时，之前创建的表不删除。【】 create-drop：与create几乎一样。如果factory.close()执行，将在JVM关闭同时，将创建的表删除了。(测试) validate：校验 hbm映射文件 和 表的列是否对应，如果对应正常执行，如果不对应抛出异常。(测试) --&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot;&gt;create&lt;/property&gt; &lt;!-- 6 java web 6.0 存放一个问题 * BeanFactory 空指针异常 异常提示：org.hibernate.HibernateException: Unable to get the default Bean Validation factory * 解决方案：取消bean校验 --&gt; &lt;property name=&quot;javax.persistence.validation.mode&quot;&gt;none&lt;/property&gt; &lt;!-- 添加映射文件 &lt;mapping &gt;添加映射文件 resource 设置 xml配置文件 （addResource(xml)） class 配置类 (addClass(User.class)) 配置的是全限定类名 --&gt; &lt;mapping resource=&quot;com/ittianyu/a_hello/User.hbm.xml&quot;/&gt;&lt;/session-factory&gt; 主键种类 自然主键: 在业务中,某个属性符合主键的三个要求.那么该属性可以作为主键列. 代理主键: 在业务中,不存符合以上3个条件的属性,那么就增加一个没有意义的列.作为主键. 一级缓存对象状态三种状态瞬时态：transient，session没有缓存对象，数据库也没有对应记录。OID特点：没有值持久态：persistent，session缓存对象，数据库最终会有记录。（事务没有提交）OID特点：有值脱管态：detached，session没有缓存对象，数据库有记录。OID特点：有值 转换状态： 一级缓存一级缓存：又称为session级别的缓存。当获得一次会话（session），hibernate在session中创建多个集合（map），用于存放操作数据（PO对象），为程序优化服务，如果之后需要相应的数据，hibernate优先从session缓存中获取，如果有就使用；如果没有再查询数据库。当session关闭时，一级缓存销毁。 可以调用方法清除一级缓存 //清除 //session.clear(); session.evict(user); 快照与一级缓存一样的存放位置，对一级缓存数据备份。保证数据库的数据与 一级缓存的数据必须一致。如果一级缓存修改了，在执行commit提交时，将自动刷新一级缓存，执行update语句，将一级缓存的数据更新到数据库。当缓存和数据库数据不一样且在提交之前，可以调用 refresh 强制刷新缓存。 关系映射一对一关系一般是可以整合成一张表，也可以分成两张表。维护两张表的关系可以选择外键也可以选择让主键同步。 实体类Address.java public class Address { private Integer id; private String name; private Company company; // 省略 get set } Company.java public class Company { private Integer id; private String name; private Address address; // 省略 get set } 外键维护关系Address.hbm.xml &lt;!-- dynamic-insert 和 dynamic-update 为 true 时，sql语句中只有值变化或者不为空的属性才会加上，用于更新部分属性 --&gt; &lt;class name=&quot;Address&quot; table=&quot;t_address_sync&quot; dynamic-insert=&quot;true&quot; dynamic-update=&quot;true&quot;&gt; &lt;id name=&quot;id&quot; column=&quot;id&quot;&gt; &lt;!-- 主键与外键表的主键同步 --&gt; &lt;generator class=&quot;foreign&quot;&gt; &lt;param name=&quot;property&quot;&gt;company&lt;/param&gt; &lt;/generator&gt; &lt;/id&gt; &lt;property name=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;!-- 需要在同步主键的一方加上 constrained=&quot;true&quot; 使用给主键加上外键约束 --&gt; &lt;one-to-one name=&quot;company&quot; class=&quot;Company&quot; constrained=&quot;true&quot; /&gt; &lt;/class&gt; Company.hbm.xml &lt;!-- dynamic-insert 和 dynamic-update 为 true 时，sql语句中只有值变化或者不为空的属性才会加上，用于更新部分属性 &lt;class name=&quot;Company&quot; table=&quot;t_company_ref&quot; dynamic-insert=&quot;true&quot; dynamic-update=&quot;true&quot;&gt; &lt;id name=&quot;id&quot; column=&quot;id&quot;&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; &lt;property name=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;!-- one-to-one 中使用了 property-ref ：当前类哪个属性是引用外键 放弃维护外键 --&gt; &lt;one-to-one name=&quot;address&quot; class=&quot;Address&quot; property-ref=&quot;company&quot; /&gt; &lt;/class&gt; 一对多实体类 Customer.java public class Customer { private Integer id; private String name; private Set&lt;Order&gt; orders = new HashSet&lt;&gt;(); // 省略 get set } Order.java public class Order { private Integer id; private String name; private Customer customer; // 省略 get set } 映射文件Customer.hbm.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&gt; &lt;hibernate-mapping package=&quot;com.ittianyu.hibernate.onetomany&quot;&gt; &lt;!-- dynamic-insert 和 dynamic-update 为 true 时，sql语句中只有值变化或者不为空的属性才会加上，用于更新部分属性 --&gt; &lt;class name=&quot;Customer&quot; table=&quot;t_customer&quot; dynamic-insert=&quot;true&quot; dynamic-update=&quot;true&quot;&gt; &lt;id name=&quot;id&quot; column=&quot;id&quot;&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; &lt;property name=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;!-- inverse 为 true 表示放弃维护关系，留给对方来维护， 一般是一对多中 一的一方放弃，由多的一放维护， 这个时候删除对象时，需要手动将关联的对象外键引用移除 --&gt; &lt;set name=&quot;orders&quot; inverse=&quot;true&quot;&gt; &lt;key column=&quot;cid&quot;&gt;&lt;/key&gt; &lt;one-to-many class=&quot;Order&quot; /&gt; &lt;/set&gt; &lt;/class&gt; &lt;/hibernate-mapping&gt; Order.hbm.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&gt; &lt;hibernate-mapping package=&quot;com.ittianyu.hibernate.onetomany&quot;&gt; &lt;!-- dynamic-insert 和 dynamic-update 为 true 时，sql语句中只有值变化或者不为空的属性才会加上，用于更新部分属性 --&gt; &lt;class name=&quot;Order&quot; table=&quot;t_order&quot; dynamic-insert=&quot;true&quot; dynamic-update=&quot;true&quot;&gt; &lt;id name=&quot;id&quot; column=&quot;id&quot;&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; &lt;property name=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;many-to-one name=&quot;customer&quot; column=&quot;cid&quot; class=&quot;Customer&quot; /&gt; &lt;/class&gt; 多对多实体类Course.java public class Course { private Integer id; private String name; private Set&lt;Student&gt; students = new HashSet&lt;&gt;(); // 省略 get set } Student.java public class Student { private Integer id; private String name; private Set&lt;Course&gt; courses = new HashSet&lt;&gt;(); // 省略 get set } 映射文件Course.hbm.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&gt; &lt;hibernate-mapping package=&quot;com.ittianyu.hibernate.manytomany&quot;&gt; &lt;!-- dynamic-insert 和 dynamic-update 为 true 时，sql语句中只有值变化或者不为空的属性才会加上，用于更新部分属性 --&gt; &lt;class name=&quot;Course&quot; table=&quot;t_course&quot; dynamic-insert=&quot;true&quot; dynamic-update=&quot;true&quot;&gt; &lt;id name=&quot;id&quot; column=&quot;id&quot;&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; &lt;property name=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;!-- many to many 中，需要给 set 加上 table 名 放弃维护外键 --&gt; &lt;set name=&quot;students&quot; table=&quot;t_student_course&quot; inverse=&quot;true&quot;&gt; &lt;key column=&quot;cid&quot;&gt;&lt;/key&gt; &lt;many-to-many class=&quot;Student&quot; column=&quot;sid&quot; /&gt; &lt;/set&gt; &lt;/class&gt; &lt;/hibernate-mapping&gt; Student.hbm.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&gt; &lt;hibernate-mapping package=&quot;com.ittianyu.hibernate.manytomany&quot;&gt; &lt;!-- dynamic-insert 和 dynamic-update 为 true 时，sql语句中只有值变化或者不为空的属性才会加上，用于更新部分属性 --&gt; &lt;class name=&quot;Student&quot; table=&quot;t_studennt&quot; dynamic-insert=&quot;true&quot; dynamic-update=&quot;true&quot;&gt; &lt;id name=&quot;id&quot; column=&quot;id&quot;&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; &lt;property name=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;!-- many to many 中，需要给 set 加上 table 名 外键表由 student 维护，并启用级联，所以 course 中要放弃维护 --&gt; &lt;set name=&quot;courses&quot; table=&quot;t_student_course&quot; cascade=&quot;save-update&quot;&gt; &lt;key column=&quot;sid&quot;&gt;&lt;/key&gt; &lt;many-to-many class=&quot;Course&quot; column=&quot;cid&quot; /&gt; &lt;/set&gt; &lt;/class&gt; &lt;/hibernate-mapping&gt; 级联 cascade 表示指定级联操作的类型。 save-update : 增加或更新 A 时，自动增加或更新 B。 delete : 删除 A 时，自动删除 B all : 上面两项效果叠加 delete-orphan (孤儿删除) : 删除所有和当前对象解除关联关系的对象 all-delete-orphan : all + delete-orphan 效果叠加 抓取策略检索方式立即检索：立即查询，在执行查询语句时，立即查询所有的数据。延迟检索：延迟查询，在执行查询语句之后，在需要时在查询。（懒加载） 检索策略类级别检索：当前的类的属性获取是否需要延迟。关联级别的检索：当前类关联另一个类是否需要延迟。 类级别检索get：立即检索。get方法一执行，立即查询所有字段的数据。load：延迟检索。默认情况，load方法执行后，如果只使用OID的值不进行查询，如果要使用其他属性值将查询。可以配置是否延迟检索； 关联级别检索容器 提供两个属性：fetch、lazy，用于控制关联检索。 fetch：确定使用sql格式 join：底层使用迫切左外连接select：使用多个select语句（默认值）subselect：使用子查询 lazy：关联对象是否延迟。 false：立即true：延迟（默认值）extra：极其懒惰，调用 size 时，sql 查询 count。（用于只需要获取个数的时候） 批量查询一次加载多行数据，用于减少 sql 语句数量 比如： 当客户关联查询订单时，默认给每一个客户生产一个select语句查询订单。开启批量查询后，使用in语句减少查询订单语句个数。 根本区别说明如果你使用load方法，hibernate认为该id对应的对象（数据库记录）在数据库中是一定存在的，所以它可以放心的使用，它可以放心的使用代理来 延迟加载该对象。在用到对象中的其他属性数据时才查询数据库，但是万一数据库中不存在该记录，那没办法，只能抛异常。所说的load方法抛异常是指在使用 该对象的数据时，数据库中不存在该数据时抛异常，而不是在创建这个对象时(注意：这就是由于“延迟加载”在作怪)。 由于session中的缓存对于hibernate来说是个相当廉价的资源，所以在load时会先查一下session缓存看看该id对应的对象是否存在，不存在则创建代理。所以如果你知道该id在数据库中一定有对应记录存在就可以使用load方法来实现延迟加载。 对于get方法，hibernate会确认一下该id对应的数据是否存在，首先在session缓存中查找，然后在二级缓存中查找，还没有就查数据库，数据库中没有就返回null。 对于load和get方法返回类型：虽然好多书中都这么说：“get()永远只返回实体类”，但实际上这是不正确的，get方法如果在 session缓存中找到了该id对应的对象，如果刚好该对象前面是被代理过的，如被load方法使用过，或者被其他关联对象延迟加载过，那么返回的还是 原先的代理对象，而不是实体类对象，如果该代理对象还没有加载实体数据（就是id以外的其他属性数据），那么它会查询二级缓存或者数据库来加载数据，但是 返回的还是代理对象，只不过已经加载了实体数据。 get方法首先查询session缓存，没有的话查询二级缓存，最后查询数据库；反而load方法创建时首先查询session缓存，没有就创建代理，实际使用数据时才查询二级缓存和数据库。 HQL查询所有 //1 使用简单类名 ， 存在自动导包 // * Customer.hbm.xml &lt;hibernate-mapping auto-import=&quot;true&quot;&gt; // Query query = session.createQuery(&quot;from Customer&quot;); //2 使用全限定类名 Query query = session.createQuery(&quot;from com.ittianyu.bean.Customer&quot;); // 获取结果 List&lt;Customer&gt; allCustomer = query.list(); 条件查询 //1 指定数据，cid OID名称 // Query query = session.createQuery(&quot;from Customer where cid = 1&quot;); //2 如果使用id，也可以（了解） // Query query = session.createQuery(&quot;from Customer where id = 1&quot;); //3 对象别名 ,格式： 类 [as] 别名 // Query query = session.createQuery(&quot;from Customer as c where c.cid = 1&quot;); //4 查询所有项，mysql--&gt; select * from... Query query = session.createQuery(&quot;select c from Customer as c where c.cid = 1&quot;); Customer customer = (Customer) query.uniqueResult(); 投影查询 //1 默认 //如果单列 ，select c.cname from，需要List&lt;Object&gt; //如果多列，select c.cid,c.cname from ，需要List&lt;Object[]&gt; ,list存放每行，Object[]多列 // Query query = session.createQuery(&quot;select c.cid,c.cname from Customer c&quot;); //2 将查询部分数据，设置Customer对象中 // * 格式：new Customer(c.cid,c.cname) // * 注意：Customer必须提供相应的构造方法。 // * 如果投影使用oid，结果脱管态对象。 Query query = session.createQuery(&quot;select new Customer(c.cid,c.cname) from Customer c&quot;); List&lt;Customer&gt; allCustomer = query.list(); 排序 Query query = session.createQuery(&quot;from Customer order by cid desc&quot;); List&lt;Customer&gt; allCustomer = query.list(); 分页 Query query = session.createQuery(&quot;from Customer&quot;); // * 开始索引 , startIndex 算法： startIndex = (pageNum - 1) * pageSize; // *** pageNum 当前页（之前的 pageCode） query.setFirstResult(0); // * 每页显示个数 ， pageSize query.setMaxResults(2); List&lt;Customer&gt; allCustomer = query.list(); 绑定参数 Integer cid = 1; //方式1 索引 从 0 开始 // Query query = session.createQuery(&quot;from Customer where cid = ?&quot;); // query.setInteger(0, cid); //方式2 别名引用 (:别名) Query query = session.createQuery(&quot;from Customer where cid = :xxx&quot;); // query.setInteger(&quot;xxx&quot;, cid); query.setParameter(&quot;xxx&quot;, cid); Customer customer = (Customer) query.uniqueResult(); 聚合函数和分组 //1 // Query query = session.createQuery(&quot;select count(*) from Customer&quot;); //2 别名 // Query query = session.createQuery(&quot;select count(c) from Customer c&quot;); //3 oid Query query = session.createQuery(&quot;select count(cid) from Customer&quot;); Long numLong = (Long) query.uniqueResult(); 连接查询 /左外连接 // List list = session.createQuery(&quot;from Customer c left outer join c.orderSet &quot;).list(); //迫切左外链接 (默认数据重复) // List list = session.createQuery(&quot;from Customer c left outer join fetch c.orderSet &quot;).list(); //迫切左外链接 (去重复) List list = session.createQuery(&quot;select distinct c from Customer c left outer join fetch c.orderSet &quot;).list(); 命名查询 Custom.hbm.xml ... &lt;!--局部 命名查询--&gt; &lt;query name=&quot;findAll&quot;&gt;&lt;![CDATA[from Customer ]]&gt;&lt;/query&gt; &lt;/class&gt; &lt;!--全局 命名查询--&gt; &lt;query name=&quot;findAll&quot;&gt;&lt;![CDATA[from Customer ]]&gt;&lt;/query&gt; 测试 //全局 //List list = session.getNamedQuery(&quot;findAll&quot;).list(); //局部 List list = session.getNamedQuery(&quot;com.ittianyu.a_init.Customer.findAll&quot;).list(); QBC查询所有 List&lt;Customer&gt; list = session.createCriteria(Customer.class).list(); 分页查询 Criteria criteria = session.createCriteria(Order.class); criteria.setFirstResult(10); criteria.setMaxResults(10); List&lt;Order&gt; list = criteria.list(); 排序 Criteria criteria = session.createCriteria(Customer.class); // criteria.addOrder(org.hibernate.criterion.Order.asc(&quot;age&quot;)); criteria.addOrder(org.hibernate.criterion.Order.desc(&quot;age&quot;)); List&lt;Customer&gt; list = criteria.list(); 条件查询 // 按名称查询: /*Criteria criteria = session.createCriteria(Customer.class); criteria.add(Restrictions.eq(&quot;cname&quot;, &quot;tom&quot;)); List&lt;Customer&gt; list = criteria.list();*/ // 模糊查询; /*Criteria criteria = session.createCriteria(Customer.class); criteria.add(Restrictions.like(&quot;cname&quot;, &quot;t%&quot;)); List&lt;Customer&gt; list = criteria.list();*/ // 条件并列查询 Criteria criteria = session.createCriteria(Customer.class); criteria.add(Restrictions.like(&quot;cname&quot;, &quot;t%&quot;)); criteria.add(Restrictions.ge(&quot;age&quot;, 35)); List&lt;Customer&gt; list = criteria.list(); 离线查询 // service 层 封装与 session 无关的 criteria DetachedCriteria detachedCriteria = DetachedCriteria.forClass(Customer.class); detachedCriteria.add(Restrictions.eq(&quot;id&quot;, 4)); // dao 层 Session session = HibernateUtils.openSession(); Criteria criteria = detachedCriteria.getExecutableCriteria(session); List list = criteria.list(); 事务隔离级别read uncommittd，读未提交。存在3个问题。read committed，读已提交。解决：脏读。存在2个问题。repeatable read ，可重复读。解决：脏读、不可重复读。存在1个问题。serializable，串行化。单事务。没有问题。 hibernate 中配置 &lt;property name=&quot;hibernate.connection.isolation&quot;&gt;4&lt;/property&gt; 对照上面的分别是 1 2 4 8，0表示没有事务级别 锁悲观锁采用数据库锁机制。丢失更新肯定会发生。 读锁：共享锁。select …. from … lock in share mode; 写锁：排他锁。（独占）select … from …. for update Hibernate 中使用Customer customer = (Customer) session.get(Customer.class, 1 ,LockMode.UPGRADE); 乐观锁在表中提供一个字段（版本字段），用于标识记录。如果版本不一致，不允许操作。丢失更新肯定不会发生Hibernate 中使用 在PO对象（javabean）提供字段，表示版本字段。 ... private Integer version; ... 在配置文件中增加 version &lt;class ...&gt; ... &lt;version name=&quot;version&quot; /&gt; ... 二级缓存sessionFactory 级别缓存，整个应用程序共享一个会话工厂，共享一个二级缓存。 由4部分构成： 类级别缓存 集合级别缓存 时间戳缓存 查询缓存(二级缓存的第2大部分,三级缓存) 并发访问策略 transactional| 可以防止脏读和不可重复读，性能低read-write| 可以防止脏读，更新缓存时锁定缓存数据nonstrict-read-write| 不保证缓存和数据库一致，为缓存设置短暂的过期时间，减少脏读read-only| 适用于不会被修改的数据，并发性能高 应用场景适合放入二级缓存中的数据:很少被修改不是很重要的数据, 允许出现偶尔的并发问题不适合放入二级缓存中的数据:经常被修改财务数据, 绝对不允许出现并发问题与其他应用数据共享的数据 二级缓存提供商 EHCache: 可作为进程（单机）范围内的缓存, 存放数据的物理介质可以是内存或硬盘, 对 Hibernate 的查询缓存提供了支持。–支持集群。OpenSymphony `:可作为进程范围内的缓存, 存放数据的物理介质可以是内存或硬盘, 提供了丰富的缓存数据过期策略, 对 Hibernate 的查询缓存提供了支持SwarmCache: 可作为集群范围内的缓存, 但不支持 Hibernate 的查询缓存JBossCache:可作为集群范围内的缓存, 支持 Hibernate 的查询缓存 开启二级缓存导包 hibernate-ehcache-5.2.8.Final.jar配置 &lt;!–二级缓存 #hibernate.cache.region.factory_class org.hibernate.cache.internal.EhCacheRegionFactory --&gt; &lt;property name=&quot;hibernate.cache.use_second_level_cache&quot;&gt;true&lt;/property&gt; &lt;property name=&quot;hibernate.cache.region.factory_class&quot;&gt;org.hibernate.cache.ehcache.EhCacheRegionFactory&lt;/property&gt; 使用二级缓存类缓存 &lt;!-- 类缓存 --&gt; &lt;class-cache class=&quot;com.ittianyu.hibernate.onetomany.Order&quot; usage=&quot;read-only&quot;/&gt; &lt;class-cache class=&quot;com.ittianyu.hibernate.onetomany.Customer&quot; usage=&quot;read-only&quot;/&gt; 集合缓存 &lt;collection-cache collection=&quot;com.ittianyu.hibernate.onetomany.Customer.orders&quot; usage=&quot;read-only&quot; /&gt; 查询缓存将HQL语句 与 查询结果进行绑定。通过HQL相同语句可以缓存内容。 配置 #hibernate.cache.use_query_cache true 启用 HQL查询缓存 &lt;property name=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/property&gt; 使用 Query query = session.createQuery(&quot;from Customer&quot;); query.setCacheable(true);// 标记为缓存]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM常用参数配置和GC调优]]></title>
    <url>%2F2019%2F04%2F21%2FJVM%E5%B8%B8%E7%94%A8%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E5%92%8CGC%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[JVM配置常用参数堆参数-Xms 初始化堆内存-Xmx 堆内存最大值-Xmn 年轻代大小，剩下为老年代-XX：permGen 永久代大小-XX: maxPermGen 永久代最大值-XX:NewRatio 老年代和年轻代的比例 默认是2 回收器参数-XX:+UseSerialGC Young和old区都是用串行，复制算法-XX:-UseParallelGC 并行，young区： 使用Parallel scavenge回收， old：单线程-XX:+UseParallelOldGc 并行，young和old都是多线程-XX:+UseConcMarkSweepGC: 并发，短暂停顿的并发，young区：可以使用普通的或者parallel垃圾回收算法，old区：使用Concurrent mark sweep-XX:+UseG1GC 并行的并发的和由增量式短暂压缩的垃圾收集器，不区分young和old，划分为多个相等大小的区域， 项目中的常用配置-Xms4800m-xmx4800m-Xmn1800m-xss512k 线程栈空间大小-verbose:gc 输出虚拟机GC详情-XX:+printGCDetails 打印GC详情-XX:+printGCDateStamps 打印GC耗时-XX:+printTenuringDistribution 打印Tenuring年龄信息-XX：heapDumpPath=/home/admin/logs 指定heapdump的文件路径或目录 常用GC调优策略GC调优原则多数的 Java 应用不需要在服务器上进行 GC 优化； 多数导致 GC 问题的 Java 应用，都不是因为我们参数设置错误，而是代码问题； 在应用上线之前，先考虑将机器的 JVM 参数设置到最优（最适合）； 减少创建对象的数量； 减少使用全局变量和大对象； GC 优化是到最后不得已才采用的手段； 在实际使用中，分析 GC 情况优化代码比优化 GC 参数要多得多。 GC调优目的将转移到老年代的对象数量降低到最小减少GC的执行时间 策略 将新对象预留在新生代，fullGC比minorGC慢十倍，通过-Xmn调节新生代大小，最大限度降低新对象直接进入老年代的情况 大对象直接进入老年代因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收老说简直就是噩梦）。-XX:PretenureSizeThreshold 可以设置直接进入老年代的对象大小 合理设置进入老年代的年龄，-XX:MaxTenuringThreshold 设置对象进入老年代的年龄大小，减少老年代的内存占用，降低 full gc 发生的频率 设置稳定的堆大小，堆大小设置有两个参数：-Xms初始化堆大小，-Xmx最大堆大小 ：注意：如果满足下面的指标，则一般不需要进行 GC 优化： MinorGC 执行时间不到50ms； Minor GC 执行不频繁，约10秒一次； Full GC 执行时间不到1s； Full GC 执行频率不算频繁，不低于10分钟1次。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次网页嵌入自定义代码]]></title>
    <url>%2F2019%2F03%2F11%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BD%91%E9%A1%B5%E5%B5%8C%E5%85%A5%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[前言腾讯体育的界面设计太猥琐啦，用了ad block 也不能屏蔽广告，而且内容都不是我需要的，我只看我想看的，而不是由被别人推荐的。这些视频还会加重网络负担，还是删除了吧。 如图： 行动先定位到元素位置，找到该元素的id或者class 很明显的id，直接获取id得到的元素，得到父节点，删除子节点。 12345var ad = document.getElementById(&apos;J_arcarousel&apos;); if (ad != null)&#123; ad.parentNode.removeChild(ad); &#125; 但这样会在很多网站生效所有要根据title判断一下 12345678var title = document.title; if (title.indexOf(&apos;腾讯体育&apos;) != -1)&#123; var ad = document.getElementById(&apos;J_arcarousel&apos;); if (ad != null)&#123; ad.parentNode.removeChild(ad); &#125;&#125; 拖进chrome不的拓展里不生效，谷歌发现我的版本高，不支持了。于是我想做成拓展，做成后发现没有发布在chrome商店，不能用。 最终还是用油猴实现了 结果清爽的界面，而且网络请求也正常了。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>瞎玩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面向对象s设计的六大原则]]></title>
    <url>%2F2019%2F03%2F09%2FJava%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1s%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%85%AD%E5%A4%A7%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[前言这是设计模式系列开篇的第一篇文章。也是我学习设计模式过程中的总结。这篇文章主要讲的是面向对象设计中，我们应该遵循的六大原则。只有掌握了这些原则，我们才能更好的理解设计模式。 我们接下来要介绍以下6个内容。 单一职责原则——SRP 开闭原则——OCP 里式替换原则——LSP 依赖倒置原则——DIP 接口隔离原则——ISP 迪米特原则——LOD 单一职责原则单一职责原则的定义是就一个类而言，应该仅有一个引起他变化的原因。也就是说一个类应该只负责一件事情。如果一个类负责了方法M1,方法M2两个不同的事情，当M1方法发生变化的时候，我们需要修改这个类的M1方法，但是这个时候就有可能导致M2方法不能工作。这个不是我们期待的，但是由于这种设计却很有可能发生。所以这个时候，我们需要把M1方法，M2方法单独分离成两个类。让每个类只专心处理自己的方法。 单一职责原则的好处如下： 可以降低类的复杂度，一个类只负责一项职责，这样逻辑也简单很多 提高类的可读性，和系统的维护性，因为不会有其他奇怪的方法来干扰我们理解这个类的含义 当发生变化的时候，能将变化的影响降到最小，因为只会在这个类中做出修改。 个人觉得有待商榷。 开闭原则开闭原则和单一职责原则一样，是非常基础而且一般是常识的原则。开闭原则的定义是软件中的对象(类，模块，函数等)应该对于扩展是开放的，但是对于修改是关闭的。 当需求发生改变的时候，我们需要对代码进行修改，这个时候我们应该尽量去扩展原来的代码，而不是去修改原来的代码，因为这样可能会引起更多的问题。 这个准则和单一职责原则一样，是一个大家都这样去认为但是又没规定具体该如何去做的一种原则。 开闭原则我们可以用一种方式来确保他，我们用抽象去构建框架，用实现扩展细节。这样当发生修改的时候，我们就直接用抽象了派生一个具体类去实现修改。 个人认为这个原则十分重要，拓展比修改更加容易，而且修改会出现很多未知的bug。 里氏替换原则里氏替换原则是一个非常有用的概念： 如果对每一个类型为T1的对象o1,都有类型为T2的对象o2,使得以T1定义的所有程序P在所有对象o1都替换成o2的时候，程序P的行为都没有发生变化，那么类型T2是类型T1的子类型。 这样说有点复杂，其实有一个简单的定义 所有引用基类的地方必须能够透明地使用其子类的对象。 里氏替换原则通俗的去讲就是：子类可以去扩展父类的功能，但是不能改变父类原有的功能。他包含以下几层意思： 子类可以实现父类的抽象方法，但是不能覆盖父类的非抽象方法。 子类可以增加自己独有的方法。 当子类的方法重载父类的方法时候，方法的形参要比父类的方法的输入参数更加宽松。 当子类的方法实现父类的抽象方法时，方法的返回值要比父类更严格。 里氏替换原则之所以这样要求是因为继承有很多缺点，他虽然是复用代码的一种方法，但同时继承在一定程度上违反了封装。父类的属性和方法对子类都是透明的，子类可以随意修改父类的成员。这也导致了，如果需求变更，子类对父类的方法进行一些复写的时候，其他的子类无法正常工作。所以里氏替换法则被提出来。 确保程序遵循里氏替换原则可以要求我们的程序建立抽象，通过抽象去建立规范，然后用实现去扩展细节，这个是不是很耳熟，对，里氏替换原则和开闭原则往往是相互依存的。 依赖倒置原则依赖倒置原则指的是一种特殊的解耦方式，使得高层次的模块不应该依赖于低层次的模块的实现细节的目的，依赖模块被颠倒了。 这也是一个让人难懂的定义，他可以简单来说就是 高层模块不应该依赖底层模块，两者都应该依赖其抽象 抽象不应该依赖细节 细节应该依赖抽象 在Java 中抽象指的是接口或者抽象类，两者皆不能实例化。而细节就是实现类，也就是实现了接口或者继承了抽象类的类。他是可以被实例化的。高层模块指的是调用端，底层模块是具体的实现类。在Java中，依赖倒置原则是指模块间的依赖是通过抽象来发生的，实现类之间不发生直接的依赖关系，其依赖关系是通过接口是来实现的。这就是俗称的面向接口编程。 通过面向接口编程，我们的代码就有了很高的扩展性，降低了代码之间的耦合度，提高了系统的稳定性。 接口隔离原则接口隔离原则的定义是 客户端不应该依赖他不需要的接口 换一种说法就是类间的依赖关系应该建立在最小的接口上。这样说好像更难懂。我们通过一个例子来说明。我们知道在Java中一个具体类实现了一个接口，那必然就要实现接口中的所有方法。如果我们有一个类A和类B通过接口I来依赖，类B是对类A依赖的实现，这个接口I有5个方法。但是类A与类B只通过方法1,2,3依赖，然后类C与类D通过接口I来依赖，类D是对类C依赖的实现但是他们却是通过方法1,4,5依赖。那么是必在实现接口的时候，类B就要有实现他不需要的方法4和方法5 而类D就要实现他不需要的方法2，和方法3。这简直就是一个灾难的设计。 所以我们需要对接口进行拆分，就是把接口分成满足依赖关系的最小接口，类B与类D不需要去实现与他们无关接口方法。比如在这个例子中，我们可以把接口拆成3个，第一个是仅仅由方法1的接口，第二个接口是包含2,3方法的，第三个接口是包含4,5方法的。 这样，我们的设计就满足了接口隔离原则。 以上这些设计思想用英文的第一个字母可以组成SOLID ，满足这个5个原则的程序也被称为满足了SOLID准则。 迪米特原则迪米特原则也被称为最小知识原则，他的定义 一个对象应该对其他对象保持最小的了解。 因为类与类之间的关系越密切，耦合度越大，当一个类发生改变时，对另一个类的影响也越大，所以这也是我们提倡的软件编程的总的原则：低耦合，高内聚。 迪米特法则还有一个更简单的定义 只与直接的朋友通信。首先来解释一下什么是直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系。耦合的方式很多，依赖、关联、组合、聚合等。其中，我们称出现成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友。也就是说，陌生的类最好不要作为局部变量的形式出现在类的内部。 这里我们可以用一个现实生活中的例子来讲解一下。比如我们需要一张CD,我们可能去音像店去问老板有没有我们需要的那张CD，老板说现在没有，等有的时候你们来拿就行了。在这里我们不需要关心老板是从哪里，怎么获得的那张CD，我们只和老板（直接朋友）沟通，至于老板从他的朋友那里通过何种条件得到的CD，我们不关心，我们不和老板的朋友（陌生人）进行通信，这个就是迪米特的一个应用。说白了，就是一种中介的方式。我们通过老板这个中介来和真正提供CD的人发生联系。 总结到这里，面向对象的六大原则，就写完了。我们看出来，这些原则其实都是应对不断改变的需求。每当需求变化的时候，我们利用这些原则来使我们的代码改动量最小，而且所造成的影响也是最小的。但是我们在看这些原则的时候，我们会发现很多原则并没有提供一种公式化的结论，而即使提供了公式化的结论的原则也只是建议去这样做。这是因为，这些设计原则本来就是从很多实际的代码中提取出来的，他是一个经验化的结论。怎么去用它，用好他，就要依靠设计者的经验。否则一味者去使用设计原则可能会使代码出现过度设计的情况。大多数的原则都是通过提取出抽象和接口来实现，如果发生过度的设计，就会出现很多抽象类和接口，增加了系统的复杂度。让本来很小的项目变得很庞大，当然这也是Java的特性（任何的小项目都会做成中型的项目）。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2019%2F03%2F03%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言观察者模式属于行为型模式 行为型模式概述： 行为型模式(Behavioral Pattern)是对在不同的对象之间划分责任和算法的抽象化。 行为型模式不仅仅关注类和对象的结构，而且重点关注它们之间的相互作用。 通过行为型模式，可以更加清晰地划分类与对象的职责，并研究系统在运行时实例对象之间的交互。在系统运行时，对象并不是孤立的，它们可以通过相互通信与协作完成某些复杂功能，一个对象在运行时也将影响到其他对象的运行。 观察者模式定义观察者模式（又被称为发布-订阅（Publish/Subscribe）模式，属于行为型模式的一种，它定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态变化时，会通知所有的观察者对象，使他们能够自动更新自己。 结构图 在观察者模式中有如下角色： Subject：抽象主题（抽象被观察者），抽象主题角色把所有观察者对象保存在一个集合里，每个主题都可以有任意数量的观察者，抽象主题提供一个接口，可以增加和删除观察者对象。 ConcreteSubject：具体主题（具体被观察者），该角色将有关状态存入具体观察者对象，在具体主题的内部状态发生改变时，给所有注册过的观察者发送通知。 Observer：抽象观察者，是观察者者的抽象类，它定义了一个更新接口，使得在得到主题更改通知时更新自己。 ConcrereObserver：具体观察者，实现抽象观察者定义的更新接口，以便在得到主题更改通知时更新自身的状态。 观察者模式简单实现观察者模式这种发布-订阅的形式我们可以拿微信公众号来举例，假设微信用户就是观察者，微信公众号是被观察者，有多个的微信用户关注了程序猿这个公众号，当这个公众号更新时就会通知这些订阅的微信用户。好了我们来看看用代码如何实现： 抽象观察者（Observer)1234public interface Observer &#123; public void update(String message);&#125; 具体观察者1234567891011121314public class WeixinUser implements Observer &#123; // 微信用户名 private String name; public WeixinUser(String name) &#123; this.name = name; &#125; @Override public void update(String message) &#123; System.out.println(name + &quot;-&quot; + message); &#125;&#125; 抽象被观察者(Subject)抽象主题，提供了attach、detach、notify三个方法： 1234567891011121314151617public interface Subject &#123; /** * 增加订阅者 * @param observer */ public void attach(Observer observer); /** * 删除订阅者 * @param observer */ public void detach(Observer observer); /** * 通知订阅者更新消息 */ public void notify(String message);&#125; 具体被观察者（ConcreteSubject）12345678910111213141516171819202122public class SubscriptionSubject implements Subject &#123; //储存订阅公众号的微信用户 private List&lt;Observer&gt; weixinUserlist = new ArrayList&lt;Observer&gt;(); @Override public void attach(Observer observer) &#123; weixinUserlist.add(observer); &#125; @Override public void detach(Observer observer) &#123; weixinUserlist.remove(observer); &#125; @Override public void notify(String message) &#123; for (Observer observer : weixinUserlist) &#123; observer.update(message); &#125; &#125;&#125; 客户端调用12345678910111213141516public class Client &#123; public static void main(String[] args) &#123; SubscriptionSubject mSubscriptionSubject=new SubscriptionSubject(); //创建微信用户 WeixinUser user1=new WeixinUser(&quot;hong&quot;); WeixinUser user2=new WeixinUser(&quot;lan&quot;); WeixinUser user3=new WeixinUser(&quot;lv&quot;); //订阅公众号 mSubscriptionSubject.attach(user1); mSubscriptionSubject.attach(user2); mSubscriptionSubject.attach(user3); //公众号更新发出消息给订阅的微信用户 mSubscriptionSubject.notify(&quot;kunrong的专栏更新了&quot;); &#125;&#125; 结果 hong-kunrong的专栏更新了 lan-kunrong的专栏更新了 lv-kunrong的专栏更新了 使用观察者模式的场景和优缺点使用场景 关联行为场景，需要注意的是，关联行为是可拆分的，而不是“组合”关系。 事件多级触发场景。 跨系统的消息交换场景，如消息队列、事件总线的处理机制。 优点解除耦合，让耦合的双方都依赖于抽象，从而使得各自的变换都不会影响另一边的变换。 缺点在应用观察者模式时需要考虑一下开发效率和运行效率的问题，程序中包括一个被观察者、多个观察者，开发、调试等内容会比较复杂，而且在Java中消息的通知一般是顺序执行，那么一个观察者卡顿，会影响整体的执行效率，在这种情况下，一般会采用异步实现。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应对算法面试]]></title>
    <url>%2F2019%2F02%2F27%2F%E5%BA%94%E5%AF%B9%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[前言算法面试不仅仅是正确回答问题，大多数问题，更需要一个合理的思考路径，展示给面试官你思考问题的方式。 例子 我们需要对一组数据进行排序 设计排序接口，标准库的设计，业务中的排序算法 排序是基础操作，很重要 解决 快速排序 O(nlogn) 忽略了算法的使用的基础环境，要动态选择 向面试官提问，这组数据有什么样的特征 有没有大量重复的元素 如果有，三路快排是更好的选择 普通数据： 普通快速排序就好 是否大部分数据距离它正确的位置很近，是否近乎有序 如果是，插入排序更好 按照业务发生顺序，先发生先完成，几乎有序，插入排序更好 是否数据的取值范围非常有限？比如对学生成绩排序 如果是这样，计数排序是更好的选择，高考成绩取值范围有限：计数排序更好 对排序有什么额外的要求 是否需要稳定？ 如果是，归并排序是更好的选择 是否是使用链表存储的？ 如果是，归并排序是更好的选择 快排依赖于数组的随机存储 数据的存储情况是怎样的？ 数据的大小是否可以装载在内存中 数据量大，或者内存很小，不足以装在内存里，需要使用外排序算法 (外部排序指的是大文件的排序，即待排序的记录存储在外存储器上，待排序的文件无法一次装入内存，需要在内存和外部存储器之间进行多次数据交换，以达到排序 整个文件的目的。外部排序最常用的算法是多路归并排序，即将原文件分解成多个能够一次性装入内存的部分，分别把每一部分调入内存完成排序。然后，对已经排 序的子文件进行多路归并排序。) 对一组数据进行排序小结 有没有可能包含有大量重复的元素？是否大部分数据距离它正确的位置很近？是否近乎有序？是否数据的取值范围非常有限？比如对学生成绩排序。是否需要稳定排序？是否是使用链表存储的？数据的大小是否可以装载在内存里？ 什么算是正确地回答一个算法问题 正确除了你能把代码编出来运行正确的结果，还包含对问题的独到见解；优化；代码规范；容错性 关键在于你所表达的解决问题的思路 甚至通过表达解题思路的方向，得出结论：这个问题的解决方案，应该在哪一个领域，可以通过查阅或者进一步学习解决问题 面试前梳理自己简历上所写到的项目：整理一下可能会问到的。 你遇到的印象最深的bug是什么？ 面向对象 设计模式 网络相关；安全相关；内存相关；并发相关；… 系统设计；scalability（大规模） 行为类问题 遇到的最大的挑战？ 犯过的错误？ 遭遇的失败？ 最享受的工作内容？ 遇到冲突的处理方式？ 做的最与众不同的事儿？ 具体阐述：我在某某项目中遇到一个怎样的算法问题：这个问题是怎样的。它是我遇到的最大的挑战,我是如何克服解决的 准备好合适的问题问面试官 整个小组的大概运行模式是怎样的？ 整个项目的后续规划是如何的？ 这个产品中的某个问题是如何解决的？ 为什么会选择某些技术？标准？ 我对某个技术很感兴趣，在你的小组中我会有怎样的机会深入这种技术？ 算法面试的准备范围 不要轻视基础算法和数据结构，而只关注“有意思”的题目 各种排序算法 基础数据结构和算法的实现：如堆、二叉树、图… 基础数据结构的使用：如链表、栈、队列、哈希表、图、Trie、并查集… 基础算法：深度优先、广度优先、二分查找、递归… 基本算法思想：递归、分治、回溯搜索、贪心、动态规划… 适合的OJ Online Portal for IT Interview 真实的面试问题 www.leetcode.com HankeRank 如何回答算法面试的问题 注意题目中的条件 给定一个有序数组（二分法） 有一些题目中的条件本质是暗示 设计一个O(nlogn)的算法（分治法：在一棵搜索树中完成任务，对于数据排序） 无需考虑额外的空间（用空间换时间） 数据规模大概是10000（用O（n^2)就可以) 当没有思路时 自己给自己几个简单的测试用例，实验一下 不要忽视暴力解决，暴力解法通常时思考的起点。 补充：三路快排适用于排序元素序列中有大量的重复排序码。简单的快速排序算法的效率将会降到非常之低。一种直接的想法就是将待排序列分成三个子序列：一部分是排序码比基准元素排序码小的；一部分是与基准元素排序码等值的；一部分是比基准元素排序码大的，如下图所示： 但是，如果我们直接据此思想去编写实现算法的话，会让我们面临很大的困难。与基准元素等值的元素到底有多少？以及如何最快速有效地确定划分的边界？所以，完成这样的三路划分是非常困难的，甚至比两路划分过程更加复杂。我们可以基于以下的思想实现三路划分：在划分的过程中，扫描时将遇到的左子序列中与基准元素排序码等值的元素放到序列的最左边，将遇到的右子序列中与基准元素排序码等值的元素放到序列的最右边。这样，我们会得到如下所示的序列划分图： 当两个扫描指针相遇时，排序码相等的元素的确切位置就知道了。然后我们只要将所有排序码与基准元素等值的元素与扫描指针指向的元素开始依次交换，就可以得到三路划分的结果了。这个方法不仅有效地处理了待排序元素序列中的重复值问题，而且在没有重复值时它也能保持算法原来的性能。其优点是：第一，如果元素序列中没有重复值，这个方法可以保持算法的效率，因为没有额外的工作要做；第二，在每次话划分的过程中，都可以将与基准元素排序码相等的元素分割出来，所有拥有相同排序码值的元素不会参加多次划分。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101private void quickSort(int[] a, int left, int right) &#123; if (right &lt;= left) return; /* * 工作指针 * p指向序列左边等于pivot元素的位置 * q指向序列右边等于Pivot元素的位置 * i指向从左向右扫面时的元素 * j指向从右向左扫描时的元素 */ int p, q, i, j; int pivot;// 锚点 i = p = left; j = q = right - 1; /* * 每次总是取序列最右边的元素为锚点 */ pivot = a[right]; while (true) &#123; /* * 工作指针i从右向左不断扫描，找小于或者等于锚点元素的元素 */ while (i &lt; right &amp;&amp; a[i] &lt;= pivot) &#123; /* * 找到与锚点元素相等的元素将其交换到p所指示的位置 */ if (a[i] == pivot) &#123; swap(a, i, p); p++; &#125; i++; &#125; /* * 工作指针j从左向右不断扫描，找大于或者等于锚点元素的元素 */ while (left &lt;= j &amp;&amp; a[j] &gt;= pivot) &#123; /* * 找到与锚点元素相等的元素将其交换到q所指示的位置 */ if (a[j] == pivot) &#123; swap(a, j, q); q--; &#125; j--; &#125; /* * 如果两个工作指针i j相遇则一趟遍历结束 */ if (i &gt;= j) break; /* * 将左边大于pivot的元素与右边小于pivot元素进行交换 */ swap(a, i, j); i++; j--; &#125; /* * 因为工作指针i指向的是当前需要处理元素的下一个元素 * 故而需要退回到当前元素的实际位置，然后将等于pivot元素交换到序列中间 */ i--; p--; while (p &gt;= left) &#123; swap(a, i, p); i--; p--; &#125; /* * 因为工作指针j指向的是当前需要处理元素的上一个元素 * 故而需要退回到当前元素的实际位置，然后将等于pivot元素交换到序列中间 */ j++; q++; while (q &lt;= right) &#123; swap(a, j, q); j++; q++; &#125; /* * 递归遍历左右子序列 */ quickSort(a, left, i); quickSort(a, j, right);&#125;private void quick(int[] a) &#123; if (a.length &gt; 0) &#123; quickSort(a, 0, a.length - 1); &#125;&#125;private void swap(int[] arr, int a, int b) &#123; int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis详解]]></title>
    <url>%2F2019%2F02%2F26%2Fredis%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Redis的基本介绍 REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 Redis的特点 支持数据持久化，可以将内存中的数据保存到磁盘中，重启的时候可以再次加载使用 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储 Redis支持数据的备份，即master-slaver模式的数据备份 Redis的优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis的应用场景 显示最新的项目列表 这个语句常用来显示最新项目，随着数据多了，查询毫无疑问会越来越慢 12SELECT * FROM foo WHERE ... ORDER BY time DESC LIMIT 10 在Web应用中，“列出最新的回复”之类的查询非常普遍，这通常会带来可扩展性问题。这令人沮丧，因为项目本来就是按这个顺序被创建的，但要输出这个顺序却不得不进行排序操作。类似的问题就可以用Redis来解决。比如说，我们的一个Web应用想要列出用户贴出的最新20条评论。在最新的评论边上我们有一个“显示全部”的链接，点击后就可以获得更多的评论。我们假设数据库中的每条评论都有一个唯一的递增的ID字段。我们可以使用分页来制作主页和评论页，使用Redis的模板： 每次新评论发表时，我们会将它的ID添加到一个Redis列表： 12LPUSH latest.comments &lt;ID&gt; 我们将列表裁剪为指定长度，因此Redis只需要保存最新的5000条评论： 1LTRIM latest.comments 0 5000 每次我们需要获取最新评论的项目范围时，我们调用一个函数来完成（使用伪代码）： 12345678910111213FUNCTION get_latest_comments(start,num_items): id_list = redis.lrange(&quot;latest.comments&quot;,start,start+num_items-1) IF id_list.length &lt; num_items id_list = SQL_DB(&quot;SELECT ... ORDER BY time LIMIT ...&quot;) END RETURN id_list END 这里我们做的很简单。在Redis中我们的最新ID使用了常驻缓存，这是一直更新的。但是我们做了限制不能超过5000个ID，因此我们的获取ID函数会一直询问Redis。只有在start/count参数超出了这个范围的时候，才需要去访问数据库。我们的系统不会像传统方式那样“刷新”缓存，Redis实例中的信息永远是一致的。SQL数据库（或是硬盘上的其他类型数据库）只是在用户需要获取“很远”的数据时才会被触发，而主页或第一个评论页是不会麻烦到硬盘上的数据库了。 删除和过滤 我们可以使用LREM来删除评论。如果删除操作非常少，另一个选择是直接跳过评论条目的入口，报告说该评论已经不存在。有些时候你想要给不同的列表附加上不同的过滤器。如果过滤器的数量受到限制，你可以简单的为每个不同的过滤器使用不同的Redis列表。毕竟每个列表只有5000条项目，但Redis却能够使用非常少的内存来处理几百万条项目 排行榜 另一个很普遍的需求是各种数据库的数据并非存储在内存中，因此在按得分排序以及实时更新这些几乎每秒钟都需要更新的功能上数据库的性能不够理想。典型的比如那些在线游戏的排行榜，比如一个Facebook的游戏，根据得分你通常想要： 列出前100名高分选手列出某用户当前的全球排名 这些操作对于Redis来说小菜一碟，即使你有几百万个用户，每分钟都会有几百万个新的得分。模式是这样的，每次获得新得分时，我们用这样的代码： 1ZADD leaderboard 得到前100名高分用户很简单： ZREVRANGE leaderboard 0 99 为什么单线程成的Redis这么快总结了几点： 纯内存操作 单线程 高效的数据结构 合理的数据编码 其他方面的优化 5种数据结构String：缓存、计数器、分布式锁等。List：链表、队列、微博关注人时间轴列表等。Hash：用户信息、Hash 表等。Set：去重、赞、踩、共同好友等。Zset：访问量排行榜、点击量排行榜等。 SDSRedis 虽然是C语言开发，但字符串没有用C语言中的字符串，而是用一种SDS（simple dynamic String）的结构体来保存字符串 123456struct sdshdr &#123; int len; int free; char buf[];&#125; SDS 的结构如上图： len：用于记录 buf 中已使用空间的长度。free：buf 中空闲空间的长度。buf[]：存储实际内容。例如：执行命令 set key value，key 和 value 都是一个 SDS 类型的结构存储在内存中。 SDS 与 C 字符串的区别 常数时间内获得字符串长度 避免缓冲区溢出 假设在内存中有两个紧挨着的两个字符串，s1=“xxxxx”和 s2=“yyyyy”。 由于在内存上紧紧相连，当我们对 s1 进行扩充的时候，将 s1=“xxxxxzzzzz”后，由于没有进行相应的内存重新分配，导致 s1 把 s2 覆盖掉，导致 s2 被莫名其妙的修改。 但 SDS 的 API 对 zfc 修改时首先会检查空间是否足够，若不充足则会分配新空间，避免了缓冲区溢出问题。 减少字符串修改时带来的内存重新分配的次数 在 C 中，当我们频繁的对一个字符串进行修改（append 或 trim）操作的时候，需要频繁的进行内存重新分配的操作，十分影响性能。 如果不小心忘记，有可能会导致内存溢出或内存泄漏，对于 Redis 来说，本身就会很频繁的修改字符串，所以使用 C 字符串并不合适。而 SDS 实现了空间预分配和惰性空间释放两种优化策略： 空间预分配：当 SDS 的 API 对一个 SDS 修改后，并且对 SDS 空间扩充时，程序不仅会为 SDS 分配所需要的必须空间，还会分配额外的未使用空间。 分配规则如下：如果对 SDS 修改后，len 的长度小于 1M，那么程序将分配和 len 相同长度的未使用空间。举个例子，如果 len=10，重新分配后，buf 的实际长度会变为 10(已使用空间)+10(额外空间)+1(空字符)=21。如果对 SDS 修改后 len 长度大于 1M，那么程序将分配 1M 的未使用空间。 惰性空间释放：当对 SDS 进行缩短操作时，程序并不会回收多余的内存空间，而是使用 free 字段将这些字节数量记录下来不释放，后面如果需要 append 操作，则直接使用 free 中未使用的空间，减少了内存的分配。 二进制安全 在 Redis 中不仅可以存储 String 类型的数据，也可能存储一些二进制数据。 二进制数据并不是规则的字符串格式，其中会包含一些特殊的字符如 ‘\0’，在 C 中遇到 ‘\0’ 则表示字符串的结束，但在 SDS 中，标志字符串结束的是 len 属性。 字典与 Java 中的 HashMap 类似，Redis 中的 Hash 比 Java 中的更高级一些。 Redis 本身就是 KV 服务器，除了 Redis 本身数据库之外，字典也是哈希键的底层实现。 字典的数据结构如下所示： 1234567typedef struct dict&#123; dictType *type; void *privdata; dictht ht[2]; int trehashidx;&#125; 1234567891011typedef struct dictht&#123; //哈希表数组 dectEntrt **table; //哈希表大小 unsigned long size; // unsigned long sizemask; //哈希表已有节点数量 unsigned long used;&#125; 重要的两个字段是 dictht 和 trehashidx，这两个字段与 rehash 有关，下面重点介绍 rehash。 当然是为了 Rehash，Rehash 的过程如下： 为 ht[1] 分配空间。如果是扩容操作，ht[1] 的大小为第一个大于等于 ht[0].used*2 的 2^n；如果是缩容操作，ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n。 将 ht[0] 中的键值 Rehash 到 ht[1] 中。 当 ht[0] 全部迁移到 ht[1] 中后，释放 ht[0]，将 ht[1] 置为 ht[0]，并为 ht[1] 创建一张新表，为下次 Rehash 做准备。 渐进式 Rehash由于 Redis 的 Rehash 操作是将 ht[0] 中的键值全部迁移到 ht[1]，如果数据量小，则迁移过程很快。但如果数据量很大，一个 Hash 表中存储了几万甚至几百万几千万的键值时，迁移过程很慢并会影响到其他用户的使用。 为了避免 Rehash 对服务器性能造成影响，Redis 采用了一种渐进式 Rehash 的策略，分多次、渐进的将 ht[0] 中的数据迁移到 ht[1] 中。 前一过程如下： 为 ht[1] 分配空间，让字典同时拥有 ht[0] 和 ht[1] 两个哈希表。字典中维护一个 rehashidx，并将它置为 0，表示 Rehash 开始。在 Rehash 期间，每次对字典操作时，程序还顺便将 ht[0] 在 rehashidx 索引上的所有键值对 rehash 到 ht[1] 中，当 Rehash 完成后，将 rehashidx 属性+1。当全部 rehash 完成后，将 rehashidx 置为 -1，表示 rehash 完成。注意，由于维护了两张 Hash 表，所以在 Rehash 的过程中内存会增长。另外，在 Rehash 过程中，字典会同时使用 ht[0] 和 ht[1]。 所以在删除、查找、更新时会在两张表中操作，在查询时会现在第一张表中查询，如果第一张表中没有，则会在第二张表中查询。但新增时一律会在 ht[1] 中进行，确保 ht[0] 中的数据只会减少不会增加。 跳跃表Zset 是一个有序的链表结构，其底层的数据结构是跳跃表 skiplist，其结构如下： 1234567891011121314typedef struct zskiplistNode &#123; //成员对象 robj *obj; //分值 double score; //后退指针 struct zskiplistNode *backward; //层 struct zskiplistLevel &#123; struct zskiplistNode *forward;//前进指针 unsigned int span;//跨度 &#125; level[]; &#125; zskiplistNode; 123456789typedef struct zskiplist &#123; //表头节点和表尾节点 struct zskiplistNode *header, *tail; //表中节点的的数量 unsigned long length; //表中层数最大的节点层数 int level; &#125; zskiplist; 前进指针：用于从表头向表尾方向遍历。 后退指针：用于从表尾向表头方向回退一个节点，和前进指针不同的是，前进指针可以一次性跳跃多个节点，后退指针每次只能后退到上一个节点。 跨度：表示当前节点和下一个节点的距离，跨度越大，两个节点中间相隔的元素越多。 在查询过程中跳跃着前进。由于存在后退指针，如果查询时超出了范围，通过后退指针回退到上一个节点后仍可以继续向前遍历。 压缩列表压缩列表 ziplist 是为 Redis 节约内存而开发的，是列表键和字典键的底层实现之一。 当元素个数较少时，Redis 用 ziplist 来存储数据，当元素个数超过某个值时，链表键中会把 ziplist 转化为 linkedlist，字典键中会把 ziplist 转化为 hashtable。 ziplist 是由一系列特殊编码的连续内存块组成的顺序型的数据结构，ziplist 中可以包含多个 entry 节点，每个节点可以存放整数或者字符串。 由于内存是连续分配的，所以遍历速度很快 编码转化Redis 使用对象（redisObject）来表示数据库中的键值，当我们在 Redis 中创建一个键值对时，至少创建两个对象，一个对象是用做键值对的键对象，另一个是键值对的值对象。 例如我们执行 SET MSG XXX 时，键值对的键是一个包含了字符串“MSG“的对象，键值对的值对象是包含字符串”XXX”的对象。 redisObject 的结构如下： 12345678910typedef struct redisObject&#123; //类型 unsigned type:4; //编码 unsigned encoding:4; //指向底层数据结构的指针 void *ptr; //... &#125;robj; 其中 type 字段记录了对象的类型，包含字符串对象、列表对象、哈希对象、集合对象、有序集合对象。 当我们执行 type key 命令时返回的结果如下 ptr 指针字段指向对象底层实现的数据结构，而这些数据结构是由 encoding 字段决定的，每种对象至少有两种数据编码： 可以通过 object encoding key 来查看对象所使用的编码： String 对象的编码转化String 对象的编码可以是 int 或 raw，对于 String 类型的键值，如果我们存储的是纯数字，Redis 底层采用的是 int 类型的编码，如果其中包括非数字，则会立即转为 raw 编码：127.0.0.1:6379&gt; set str 1OK127.0.0.1:6379&gt; object encoding str“int”127.0.0.1:6379&gt; set str 1aOK127.0.0.1:6379&gt; object encoding str“raw”127.0.0.1:6379&gt; List对象的编码转化List 对象的编码可以是 ziplist 或 linkedlist，对于 List 类型的键值，当列表对象同时满足以下两个条件时，采用 ziplist 编码： 列表对象保存的所有字符串元素的长度都小于 64 字节。列表对象保存的元素个数小于 512 个。如果不满足这两个条件的任意一个，就会转化为 linkedlist 编码。注意：这两个条件是可以修改的，在 redis.conf 中： list-max-ziplist-entries 512list-max-ziplist-value 64 Set 类型的编码转化Set 对象的编码可以是 intset 或 hashtable，intset 编码的结婚对象使用整数集合作为底层实现，把所有元素都保存在一个整数集合里面。 127.0.0.1:6379&gt; sadd set 1 2 3(integer) 3127.0.0.1:6379&gt; object encoding set“intset”127.0.0.1:6379&gt; 如果 set 集合中保存了非整数类型的数据时，Redis 会将 intset 转化为 hashtable： 127.0.0.1:6379&gt; sadd set 1 2 3(integer) 3127.0.0.1:6379&gt; object encoding set“intset”127.0.0.1:6379&gt; sadd set a(integer) 1127.0.0.1:6379&gt; object encoding set“hashtable” 127.0.0.1:6379&gt; 当 Set 对象同时满足以下两个条件时，对象采用 intset 编码： 保存的所有元素都是整数值（小数不行）。Set 对象保存的所有元素个数小于 512 个。不能满足这两个条件的任意一个，Set 都会采用 hashtable 存储。注意：第两个条件是可以修改的，在 redis.conf 中： set-max-intset-entries 512 Hash 对象的编码转化Hash 对象的编码可以是 ziplist 或 hashtable，当 Hash 以 ziplist 编码存储的时候，保存同一键值对的两个节点总是紧挨在一起，键节点在前，值节点在后： 当 Hash 对象同时满足以下两个条件时，Hash 对象采用 ziplist 编码： Hash 对象保存的所有键值对的键和值的字符串长度均小于 64 字节。 Hash 对象保存的键值对数量小于 512 个。如果不满足以上条件的任意一个，ziplist 就会转化为 hashtable 编码。注意：这两个条件是可以修改的，在 redis.conf 中： hash-max-ziplist-entries 512 Zset 对象的编码转化Zset 对象的编码可以是 ziplist 或 zkiplist，当采用 ziplist 编码存储时，每个集合元素使用两个紧挨在一起的压缩列表来存储。 第一个节点存储元素的成员，第二个节点存储元素的分值，并且按分值大小从小到大有序排列。 当 Zset 对象同时满足一下两个条件时，采用 ziplist 编码： Zset 保存的元素个数小于 128。 Zset 元素的成员长度都小于 64 字节。 如果不满足以上条件的任意一个，ziplist 就会转化为 zkiplist 编码。注意：这两个条件是可以修改的，在 redis.conf 中： zset-max-ziplist-entries 128zset-max-ziplist-value 64 思考：Zset 如何做到 O(1) 复杂度内元素并且快速进行范围操作？Zset 采用 skiplist 编码时使用 zset 结构作为底层实现，该数据结构同时包含了一个跳跃表和一个字典。 其结构如下： 12345typedef struct zset&#123; zskiplist *zsl; dict *dict;&#125; Zset 中的 dict 字典为集合创建了一个从成员到分值之间的映射，字典中的键保存了成员，字典中的值保存了成员的分值，这样定位元素时时间复杂度是 O(1)。 Zset 中的 zsl 跳跃表适合范围操作，比如 ZRANK、ZRANGE 等，程序使用 zkiplist。 另外，虽然 Zset 中使用了 dict 和 skiplist 存储数据，但这两种数据结构都会通过指针来共享相同的内存，所以没有必要担心内存的浪费 过期数据的删除对Redis的性能影响当我们对某些 key 设置了 expire 时，数据到了时间会自动删除。如果一个键过期了，它会在什么时候删除呢？ 下面介绍三种删除策略： 定时删除：在这是键的过期时间的同时，创建一个定时器 Timer，让定时器在键过期时间来临时立即执行对过期键的删除 惰性删除：键过期后不管，每次读取该键时，判断该键是否过期，如果过期删除该键返回空 定期删除：每隔一段时间对数据库中的过期键进行一次检查。 定时删除：对内存友好，对 CPU 不友好。如果过期删除的键比较多的时候，删除键这一行为会占用相当一部分 CPU 性能，会对 Redis 的吞吐量造成一定影响。 惰性删除：对 CPU 友好，内存不友好。如果很多键过期了，但在将来很长一段时间内没有很多客户端访问该键导致过期键不会被删除，占用大量内存空间。 定期删除：是定时删除和惰性删除的一种折中。每隔一段时间执行一次删除过期键的操作，并且限制删除操作执行的时长和频率。 具体的操作如下： Redis 会将每一个设置了 expire 的键存储在一个独立的字典中，以后会定时遍历这个字典来删除过期的 key。除了定时遍历外，它还会使用惰性删除策略来删除过期的 key。 Redis 默认每秒进行十次过期扫描，过期扫描不会扫描所有过期字典中的 key，而是采用了一种简单的贪心策略。从过期字典中随机选择 20 个 key；删除这 20 个 key 中已过期的 key；如果过期 key 比例超过 1/4，那就重复步骤 1。 同时，为了保证在过期扫描期间不会出现过度循环，导致线程卡死，算法还增加了扫描时间上限，默认不会超过 25ms。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>面试知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库专题]]></title>
    <url>%2F2019%2F02%2F21%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%93%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前言面试之路漫漫其修远兮，吾将上下而求索 优化查询的方法使用索引应该尽量避免全表扫描，首先应考虑再where以及order by，group by涉及的列上建立索引 优化SQL语句 通过explain（查询优化神器）用来查看sql语句的执行效果，可以帮助选择更好的索引和优化查询语句；eg：explain select * from news; 任何地方都不要使用select from t,用具体字段列表代替“”，不要返回用不到的任何字段。 不在索引类做运算或者使用函数 查询尽可能使用limit减少返回的行数，减少数据传送传输时间和带宽浪费 优化数据库对象优化表的数据类型使用 procedure analyse()函数对表进行分析， 该函数可以对表中列的数据类型提出优化建议。 能小就用小。 表数据类型第一个原则是： 使用能正确的表示和存储数据的最短类型。 这样可以减少对磁盘空间、 内存、 cpu 缓存的使用使用方法：select * from 表名 procedure analyse(); 对表进行拆分 垂直拆分 把主键和一些列放在一个表中， 然后把主键和另外的列放在另一个表中。 如果一个表中某些列常用， 而另外一些不常用， 则可以采用垂直拆分 水平拆分 根据一列或者多列数据的值把数据行放到两个独立的表中 使用中间表来提高查询速度创建中间表， 表结构和源表结构完全相同， 转移要统计的数据到中间表， 然后在中间表上进行统计， 得出想要的结果。 硬件优化 cpu优化，选择多核和主频高的cpu 内存的优化，使用更大的内存，将尽量多的内存分配给mysql做缓存 磁盘I/O的优化 使用磁盘阵列RAID 0 没有数据冗余， 没有数据校验的磁盘陈列。 实现 RAID 0至少需要两块以上的硬盘， 它将两块以上的硬盘合并成一块， 数据连续地分割在每块盘上。RAID1 是将一个两块硬盘所构成 RAID 磁盘阵列， 其容量仅等于一块硬盘的容量， 因为另一块只是当作数据“镜像”。使用 RAID-0+1 磁盘阵列。 RAID 0+1 是 RAID 0 和 RAID 1 的组合形式。 它在提供与 RAID 1 一样的数据安全保障的同时， 也提供了与 RAID 0 近似的存储性能 调整磁盘调度算法选择合适的磁盘调度算法，可以减少磁盘的寻道时间Mysql的自身优化对 MySQL 自身的优化主要是对其配置文件 my.cnf 中的各项参数进行优化调整。 如指定 MySQL 查询缓冲区的大小， 指定 MySQL 允许的最大连接进程数等 应用优化 使用数据库连接池 使用查询缓存 它的作用是存储 select 查询的文本及其相应结果。 如果随后收到一个相同的查询， 服务器会从查询缓存中直接得到查询结果。 查询缓存适用的对象是更新不频繁的表， 当表中数据更改后， 查询缓存中的相关条目就会被清空。 如果有一个特别大的访问量到数据库上， 怎么做优化？ 使用优化查询的方法（上述） 主从复制，读写分离，负载均衡 目前，大部分的主流关系型数据库都提供了主从复制的功能，通过配置两台（或多台）数据库的主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。网站可以利用数据库的这一功能，实现数据库的读写分离，从而改善数据库的负载压力。一个系统的读操作远远多于写操作，因此写操作发向 master，读操作发向 slaves 进行操作（简单的轮循算法来决定使用哪个 slave）。利用数据库的读写分离，Web 服务器在写数据的时候，访问主数据库（Master），主数据库通过主从复制机制将数据更新同步到从数据库（Slave），这样当 Web 服务器读数据的时候，就可以通过从数据库获得数据。这一方案使得在大量读操作的 Web 应用可以轻松地读取数据，而主数据库也只会承受少量的写入操作，还可以实现数据热备份，可谓是一举两得的方案 数据库的分表，分区，分库分表见上面描述。分区就是把一张表的数据分成多个区块，这些区块可以在一个磁盘上，也可以在不同的磁盘上，分区后，表面上还是一张表，但数据散列在多个位置，这样一来，多块硬盘同时处理不同的请求，从而提高磁盘 I/O 读写性能，实现比较简单。 包括水平分区和垂直分区。分库是根据业务不同把相关的表切分到不同的数据库中，比如 web、bbs、blog 等库 sql的注入问题 sql语句的安全考虑 1.防止 sql 注入， 对特殊字符进行过滤、 转义或者使用预编译的 sql 语句绑定变量。 2.当 sql 语句运行出错时， 不要把数据库返回的错误信息全部显示给用户，以防止泄漏服务器和数据库相关信息。解决方法： 参数绑定。为了防范这样” SQL 注入安全“可以用预编译解决（不要用拼接 SQL 字符串,可以用 prepareStatement,参数用 set 方法进行填装 ） 检查变量的数据类型和格式 如果你的 SQL 语句是类似 where id={$id}这种形式， 数据库里所有的 id 都是数字， 那么就应该在 SQL 被执行前， 检查确保变量 id 是 int 类型； 如果是接受邮箱， 那就应该检查并严格确保变量一定是邮箱的格式， 其他的类型比如日期、时间等也是一个道理。 总结起来： 只要是有固定格式的变量， 在 SQL 语句执行前， 应该严格按照固定格式去检查， 确保变量是我们预想的格式， 这样很大程度上可以避免 SQL 注入攻击 所有的sql语句都封装在存储过程中 连接问题 内连接只会返回符合连接条件的纪录 左外连接（LEFT JOIN 或 LEFT OUTER JOIN ） 即以左表为基准，到右表找匹配的数据，找不到匹配的用 NULL 补齐。显示左表的全部记录及右表符合连接条件的记录 右外连接（RIGHT JOIN 或 RIGHT OUTER JOIN ） 即以右表为基准，到左表找匹配的数据，找不到匹配的用 NULL 补齐。显示右表的全部记录及左表符合连接条件的记录。 全外连接除了显示符合连接条件的记录外，在 2 个表中的其他记录也显示出来 数据库中两个表求交集，并集，差集 求交集 select A.* from A inner join B using(name,addr,age); 求差集在A中出现但B没有的select A.* from A left join B using(name,addr,age) where B.name is NULL; 求并集（用union) 存储过程存储过程：就是一些编译好的sql语句，这些sql语句代码像一个方法一样实现一些功能（对单表或多表的增删查改），然后给代码取一个名字，在用到这个功能的时候就调用他就行。 优点： 预编译过了，速度快。 在服务器运行，减少客户端压力 允许模块化程序设计，就是只需创建一次过程，以后再程序中就可以调用过程任意次，类似方法的复用。 减少网络流量 增强了使用的安全性 缺点：调试麻烦，可移植性不灵活 涉及范式的问题1NF:字段不可再分，原子性。2NF：满足第二范式（ 2NF ）必须先满足第一范式（ 1NF ）。一个表只能说明一个事物。非主键属性必须完全依赖于主键属性。3NF:满足第三范式（ 3NF ） 必须先满足第二范式（ 2NF ） 。每列都与主键有直接关系，不存在传递依赖。任何非主属性不依赖于其它非主属性BCNF：BCNF是比第三范式更严格一个范式。它要求关系模型中所有的属性（包括主属性和非主属性）都不传递依赖于任何候选关键字。也就是说，当关系型表中功能上互相依赖的那些列的每一列都是一个候选关键字时候，该满足BCNF。 BCNF实际上是在第三范式的基础上，进一步消除了主属性的传递依赖。 不符合第一范式的例子(关系数据库中 create 不出这样的表)：表:字段 1, 字段 2(字段 2.1, 字段 2.2), 字段 3 ……不符合第二范式的例子:表:学号, 姓名, 年龄, 课程名称, 成绩, 学分;这个表明显说明了两个事物:学生信息, 课程信息。不符合第三范式的例子:学号, 姓名, 年龄, 所在学院, 学院地点，学院联系电话，主键为”学号”；存在依赖传递: (学号) → (所在学院) → (学院地点, 学院电话) https://blog.csdn.net/a327736051/article/details/51419136举例 有这样一个配件管理表WPE(WNO,PNO,ENO,QNT),其中WNO表示仓库号，PNO表示配件号，ENO表示职工号，QNT表示数量。 有以下约束要求： （1） 一个仓库有多名职工； （2） 一个职工仅在一个仓库工作； （3） 每个仓库里一种型号的配件由专人负责，但一个人可以管理几种配件； （4） 同一种型号的配件可以分放在几个仓库中。 分析表中的函数依赖关系，可以得到： （1） ENO-&gt;WNO; （2） （WNO，PNO）-&gt;QNT （3） （WNO，PNO）-&gt;ENO （4） （ENO，PNO）-&gt;QNT 可以看到，候选键有：（ENO,PNO）;(WNO,PNO)。所以，ENO,PNO,WNO均为主属性，QNT为非主属性。显然，非主属性是直接依赖于候选键的。所以此表满足第三范式。 而我们观察一下主属性：（WNO,PNO）-&gt;ENO;ENO-&gt;WNO。显然WNO对于候选键（WNO,PNO）存在传递依赖，所以不符合BCNF. 解决这个问题的办法是分拆为两个表：管理表EP（ENO，PNO，QNT）；工作表EW（ENO，WNO）。但这样做会导致函数依赖（WNO,PNO）-&gt;ENO丢失。 涉及事务的问题事务是由一组sql语句组成的逻辑处理单元ACID 原子性：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束再中间某个环节，事务在执行过程中发生错误，会被回滚到事务开始前的状态。就像这个事务从来没有执行过一样。 一致性：在事务开始和完成时，数据库中的数据都保持一致的状态，数据的完整性约束没有被破坏，具体来说就是， 比如表与表之间存在外键约束关系， 那么你对数据库进行的修改操作就必需要满足约束条件， 即如果你修改了一张表中的数据， 那你还需要修改与之存在外键约束关系的其他表中对应的数据， 以达到一致性。 隔离性：一个事务的执行不能被其他事务干扰，为了防止事务操作间的混淆，必须串行化或者序列化执行请求，使得在同一时间仅有一个请求用于同一数据。（在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务）（事务处理过程中的中间状态对外部时不可见的）。隔离性通过锁就可以实现。 持久性：一个事务一旦提交，它对数据库中数据的改变就应该时永久性的。并不会被回滚。 并发事务带来的问题 更新丢失两个事务T1和T2 读入同一数据并修改，T2提交的结果覆盖了T1提交的结果，导致T1的修改被丢失。 脏读事务T1修改某一数据，并且将其写回磁盘，事务T2读取同一数据后，T1由于某种原因被撤销，这时T1已修改过的数据恢复原值，T2读到的数据就与数据库中的数据不一致，T2读到的数据就与数据库中的数据不一致，则T2读到的数据为“脏数据”例如：张三的工资为 5000,事务 A 中把他的工资改为 8000,但事务 A 尚未提交。与此同时， 事务 B 正在读取张三的工资， 读取到张三的工资为 8000。 随后，事务 A 发生异常， 而回滚了事务。 张三的工资又回滚为 5000。 最后， 事务 B 读取到的张三工资为 8000 的数据即为脏数据， 事务 B 做了一次脏读。 不可重复读 是指在一个事务内， 多次读同一数据。 在这个事务还没有结束时， 另外一个事务也访问该同一数据。 那么， 在第一个事务中的两次读数据之间， 由于第二个事务的修改， 那么第一个事务两次读到的的数据可能是不一样的。 这样就发生了在一个事务内两次相同的查询读到的数据是不一样的， 因此称为是不可重复读。 例如：在事务 A 中， 读取到张三的工资为 5000， 操作没有完成， 事务还没提交。与此同时， 事务 B 把张三的工资改为 8000， 并提交了事务。 随后， 在事务 A 中，再次读取张三的工资， 此时工资变为 8000。 在一个事务中前后两次读取的结果并不致， 导致了不可重复读 幻读 目前工资为 5000 的员工有 10 人， 事务 A 读取所有工资为 5000 的人数为10 人。 此时， 事务 B 插入一条工资也为 5000 的记录。 这是， 事务 A 再次读取工资为 5000 的员工， 记录为 11 人。 此时产生了幻读 不可重复读的重点是修改：同样的条件， 你读取过的数据， 再次读取出来发现值不一样了。幻读的重点在于新增或者删除：同样的条件， 第 1 次和第 2 次读出来的记录数不一样。避免不一致性的方法和技术就是并发控制。 最常用的技术是封锁技术 并发控制的方式加锁，如乐观锁，悲观锁 数据库事务的隔离级别数据库提供了 4 种隔离级别（由低到高）：这 4 个级别可逐个解决脏读， 不可重复读和幻读这几个问题。 读未提交数据 允许事务读取未被其他事务提交的变更，可能由脏读，不可重复读和幻读的问题比如： 某时刻会话 a 修改了一个数据， 但还未提交， 此时会话 b 读取了该数据， 这是，会话 a 回滚了事务， 这就导致数据出现了不一致状态， 这就是脏读 读以提交数据 允许事务读取已经被其他事务提交的变更， 可以避免脏读， 可能有不可重复读和幻读的问题例如： 某时刻会话 a 的一个事务里查询一个数据， 得到的数据是 1， 这时会话 b 修改了该数据的值为 2， 并提交了， 此时会话 a 的事务又要读取该数据， 这时的数据是 2， 就样就出现了同一个事务内， 读的结果不一样， 这就是不可重复读 可重复读（mysql的默认隔离级别）确保事务可以多次从一个字段中读取相同的值， 在这个事务持续期间， 禁止其他事务对这个字段进行更新， 可以避免脏读和不可重复读， 可能会有幻读 4.可串行化所有事务都一个接一个地串行执行。 可以避免脏读， 不可重复读， 幻读。 MySQL事务的控制语句BEGIN 或 START TRANSACTION： 显示地开启一个事务；COMMIT： 提交事务， 并使已对数据库进行的所有修改称为永久性的；ROLLBACK： 回滚会结束用户的事务， 并撤销正在进行的所有未提交的修改； 涉及锁的问题说下数据库的锁机制， 数据库中都有哪些锁 共享锁： 可共享读，不可共享修改 排他锁： 任何事务必须等到X锁被释放后才能对该页进行访问 产生死锁的四个必要条件： 互斥条件：一个资源每次只能被一个进程使用 请求和保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不可剥夺条件： 进程已获得的资源，在未使用之前，不能强行剥夺 环路等待条件： 若干进程之间形成一种首尾相连的循环等待资源关系 只要系统发生了死锁， 这些条件必然成立， 而只要上述条件之一不满足， 就不会发生死锁 预防死锁 破坏互斥条件 破环不可剥夺条件 破环请求和保持条件 破坏环路等待条件 避免死锁银行家算法 检测死锁 解除死锁 mysql锁的粒度（即锁的级别）MySQL 各存储引擎使用了三种类型（级别） 的锁定机制： 行级锁定， 页级锁定和表级锁定。 表级锁 直接锁定整张表， 在你锁定期间， 其它进程无法对该表进行写操作。 如果你是写锁， 则其它进程则读也不允许。 特点： 开销小， 加锁快； 不会出现死锁； 锁定粒度最大， 发生锁冲突的概率最高， 并发度最低MyISAM 存储引擎采用的是表级锁。有 2 种模式： 表共享读锁和表独占写锁。 加读锁的命令:lock table 表名 read;去掉锁的命令： unlock tables。支持并发插入： 支持查询和插入操作并发进行（在表尾并发插入） 。锁调度机制： 写锁优先。 一个进程请求某个 MyISAM 表的读锁， 同时另一个进程也请求同一表的写锁， MySQL 如何处理呢？ 答案是写进程先获得锁。 行级锁仅对指定的记录进行加锁， 这样其它进程还是可以对同一个表中的其它记录进行操作。 特点： 开销大， 加锁慢； 会出现死锁； 锁定粒度最小， 发生锁冲突的概率最低， 并发度也最高。 InnoDB 存储引擎既支持行级锁， 也支持表级锁， 但默认情况下是采用行级锁 页级锁 一次锁定相邻的一组记录。 开销和加锁时间界于表锁和行锁之间； 会出现死锁； 锁定粒度界于表锁和行锁之间， 并发度一般。 最常用的处理多用户并发访问的方法是加锁。 当一个用户锁住数据库中的某个对象时， 其他用户就不能再访问该对象。 加锁对并发访问的影响体现在锁的粒度上。 比如， (表锁)放在一个表上的锁限制对整个表的并发访问； （页锁）放在数据页上的锁限制了对整个数据页的访问； （行锁） 放在行上的锁只限制对该行的并发访问 乐观锁和悲观所的概念，实现方式和使用场景 悲观锁：锁如其名， 他对世界是悲观的， 他认为别人访问正在改变的数据的概率是很高的， 所以从数据开始更改时就将数据锁住， 直到更改完成才释放 悲观锁可能会造成加锁的时间很长， 并发性不好， 特别是长事务， 影响系统的整体性能。悲观锁的实现方式：悲观锁， 也是基于数据库的锁机制实现。 传统的关系型数据库里边就用到了很多这种锁机制， 比如行锁， 表锁等， 读锁， 写锁等， 都是在做操作之前先上锁。 乐观锁：对世界比较乐观， 认为别人访问正在改变的数据的概率是很低的， 所以直到修改完成准备提交所做的修改到数据库的时候才会将数据锁住，当你读取以及改变该对象时并不加锁， 完成更改后释放。 乐观锁不能解决脏读的问题 乐观锁加锁的时间要比悲观锁短， 大大提升了大并发量下的系统整体性能表现。 乐观锁的实现方式： 大多是基于数据版本（Version） 记录机制实现， 需要为每一行数据增加一个版本标识（也就是每一行数据多一个字段 version） ， 每次更新数据都要更新对应的版本号+1。 工作原理：读出数据时， 将此版本号一同读出， 之后更新时， 对此版本号加一。 此时， 将提交数据的版本信息与数据库表对应记录的当前版本信息进行比对， 如果提交的数据版本号大于数据库表当前版本号， 则予以更新， 否则认为是过期数据， 不得不重新读取该对象并作出更改 涉及索引问题索引的优点 加快数据的检索速度 创建唯一性索引，保证数据库表中每一行数据的唯一性 加速表和表之间的连接 在使用分组和排序字句进行数据检索时，可以显著减少查询中分组和排序的时间 索引的缺点 占用物理空间 当对表中的数据进行增加、增加和修改的时候，索引也要动态维护，降低了数据的维护速度。 性别字段为什么不适合加索引？ 从 B+树原理解释。尽量选择区分度高的字段作为索引,区分度的公式是 count(distinct col)/count(*)， 表示字段不重复的比例， 比例越大我们扫描的记录数越少， 唯一键的区分度是 1， 而一些状态、性别字段可能在大数据面前区分度就是 0。 在性别字段上增加索引， 并不能明显加快检索速度。 有哪些索引唯一索引主键索引聚集索引组合索引 Mysql 的 B+树索引的优点？为什么不用二叉树？B-树和 B+树为什么比红黑树更合适？数据库文件很大，需要存储到磁盘上，索引的结构组织要尽量减少查找过程中磁盘I/O 的存取次数。 高度原因B+树中的每个结点可以包含大量的关键字，这样树的深度降低了，所以任何关键字的查找必须走一条从根结点到叶子结点的路，所有关键字查询的路径长度相同，导致每一个数据的查询效率相当，这就意味着查找一个元素只要很少结点从外存磁盘中读入内存，很快访问到要查找的数据，减少了磁盘 I/O 的存取次数。 磁盘预读原理和局部性原理将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全载入。 建立索引的几大原则 最左前缀匹配原则，mysql会一直向右匹配直到范围查询（&gt;, &lt; , between,like)就停止匹配，范围查询会导致组合索引半生效。 尽量选择区分度高的字段作为索引，某字段的区分度的公式count（distinctcol)/count(*), 表示字段不重复的比例，比例越大，我们扫描的记录数越少，查找匹配的时候可以过滤更多的行，唯一的索引的区分度是1，而一些状态，性别字段可能在大数据面前区分度就是0. 不在索引列做运算或者使用函数 尽量使用扩展索引，不要新建索引 where字句中经常使用的字段应该创建索引，分组字段或者排序字段应该创建字段，两个表的连接字段应该创建索引 like模糊查询中，右模糊查询（eg:321%)会使用索引，而%321和%322%会放弃索引而使用全局扫描。 涉及存储引擎的问题mysql中的MyIsam与InnoDB的区别InnoDB是mysql的默认引擎 事务处理方面 MyISAM强调的是性能，查询的速度比InnoDB类型更快，但是不提供事务支持，InnoDB提供事务支持 外键 MyISAM不支持外键，InnoDB支持外键 锁 MyISAM只支持表级锁，InnoDB支持行级锁和表级锁，默认是行级锁，行锁大幅度提高了多用户并发操作的性能，InnoDB比较适合插入和更新操作比较多的情况，而MyISAM则适合用于频繁查询的情况，另外，InnoDB表的行锁不是绝对的，如果在执行一个sql语句时，Mysql不能确定哟啊扫描的范围，InnoDB表同样会锁全表 全文索引 全文索引(也称全文检索)是目前搜索引擎使用的一种关键技术。它能够利用「分词技术「等多种算法智能分析出文本文字中关键字词的频率及重要性，然后按照一定的算法规则智能地筛选出我们想要的搜索结果MyISAM 支持全文索引， InnoDB 不支持全文索引。innodb 从 mysql5.6 版本开始提供对全文索引的支持 表主键 MyISAM：允许没有主键的表存在。InnoDB：如果没有设定主键，就会自动生成一个 6 字节的主键(用户不可见)。 表的具体行数 MyIsam : select count() from table , 只需独处保存好的行数，因为MyISAM内置了一个计数器，count()时直接从计数器中读。 InnoDB: 不保存表的具体行数，也就是说count(*)要扫描一遍整个表来计算有多少行。 一张表,里面有 ID 自增主键,当 insert 了 17 条记录之后,删除了第 15,16,17 条记录,再把 Mysql 重启,再 insert 一条记录,这条记录的 ID 是 18 还是 15 ？如果表的类型是 MyISAM， 那么是 18。因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件里， 重启MySQL 自增主键的最大 ID 也不会丢失。如果表的类型是 InnoDB， 那么是 15。InnoDB 表只是把自增主键的最大 ID 记录到内存中， 所以重启数据库会导致最大 ID 丢失 关系型数据库和非关系型数据库的区别。非关系型数据库的优势： 性能NOSQL 是基于键值对的， 可以想象成表中的主键和值的对应关系， 而且不需要经过 SQL 层的解析， 所以性能非常高。 可扩展性同样也是因为基于键值对， 数据之间没有耦合性， 所以非常容易水平扩展。 关系型数据库的优势： 复杂查询可以用 SQL 语句方便的在一个表以及多个表之间做非常复杂的数据查询。 事务支持使得对于安全性能很高的数据访问要求得以实现 补充数据库索引失效的集中情况。1.对于组合索引， 不是使用的第一部分， 则不会使用索引 。2.or 语句前后没有同时使用索引。 要想使用 or， 又想让索引生效， 只能将 or 条件中的每个列都加上索引3.如果列类型是字符串， 那一定要在条件中使用引号引起来， 否则不会使用索引 。4.如果 mysql 估计使用全表描述比使用索引快， 则不使用索引。5.在索引列上做运算或者使用函数。6.以“%”开头的 LIKE 查询， 模糊匹配。 数据库表里有 100 万条数据， 想要删除 80 万条数据， 但是因为锁的原因， 删除很慢， 现在想要快速删除怎么办 ？如果需要保留的数据不多， 需要删除的数据很多， 那么可以考虑把需要保留的数据复制到临时表， 然后删除所有数据， 最后复制回去。具体做法是： 先把要保留的数据用 insert into … select from … where …移到另外的表中， truncate table 旧表， 然后再 insert into … select from … ， 这个不存在锁， 比 delete效率高。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>面试知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬币阶梯]]></title>
    <url>%2F2019%2F02%2F21%2F%E7%A1%AC%E5%B8%81%E9%98%B6%E6%A2%AF%2F</url>
    <content type="text"><![CDATA[题目：你总共有 n 枚硬币，你需要将它们摆成一个阶梯形状，第 k 行就必须正好有 k 枚硬币。给定一个数字 n，找出可形成完整阶梯行的总行数。n 是一个非负整数，并且在32位有符号整型的范围 常规硬干12345678910111213141516171819202122232425public int arrangeCoins(int n) &#123; int layer = 1; int layerTmpt = 1; int result = 1; while(result &lt; n) &#123; layerTmpt++; // 说明溢出 if (layerTmpt &lt; 0) &#123; return layer; &#125; result += layerTmpt; // 说明溢出 if (result &lt; 0) &#123; return layer; &#125; layer++; &#125; if(result == n) &#123; return layer; &#125; else &#123; return layer - 1; &#125;&#125; 逆向思维从1往上加会造成溢出，那么我们从n往下减就不存在溢出了。12345678910111213public int arrangeCoins(int n) &#123; int layer = 0; for (int i = 1; i &lt;= n; ++i) &#123; n -= i; if (n &lt; 0) &#123; return layer; &#125; else &#123; layer++; &#125; &#125; return layer;&#125; 数学公式一看就知道等差数列啦，回顾等差数列的求和公式Sn= (a1+an)n/2= (a1+a1+(n-1)d)*n 因为a1=1,d=1,Sn又知道，所以我们求n就很简单啦。 为了区分，下面用x代替n x^2+x = Sn2;so (x+1/2)^2 = Sn2+1/4; 代码： 1234public int arrangeCoins(int n) &#123; return (int) (Math.sqrt((long) n * 2 + 0.25) - 0.5);&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql的执行顺序]]></title>
    <url>%2F2019%2F02%2F20%2Fsql%E7%9A%84q%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[SQL语言不同于其他编程语言的最明显特征是处理代码的顺序。在大多数据库语言中，代码按编码顺序被处理。但在SQL语句中，第一个被处理的子句式FROM，而不是第一出现的SELECT。SQL查询处理的步骤序号： sql 的select语句的完整执行顺序 from字句组装来自不同的数据源的数据 join table连接 on where 字句基于指定条件对纪录进行筛选 group by字句将数据分为多个分组 使用聚集函数进行计算 with{cube|rollup} having 计算所有表达式 select distinct order by 以上每个步骤都会产生一个虚拟表，该虚拟表被用作下一个步骤的输入。这些虚拟表对调用者(客户端应用程序或者外部查询)不可用。只有最后一步生成的表才会会给调用者。如果没有在查询中指定某一个子句，将跳过相应的步骤。 逻辑查询处理阶段简介： 1、 FROM：对FROM子句中的前两个表执行笛卡尔积(交叉联接)，生成虚拟表VT1。 2、 ON：对VT1应用ON筛选器，只有那些使为真才被插入到TV2。 3、 OUTER (JOIN):如果指定了OUTER JOIN(相对于CROSS JOIN或INNER JOIN)，保留表中未找到匹配的行将作为外部行添加到VT2，生成TV3。如果FROM子句包含两个以上的表，则对上一个联接生成的结果表和下一个表重复执行步骤1到步骤3，直到处理完所有的表位置。 4、 WHERE：对TV3应用WHERE筛选器，只有使为true的行才插入TV4。 5、 GROUP BY：按GROUP BY子句中的列列表对TV4中的行进行分组，生成TV5。 6、 CUTE|ROLLUP：把超组插入VT5，生成VT6。 7、 HAVING：对VT6应用HAVING筛选器，只有使为true的组插入到VT7。 8、 SELECT：处理SELECT列表，产生VT8。 9、 DISTINCT：将重复的行从VT8中删除，产品VT9。 10、ORDER BY：将VT9中的行按ORDER BY子句中的列列表顺序，生成一个游标(VC10)。 11、TOP：从VC10的开始处选择指定数量或比例的行，生成表TV11，并返回给调用 联合查询时过滤条件放在ON之后和放在WHERE之后的区别 有两个表，A表和B表，我们经常会通过一些关键字段来联合查询两张表里的数据，如: select * from A left join B on A.bizNo = B.bizNo 如果我们想要在上述条件上再增加一些过滤条件，比如B.name = ‘XXX’。 那么我们有两种写法: 写法1: select * from A left join B on A.bizNo = B.bizNo and B.name = ‘XXX’ 写法2: select * from A left join B on A.bizNo = B.bizNo where B.name = ‘XXX’ 这两种写法的区别在于，过滤条件放在ON的后面是在联合之前就进行过滤，放在WHERE后面是在联合之后的结果集上进行过滤。 如果A的记录在B中都能够查到数据的话，那么两种写法的结果是一样的。 否则会有差别，假如A中有两条记录a1,a2，其中a1可以在B中查到记录，a2无法查到记录。 那么在写法1的情况下，最终的结果集会有两条记录如下: a1 b1 a2 null 在写法2的情况下，最终的结果集只有一条记录: a1 b1]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何判断一个元素在亿级数据中是否存在]]></title>
    <url>%2F2019%2F02%2F20%2F%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0%E5%9C%A8%E4%BA%BF%E7%BA%A7%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%2F</url>
    <content type="text"><![CDATA[前言看到的一道面试题 现在有一个非常庞大的数据，假设全是 int 类型。现在我给你一个数，你需要告诉我它是否存在其中(尽量高效)。 常规实现用hashMap来存放数据，他的写效率都非常高 单测用HashSet，底层也是Hashmap 12345678910111213@Testpublic void hashMapTest() &#123; long start = System.currentTimeMillis(); Set&lt;Integer&gt; hashSet = new HashSet&lt;&gt;(); for (int i = 0; i &lt; 100; i++) &#123; hashSet.add(i); &#125; Assert.assertTrue(hashSet.contains(67)); Assert.assertTrue(hashSet.contains(670)); long end = System.currentTimeMillis(); System.out.println(end-start);&#125; 100没有问题尝试1千万，就内存溢出了 可见在内存有限的情况下我们不能使用这种方式。 实际情况也是如此；既然要判断一个数据是否存在于集合中，考虑的算法的效率以及准确性肯定是要把数据全部 load 到内存中的。 BloomFilter基于上面分析的条件，要实现这个需求最需要解决的是 如何将庞大的数据load到内存中。 而我们是否可以换种思路，因为只是需要判断数据是否存在，也不是需要把数据查询出来，所以完全没有必要将真正的数据存放进去。 伟大的科学家们已经帮我们想到了这样的需求。 BurtonHowardBloom 在 1970 年提出了一个叫做 BloomFilter（中文翻译：布隆过滤）的算法。 它主要就是用于解决判断一个元素是否在一个集合中，但它的优势是只需要占用很小的内存空间以及有着高效的查询效率。 所以在这个场景下在合适不过了。 Bloom Filter 原理下面来分析下它的实现原理 官方的说法是：它是一个保存了很长的二级制向量，同时结合 Hash 函数实现的。 如图所示： 首先需要初始化一个二进制的数组，长度设为 L（图中为 8），同时初始值全为 0 。 当写入一个 A1=1000 的数据时，需要进行 H 次 hash 函数的运算（这里为 2 次）；与 HashMap 有点类似，通过算出的 HashCode 与 L 取模后定位到 0、2 处，将该处的值设为 1。 A2=2000 也是同理计算后将 4、7 位置设为 1。 当有一个 B1=1000 需要判断是否存在时，也是做两次 Hash 运算，定位到 0、2 处，此时他们的值都为 1 ，所以认为 B1=1000 存在于集合中。 当有一个 B2=3000 时，也是同理。第一次 Hash 定位到 index=4 时，数组中的值为 1，所以再进行第二次 Hash 运算，结果定位到 index=5 的值为 0，所以认为 B2=3000 不存在于集合中。 整个的写入、查询的流程就是这样，汇总起来就是： 对写入的数据做 H 次 hash 运算定位到数组中的位置，同时将数据改为 1 。当有数据查询时也是同样的方式定位到数组中。一旦其中的有一位为 0 则认为数据肯定不存在于集合，否则数据可能存在于集合中。 所以布隆过滤有以下几个特点： 只要返回数据不存在，则肯定不存在。 返回数据存在，但只能是大概率存在。 同时不能清除其中的数据。 第一点应该都能理解，重点解释下 2、3 点。 为什么返回存在的数据却是可能存在呢，这其实也和 HashMap 类似。 在有限的数组长度中存放大量的数据，即便是再完美的 Hash 算法也会有冲突，所以有可能两个完全不同的 A、B 两个数据最后定位到的位置是一模一样的。 这时拿 B 进行查询时那自然就是误报了。 删除数据也是同理，当我把 B 的数据删除时，其实也相当于是把 A 的数据删掉了，这样也会造成后续的误报。 基于以上的 Hash 冲突的前提，所以 BloomFilter 有一定的误报率，这个误报率和 Hash 算法的次数 H，以及数组长度 L 都是有关的。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结排序算法]]></title>
    <url>%2F2019%2F02%2F16%2F%E6%80%BB%E7%BB%93%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法的总结 算法分类 比较和非比较的区别常见的快速排序、归并排序、堆排序、冒泡排序等属于比较排序 在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置。 在冒泡排序之类的排序中，问题规模为n，又因为需要比较n次，所以平均时间复杂度为O(n²)。 在归并排序、快速排序之类的排序中，问题规模通过分治法消减为logN次，所以时间复杂度平均O(nlogn)。 比较排序的优势是，适用于各种规模的数据，也不在乎数据的分布，都能进行排序。可以说，比较排序适用于一切需要排序的情况。 计数排序、基数排序、桶排序属于非比较排序针对数组arr，计算arr[i]之前有多少个元素，则唯一确定了arr[i]在排序后数组中的位置。 非比较排序只要确定每个元素之前的已有的元素个数即可，所有一次遍历即可解决。算法时间复杂度O(n)。 非比较排序时间复杂度底，但由于非比较排序需要占用空间来确定唯一位置。所以对数据规模和数据分布有一定的要求。 冒泡排序（bubble sort)冒泡排序是一种简单的排序算法，他重复地走过要排列的数列，一次比较两个元素，如果他们的顺序错误就交换过来 走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成 动图演示 代码演示： 123456789101112131415public int[] bubbleSort(int[] array) &#123; if (array.length==0) return array; for (int i = 0; i &lt; array.length-1; i++) &#123; for (int j = 0; j&lt;array.length-i-1; j++)&#123; if(array[j]&gt;array[j+1]) &#123; int tmp = array[j]; array[j] = array[j+1]; array[j+1] = tmp; &#125; &#125; &#125; return array;&#125; 算法分析: 最佳T(n) = O(n)最差T(n) = O(n^2)平均T(n) = O(n^2) 选择排序表现稳定，因为无论什么数据进去都是O(n^2)的时间复杂度，所以用到他时，数据规模越小越好。 它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 代码实现： 12345678910111213141516public int[] selectSort(int[] array) &#123; if (array.length == 0) return array; for (int i = 0; i &lt; array.length-1; i++) &#123; int minIndex = i; for (int j = i+1; j &lt; array.length; j++) &#123; if (array[minIndex] &gt; array[j]) &#123; minIndex = j; &#125; &#125; int tmp = array[minIndex]; array[minIndex] = array[i]; array[i] = tmp; &#125; return array;&#125; 算法分析：最佳情况：T(n) = O(n2) 最差情况：T(n) = O(n2) 平均情况：T(n) = O(n2) 插入排序工作原理：对于未排序的数据，在已经排序中从后向前扫描，找到相应位置并插入 动图演示： 代码实现： 1234567891011121314151617public static int[] insertSort(int[] array) &#123; if (array.length == 0) &#123; return array; &#125; int current= 0; for (int i = 0; i &lt; array.length-1; i++) &#123; int preIndex = i; current =array[i+1]; while (preIndex&gt;=0&amp;&amp; current&lt;array[preIndex])&#123; array[preIndex+1] = array[preIndex]; preIndex--; &#125; array[preIndex+1] = current; &#125; return array; &#125; 算法分析： 最佳情况：T(n) = O(n) 最坏情况：T(n) = O(n2) 平均情况：T(n) = O(n2) 希尔排序希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破O(n2）的第一批算法之一。 它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。 希尔排序是把记录按下表的一定增量分组，对每组使用直接插入排序算法排序； 随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 动图展示： 代码实现 1234567891011121314151617181920public static int[] shellSort(int[] array) &#123; if (array.length== 0) return array; int len = array.length; int gap = len/2; while (gap&gt;0) &#123; for (int i = gap; i&lt;len; i+=gap) &#123; int tmp = array[i]; int preIndex = i-gap; while (preIndex&gt;=0 &amp;&amp; array[preIndex] &gt; tmp) &#123; array[preIndex+gap] = array[preIndex]; preIndex-=gap; &#125; array[preIndex+gap] = tmp; &#125; gap/=2; &#125; return array;&#125; 算法分析最佳情况：T(n) = O(nlog2 n) 最坏情况：T(n) = O(nlog2 n) 平均情况：T(n) =O(nlog2n) 归并排序和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(n log n）的时间复杂度。 代价是需要额外的内存空间。 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并 动图演示 代码实现： 1234567891011121314151617181920212223242526272829public static int[] mergeSort(int []array) &#123; if (array.length&lt;2) &#123; return array; &#125; int len = array.length; int mid = len/2; int []left = Arrays.copyOfRange(array,0,mid); int []right = Arrays.copyOfRange(array,mid,len); return merge(mergeSort(left),mergeSort(right));&#125;public static int[] merge(int []left, int []right) &#123; int[] result = new int[left.length+right.length]; int l=0; int r = 0; for (int i = 0 ; i &lt; left.length || i&lt;result.length; i++) &#123; if (l&gt;=left.length)&#123; result[i] = right[r++]; &#125;else if (r&gt;=right.length) &#123; result[i] = left[l++]; &#125;else if (left[l]&lt;right[r])&#123; result[i] = left[l++]; &#125;else &#123; result[i] = right[r++]; &#125; &#125; return result;&#125; 算法分析: 最佳情况：T(n) = O(n) 最差情况：T(n) = O(nlogn) 平均情况：T(n) = O(nlogn) 快速排序快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。即每次使一个数达到要求，而且左边的小于他，右边的大于他。 动图展示： 123456789101112131415161718192021public static void quickSort(int []array, int start, int end) &#123; if (start &gt;= end) return ; int pivot = partion(array, start,end); quickSort(array,start,pivot-1); quickSort(array,pivot+1,end);&#125;public static int partion(int[] array, int low, int high) &#123; int pivot = array[low];//枢轴纪录 while (low&lt;high) &#123; while (low&lt;high &amp;&amp; array[high]&gt;pivot) --high; array[low] = array[high];//交换比枢轴小的 while (low&lt;high &amp;&amp; array[low]&lt;pivot) ++low; array[high] = array[low];//交换比枢轴大的 &#125; array[low] = pivot; //返回枢轴的位置 return low;&#125; 算法分析 最佳情况：T(n) = O(nlogn) 最差情况：T(n) = O(n2) 平均情况：T(n) = O(nlogn) 堆排序堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 算法描述：先建立最大堆，然后交换把堆顶交换到尾部，然后再次成立最大堆，循环执行，最后形成从小到大排列 动图展示： 代码展示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static int len;public static void main(String[] args)&#123; int[] array = &#123;1,2,4,6,5,9,8,7,3&#125;; int[] newArray = HeapSort(array); for (int i = 0; i &lt; newArray.length; i++) &#123; System.out.print(array[i]); &#125;&#125;public static int[] HeapSort(int[] array) &#123; len = array.length; if (len &lt; 1) return array; //1.构建一个最大堆 buildMaxHeap(array); //2.循环将堆首位（最大值）与末位交换，然后在重新调整最大堆 while (len &gt; 0) &#123; swap(array, 0, len - 1); len--; adjustHeap(array, 0); &#125; return array;&#125;/** * 建立最大堆 * * @param array */public static void buildMaxHeap(int[] array) &#123; //从最后一个非叶子节点开始向上构造最大堆 for (int i = (len - 1) / 2; i &gt;= 0; i--) &#123; adjustHeap(array, i); &#125;&#125;/** * 调整使之成为最大堆 * * @param array * @param i */public static void adjustHeap(int[] array, int i) &#123; int maxIndex = i; //如果有左子树，且左子树大于父节点，则将最大指针指向左子树 if (i * 2 &lt; len &amp;&amp; array[i * 2] &gt; array[maxIndex]) maxIndex = i * 2; //如果有右子树，且右子树大于父节点，则将最大指针指向右子树 if (i * 2 + 1 &lt; len &amp;&amp; array[i * 2 + 1] &gt; array[maxIndex]) maxIndex = i * 2 + 1; //如果父节点不是最大值，则将父节点与最大值交换，并且递归调整与父节点交换的位置。 if (maxIndex != i) &#123; swap(array, maxIndex, i); adjustHeap(array, maxIndex); &#125;&#125;public static void swap(int[] array, int x,int y) &#123; int temp = array[x]; array[x] = array[y]; array[y] = temp;&#125; 算法分析 最佳情况：T(n) = O(nlogn) 最差情况：T(n) = O(nlogn) 平均情况：T(n) = O(nlogn) 计数排序计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。 然后根据数组C来将A中的元素排到正确的位置。它只能对整数进行排序 动图展示： 代码展示： 123456789101112131415161718192021222324252627public static int[] CountingSort(int[] array) &#123; if (array.length == 0) return array; int bias, min = array[0], max = array[0]; for (int i = 1; i &lt; array.length; i++) &#123; if (array[i] &gt; max) max = array[i]; if (array[i] &lt; min) min = array[i]; &#125; bias = 0 - min; int[] bucket = new int[max - min + 1]; Arrays.fill(bucket, 0); for (int i = 0; i &lt; array.length; i++) &#123; bucket[array[i] + bias]++; &#125; int index = 0, i = 0; while (index &lt; array.length) &#123; if (bucket[i] != 0) &#123; array[index] = i - bias; bucket[i]--; index++; &#125; else i++; &#125; return array; &#125; 算法分析 当输入的元素是n 个0到k之间的整数时，它的运行时间是 O(n + k)。 计数排序不是比较排序，排序的速度快于任何比较排序算法。 由于用来计数的数组C的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。 最佳情况：T(n) = O(n+k) 最差情况：T(n) = O(n+k) 平均情况：T(n) = O(n+k) 桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。 桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排 9.1 算法描述人为设置一个BucketSize，作为每个桶所能放置多少个不同数值（例如当BucketSize==5时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放100个3）； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序； 从不是空的桶里把排好序的数据拼接起来。 注意，如果递归使用桶排序为各个桶排序，则当桶数量为1时要手动减小BucketSize增加下一循环桶的数量，否则会陷入死循环，导致内存溢出。 代码展示： 12345678910111213141516171819202122232425262728293031public static ArrayList BucketSort(ArrayList&lt;Integer&gt; array, int bucketSize) &#123; if (array == null || array.size() &lt; 2) return array; int max = array.get(0); int min = array.get(0); // 找到最大值最小值 for (int i = 0; i &lt; array.size(); i++) &#123; if (array.get(i) &gt; max) max = array.get(i); if (array.get(i) &lt; min) min = array.get(i); &#125; int bucketCount = (max - min) / bucketSize + 1; ArrayList&lt;ArrayList&gt; bucketArr = new ArrayList&lt;&gt;(bucketCount); ArrayList resultArr = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bucketCount; i++) &#123; bucketArr.add(new ArrayList()); &#125; for (int i = 0; i &lt; array.size(); i++) &#123; bucketArr.get((array.get(i) - min) / bucketSize).add(array.get(i)); &#125; for (int i = 0; i &lt; bucketCount; i++) &#123; if (bucketCount == 1) bucketSize--; ArrayList temp = BucketSort(bucketArr.get(i), bucketSize); for (int j = 0; j &lt; temp.size(); j++) resultArr.add(temp.get(j)); &#125; return resultArr;&#125; 算法分析桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 最佳情况：T(n) = O(n+k) 最差情况：T(n) = O(n+k) 平均情况：T(n) = O(n2) 基数排序（Radix Sort）基数排序也是非比较的排序算法，对每一位进行排序，从最低位开始排序，复杂度为O(kn),为数组长度，k为数组中的数的最大的位数； 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。 有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。 最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。 动图展示： 代码： 1234567891011121314151617181920212223242526272829303132 public static int[] RadixSort(int[] array) &#123; if (array == null || array.length &lt; 2) return array; // 1.先算出最大数的位数； int max = array[0]; for (int i = 1; i &lt; array.length; i++) &#123; max = Math.max(max, array[i]); &#125; int maxDigit = 0; while (max != 0) &#123; max /= 10; maxDigit++; &#125; int mod = 10, div = 1; ArrayList&lt;arraylist&gt; bucketList = new ArrayList&lt;arraylist&gt;(); for (int i = 0; i &lt; 10; i++) bucketList.add(new ArrayList()); for (int i = 0; i &lt; maxDigit; i++, mod *= 10, div *= 10) &#123; for (int j = 0; j &lt; array.length; j++) &#123; int num = (array[j] % mod) / div; bucketList.get(num).add(array[j]); &#125; int index = 0; for (int j = 0; j &lt; bucketList.size(); j++) &#123; for (int k = 0; k &lt; bucketList.get(j).size(); k++) array[index++] = bucketList.get(j).get(k); bucketList.get(j).clear(); &#125; &#125; return array;&#125; 算法分析最佳情况：T(n) = O(n * k) 最差情况：T(n) = O(n * k) 平均情况：T(n) = O(n * k) 基数排序有两种方法： MSD 从高位开始进行排序 LSD 从低位开始进行排序 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统相关知识点]]></title>
    <url>%2F2019%2F02%2F16%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[前言为了面试而翻起操作系统这本大book 进程间的通信方式(IPC) 共享内存 消息队列 信号 信号量 套接字 普通管道 有名管道 进程调度方法 先来先服务调度算法 短作业进程优先 优先权调度算法 高响应比优先调度算法 轮转法 多级反馈队列调度 线程间的通信方式锁机制: 互斥锁 条件变量 读写锁 信号量机制： 无名线程信号量和命名线程信号量 信号机制：类似进程间的信号处理机制 线程间的通信目的主要是用于线程同步，所以线程没有想进程通信中的用于数据交换的通信机制 ###操作系统组成部分 进程管理：实质上是对处理机执行“时间”的管理，即如何将CPU真正合理地分配给每个任务。 存储管理：实质是对存储“空间”的管理，主要指对主存的管理； 设备管理：实质是对硬件设备的管理，其中包括对输入输出设备的分配、启动、完成和回收 文件管理：又称为信息管理 程序接口 用户界面 用户态和系统态在什么时候进行切换？ 平时用的都是 64 位系统，那它和 32 位系统相比， 有什么区别和优点？以下三种情况会导致由用户态到内核态的切换 系统调用 异常，如缺页中断 外围设备的终端，当外围设备完成用户请求的操作，回向cpu发出中断操作 1）选址能力不同 2）计算速度不同 选择一个你熟悉的磁盘臂调度算法进行简单描 先来先服务： 这种算法的思想比较容易理解。假设当前磁道在某一位置，依次处理服务队列里的每一个磁道，这样做的优点是处理起来比较简单，但缺点是磁头移动的距离和平均移动距离会很大。 最短寻道时间优先算法：这种算法的本质是利用贪心算法来实现，假设当前磁道在某一位置，接下来处理的是距离当前磁道最近的磁道号，处理完成之后再处理离这个磁道号最近的磁道号，直到所有的磁道号都服务完了程序结束。这样做的优点是性能会优于FIFO算法，但是会产生距离当前磁道较远的磁道号长期得不到服务，也就是“饥饿”现象，因为要求访问的服务的序列号是动态产生的，即各个应用程序可能不断地提出访问不同的磁道号的请求。 scan算法：也就是很形象的电梯调度算法。先按照一个方向(比如从外向内扫描)，扫描的过程中依次访问要求服务的序列。当扫描到最里层的一个服务序列时反向扫描，这里要注意，假设最里层为0号磁道，最里面的一个要求服务的序列是5号，访问完5号之后，就反向了，不需要再往里扫。结合电梯过程更好理解，在电梯往下接人的时候，明知道最下面一层是没有人的，它是不会再往下走的 cscan算法：循环扫描算法，来看一下上一种算法，有什么问题。仔细一看，我们会发现，在扫描到最里面的要求服务的序列时，接着会反向，在接下来的很大一部分时间里，应该是没有要求服务的磁道号的，因为之前已经访问过了。什么意思，就是说从初始磁道号到最里层的一个磁道号之间的所有序列都已经访问过了，所以SCAN会增加等待的时间。为了解决这样的情况，CSCAN算法的思想是，访问完最里面一个要求服务的序列之后，立即回到最外层欲访问磁道。也就是始终保持一个方向。故也称之为单向扫描调度算法。从最里面的一个磁道立即回到最外层欲访问的磁道，这步的距离是两者磁道号差的绝对值。 进程和线程的区别 调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位 并发行：不仅进程之间可以并发执行，同一个进程的多个线程也可以并发执行 拥有资源：进程是拥有资源的一个独立单位， 线程自己基本上不拥有系统资源， 只拥有一点在运行中必不可少的资源（如程序计数器、 一组寄存器和栈),但是它可以与同属一个进程的其他线程共享进程所拥有的全部资源。 进程之间是不能共享地址空间的, 而线程是共享着所在进程的地址空间的 系统开销： 在创建或撤销进程是由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤销线程时的开销。 操作系统的换页方法opt：最佳替换算法（optional replacement）。替换下次访问距当前时间最长的页。opt算法需要知道操作系统将来的事件，显然不可能实现，只作为一种衡量其他算法的标准。 LRU:最近最少使用(Least Recently Used).替换上次使用距离当前最远的页。根据局部性原理：替换最近最不可能 访问到的页。性能最接近OPT，但难以实现。可以维护一个关于访问页的栈或者给每个页添加最后访问的时间标签，但开销都很大 FIFO:先进先出(First In First Out),将页面看做一个循环缓冲区，按循环方式替换。这是实现最为简单的算法，隐含的逻辑是替换驻留在内存时间最长的页。但由于一部分程序或数据在整个程序的生命周期中使用频率很高，所以会导致反复的换入换出 clock: 时钟替换算法（Clock）,给每个页帧关联一个使用位。当该页第一次装入内存或者被重新访问到时，将使用位置为1。每次需要替换时，查找使用位被置为0的第一个帧进行替换。在扫描过程中，如果碰到使用位为1的帧，将使用位置为0，在继续扫描。如果所谓帧的使用位都为0，则替换第一个帧 图解： 操作系统的内存管理计算机存储的层次结构图 内存管理方法内存管理主要包括虚地址、地址变换、内存分配和回收、内存扩充、内存共享和保护等功能。 连续分配存储管理方式连续分配是指为一个用户程序分配连续的内存空间，连续分配有单一连续存储管理和分区式储管理两种方式 单一连续存储管理 在这种管理方式中，内存被分为两个区域：系统区和用户区。应用程序装入到用户区，可使用用户区全部空间。其特点是，最简单，适用于单用户、单任务的操作系统。CP／M和 DOS 2．0以下就是采用此种方式。这种方式的最大优点就是易于管理。但也存在着一些问题和不足之处，例如对要求内存空间少的程序，造成内存浪费；程序全部装入，使得很少使用的程序部分也占用—定数量的内存 分区式存储管理为了支持多道程序系统和分时系统，支持多个程序并发执行，引入了分区式存储管理。分区式存储管理是把内存分为一些大小相等或不等的分区，操作系统占用其中一个分区，其余的分区由应用程序使用，每个应用程序占用一个或几个分区。分区式存储管理虽然可以支持并发，但难以进行内存分区的共享。 分区式存储管理引人了两个新的问题：内碎片和外碎片。内碎片是占用分区内未被利用的空间，外碎片是占用分区之间难以利用的空闲分区(通常是小空闲分区)。 为实现分区式存储管理，操作系统应维护的数据结构为分区表或分区链表。表中各表项一般包括每个分区的起始地址、大小及状态(是否已分配)。 分区式存储管理常采用的一项技术就是内存紧缩(compaction)。 固定分区固定式分区的特点是把内存划分为若干个固定大小的连续分区。分区大小可以相等：这种作法只适合于多个相同程序的并发执行(处理多个类型相同的对象)。分区大小也可以不等：有多个小分区、适量的中等分区以及少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区 优点：易于实现，开销小。缺点：主要有两个：内碎片造成浪费；分区总数固定，限制了并发执行的程序数目。 动态分区动态分区的特点是动态创建分区：在装入程序时按其初始要求分配，或在其执行过程中通过系统调用进行分配或改变分区大小。与固定分区相比较其优点是：没有内碎片。但它却引入了另一种碎片——外碎片。动态分区的分区分配就是寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。分区分配的先后次序通常是从内存低端到高端。动态分区的分区释放过程中有一个要注意的问题是，将相邻的空闲分区合并成一个大的空闲分区。 下面列出了几种常用的分区分配算法： 最先适配法(nrst-fit)：按分区在内存的先后次序从头查找，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，较大的空闲分区可以被保留在内存高端。但随着低端分区不断划分会产生较多小分区，每次分配时查找时间开销便会增大。 下次适配法(循环首次适应算法 next fit)：按分区在内存的先后次序，从上次分配的分区起查找(到最后{区时再从头开始}，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，使空闲分区分布得更均匀，但较大空闲分区不易保留。 最佳适配法(best-fit)：按分区在内存的先后次序从头查找，找到其大小与要求相差最小的空闲分区进行分配。从个别来看，外碎片较小；但从整体来看，会形成较多外碎片优点是较大的空闲分区可以被保留。 最坏适配法(worst- fit)：按分区在内存的先后次序从头查找，找到最大的空闲分区进行分配。基本不留下小空闲分区，不易形成外碎片。但由于较大的空闲分区不被保留，当对内存需求较大的进程需要运行时，其要求不易被满足。 伙伴系统固定分区和动态分区方式都有不足之处。固定分区方式限制了活动进程的数目，当进程大小与空闲分区大小不匹配时，内存空间利用率很低。动态分区方式算法复杂，回收空闲分区时需要进行分区合并等，系统开销较大。伙伴系统方式是对以上两种内存方式的一种折衷方案。伙伴系统规定，无论已分配分区或空闲分区，其大小均为 2 的 k 次幂，k 为整数， l≤k≤m，其中： 2^1 表示分配的最小分区的大小， 2^m 表示分配的最大分区的大小， 通常 2^m是整个可分配内存的大小。假设系统的可利用空间容量为2^m个字， 则系统开始运行时， 整个内存区是一个大小为2^m的空闲分区。在系统运行过中， 由于不断的划分，可能会形成若干个不连续的空闲分区，将这些空闲分区根据分区的大小进行分类，对于每一类具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表。这样，不同大小的空闲分区形成了k(0≤k≤m)个空闲分区链表。 分配步骤：当需要为进程分配一个长度为n 的存储空间时: 首先计算一个i 值，使 2^(i－1) &lt;n ≤ 2^i，然后在空闲分区大小为2^i的空闲分区链表中查找。若找到，即把该空闲分区分配给进程。否则，表明长度为2^i的空闲分区已经耗尽，则在分区大小为2^(i＋1)的空闲分区链表中寻找。 若存在 2^(i＋1)的一个空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于配， 而把另一个加入分区大小为2^i的空闲分区链表中。 若大小为2^(i＋1)的空闲分区也不存在，则需要查找大小为2^(i＋2)的空闲分区， 若找到则对其进行两次分割： 第一次，将其分割为大小为 2^(i＋1)的两个分区，一个用于分配，一个加入到大小为 2^(i＋1)的空闲分区链表中； 第二次，将第一次用于分配的空闲区分割为 2^i的两个分区，一个用于分配，一个加入到大小为 2^i的空闲分区链表中。 若仍然找不到，则继续查找大小为 2^(i＋3)的空闲分区，以此类推。由此可见，在最坏的情况下，可能需要对 2^k的空闲分区进行 k 次分割才能得到所需分区。 与一次分配可能要进行多次分割一样，一次回收也可能要进行多次合并，如回收大小为2^i的空闲分区时，若事先已存在2^i的空闲分区时，则应将其与伙伴分区合并为大小为2^i＋1的空闲分区，若事先已存在2^i＋1的空闲分区时，又应继续与其伙伴分区合并为大小为2^i＋2的空闲分区，依此类推。在伙伴系统中，其分配和回收的时间性能取决于查找空闲分区的位置和分割、合并空闲分区所花费的时间。与前面所述的多种方法相比较，由于该算法在回收空闲分区时，需要对空闲分区进行合并，所以其时间性能比前面所述的分类搜索算法差，但比顺序搜索算法好，而其空间性能则远优于前面所述的分类搜索法，比顺序搜索法略差。 需要指出的是，在当前的操作系统中，普遍采用的是下面将要讲述的基于分页和分段机制的虚拟内存机制，该机制较伙伴算法更为合理和高效，但在多处理机系统中，伙伴系统仍不失为一种有效的内存分配和释放的方法，得到了大量的应用。 页式和段式存储管理前面的几种存储管理方法中，为进程分配的空间是连续的，使用的地址都是物理地址。如果允许将一个进程分散到许多不连续的空间，就可以避免内存紧缩，减少碎片。基于这一思想，通过引入进程的逻辑地址，把进程地址空间与实际存储空间分离，增加存储管理的灵活性。地址空间和存储空间两个基本概念的定义如下： 地址空间：将源程序经过编译后得到的目标程序，存在于它所限定的地址范围内，这个范围称为地址空间。地址空间是逻辑地址的集合。 存储空间：指主存中一系列存储信息的物理单元的集合，这些单元的编号称为物理地址存储空间是物理地址的集合。 根据分配时所采用的基本单位不同，可将离散分配的管理方式分为以下三种：页式存储管理、段式存储管理和段页式存储管理。其中段页式存储管理是前两种结合的产物。 页式存储管理将程序的逻辑地址空间划分为固定大小的页(page)，而物理内存划分为同样大小的页框(page frame)。程序加载时，可将任意一页放人内存中任意一个页框，这些页框不必连续，从而实现了离散分配。该方法需要CPU的硬件支持，来实现逻辑地址和物理地址之间的映射。在页式存储管理方式中地址结构由两部构成，前一部分是页号，后一部分为页内地址w（位移量），如图4所示： 页式管理方式的优点是： 1）没有外碎片，每个内碎片不超过页大比前面所讨论的几种管理方式的最大进步是， 2）一个程序不必连续存放。 3）便于改变程序占用空间的大小(主要指随着程序运行，动态生成的数据增多，所要求的地址空间相应增长)。 缺点是：要求程序全部装入内存，没有足够的内存，程序就不能执行。 段式存储管理在段式存储管理中，将程序的地址空间划分为若干个段(segment)，这样每个进程有一个二维的地址空间。在前面所介绍的动态分区分配方式中，系统为整个进程分配一个连续的内存空间。而在段式存储管理系统中，则为每个段分配一个连续的分区，而进程中的各个段可以不连续地存放在内存的不同分区中。程序加载时，操作系统为所有段分配其所需内存，这些段不必连续，物理内存的管理采用动态分区的管理方法。 在为某个段分配物理内存时，可以采用首先适配法、下次适配法、最佳适配法等方法。 在回收某个段所占用的空间时，要注意将收回的空间与其相邻的空间合并。 段式存储管理也需要硬件支持，实现逻辑地址到物理地址的映射。 程序通过分段划分为多个模块，如代码段、数据段、共享段： –可以分别编写和编译–可以针对不同类型的段采取不同的保护–可以按段为单位来进行共享，包括通过动态链接进行代码共享这样做的优点是：可以分别编写和编译源程序的一个文件，并且可以针对不同类型的段采取不同的保护，也可以按段为单位来进行共享。 总的来说，段式存储管理的优点是：没有内碎片，外碎片可以通过内存紧缩来消除；便于实现内存共享。缺点与页式存储管理的缺点相同，进程必须全部装入内存。 页式和段式管理的区别页式和段式系统有许多相似之处。比如，两者都采用离散分配方式，且都通过地址映射机构来实现地址变换。但概念上两者也有很多区别，主要表现在：1)、需求：是信息的物理单位，分页是为了实现离散分配方式，以减少内存的碎片，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要，而不是用户的需要。段是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了更好地满足用户的需要。一条指令或一个操作数可能会跨越两个页的分界处，而不会跨越两个段的分界处。2)、大小：页大小固定且由系统决定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的。段的长度不固定，且决定于用户所编写的程序，通常由编译系统在对源程序进行编译时根据信息的性质来划分。3)、逻辑地址表示：页式系统地址空间是一维的，即单一的线性地址空间，程序员只需利用一个标识符，即可表示一个地址。分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。4)、段比页大，因而段表比页表短，可以缩短查找时间，提高访问速度。 线程的同步机制 临界区（Critical Section)：通过对多线程的串行化来访问公共资源或一段代码， 速度快， 适合控制数据访问。 在任意时刻只允许一个线程对共享资源进行访问， 如果有多个线程试图访问公共资源， 那么在有一个线程进入后， 其他试图访问公共资源的线程将被挂起， 并一直等到进入临界区的线程离开， 临界区在被释放后， 其他线程才可以抢占。 互斥量（Mutex)：采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限， 因为互斥对象只有一个， 所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享， 还能实现不同应用程序的公共资源安全共享 信号量（semaphore）：它允许多个线程在同一时刻访问同一资源， 但是需要限制在同一时刻访问此资源的最大线程数目。 事件（Event）：通过通知操作的方式来保持线程的同步， 还可以方便实现对多个线程的优先级比较的操作]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>面试知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1-n中有多少个1]]></title>
    <url>%2F2019%2F01%2F30%2F1-n%E4%B8%AD%E6%9C%89%E5%A4%9A%E5%B0%91%E4%B8%AA1%2F</url>
    <content type="text"><![CDATA[题目给定一个整数 n，计算所有小于等于 n 的非负整数中数字 1 出现的个数。 示例: 输入: 13输出: 6解释: 数字 1 出现在以下数字中: 1, 10, 11, 12, 13 。 思路思路一从1到n，每个数再进行拆分，统计1的个数，显然这种方法不妥，当n等于一亿的时候，效率非常低。 思路二这时候只能到discuss上看一下别人的解法，比较震惊，这种解法很有技巧性。 代码 12345678int countDigitOne(int n) &#123; int ones = 0; for (long long m = 1; m &lt;= n; m *= 10) &#123; int a = n/m, b = n%m; ones += (a + 8) / 10 * m + (a % 10 == 1) * (b + 1); &#125; return ones;&#125; 原话 For each position, split the decimal representation into two parts, for example split n=3141592 into a=31415 and b=92 when we’re at m=100 for analyzing the hundreds-digit. And then we know that the hundreds-digit of n is 1 for prefixes “” to “3141”, i.e., 3142 times. Each of those times is a streak, though. Because it’s the hundreds-digit, each streak is 100 long. So (a / 10 + 1) 100 times, the hundreds-digit is 1. Consider the thousands-digit, i.e., when m=1000. Then a=3141 and b=592. The thousands-digit is 1 for prefixes “” to “314”, so 315 times. And each time is a streak of 1000 numbers. However, since the thousands-digit is a 1, the very last streak isn’t 1000 numbers but only 593 numbers, for the suffixes “000” to “592”. So (a / 10 1000) + (b + 1) times, the thousands-digit is 1. The case distincton between the current digit/position being 0, 1 and &gt;=2 can easily be done in one expression. With (a + 8) / 10 you get the number of full streaks, and aa % 10 == 1 tells you whether to add a partial streak. 个人理解 根据1，10.100，1000… 将n分为两部分,分别计算个位，十位，百位，千位上1的个数，如n=3141592 当m=100时，我们计算的是百位上1的个数，他的前缀是3141，又因为5&gt;1，所以共有3142m个1([a+8]/10m , +8的原因是0和1加八处以10没有意义，2以上+8就有进位)，但如果是3141192，百位上的是1，前面是就只有3141m个，还要根据后面有多少个数来决定有多少个1，应该是93个1（(a % 10 == 1) (b + 1)）。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从输入URL到页面加载发生了什么]]></title>
    <url>%2F2019%2F01%2F29%2F%E4%BB%8E%E8%BE%93%E5%85%A5URL%E5%88%B0%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[前言知乎看到的面试题，一开始也答不上来，查阅相关资料写下笔记，顺便当是复习计算机网络了。 总体过程 dns解析 TCP请求 发送HTTP请求 服务器处理请求返回HTTP报文 浏览器解析渲染页面 连接结束 具体过程DNS解析DNS解析的过程就是寻找哪台机器上有你需要资源的过程。当你在浏览器中输入一个地址时，例如www.baidu.com，其实不是百度网站真正意义上的地址。互联网上每一台计算机的唯一标识是它的IP地址，但是IP地址并不方便记忆。用户更喜欢用方便记忆的网址去寻找互联网上的其它计算机，也就是上面提到的百度的网址。所以互联网设计者需要在用户的方便性与可用性方面做一个权衡，这个权衡就是一个网址到IP地址的转换，这个过程就是DNS解析。它实际上充当了一个翻译的角色，实现了网址到IP地址的转换。网址到IP地址转换的过程是如何进行的? 解析过程DNS解析是一个递归查询的过程。上述图片是查找www.google.com的IP地址过程。首先在本地域名服务器中查询IP地址，如果没有找到的情况下，本地域名服务器会向根域名服务器发送一个请求，如果根域名服务器也不存在该域名时，本地域名会向com顶级域名服务器发送一个请求，依次类推下去。直到最后本地域名服务器得到google的IP地址并把它缓存到本地，供下次查询使用。从上述过程中，可以看出网址的解析是一个从右向左的过程: com -&gt; google.com -&gt; www.google.com。但是你是否发现少了点什么，根域名服务器的解析过程呢？事实上，真正的网址是www.google.com.，并不是我多打了一个.，这个.对应的就是根域名服务器，默认情况下所有的网址的最后一位都是.，既然是默认情况下，为了方便用户，通常都会省略，浏览器在请求DNS的时候会自动加上，所有网址真正的解析过程为: . -&gt; .com -&gt; google.com. -&gt; www.google.com.。 TCP连接HTTP协议是使用TCP作为其传输层协议的，当TCP出现瓶颈时，HTTP也会受到影响。略，看另一篇博文。 HTTPS协议HTTP报文是包裹在TCP报文中发送的，服务器端收到TCP报文时会解包提取出HTTP报文。但是这个过程中存在一定的风险，HTTP报文是明文，如果中间被截取的话会存在一些信息泄露的风险。那么在进入TCP报文之前对HTTP做一次加密就可以解决这个问题了。HTTPS协议的本质就是HTTP + SSL(or TLS)。在HTTP报文进入TCP报文之前，先使用SSL对HTTP报文进行加密。从网络的层级结构看它位于HTTP协议与TCP协议之间。 HTTPS过程HTTPS在传输数据之前需要客户端与服务器进行一个握手(TLS/SSL握手)，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL使用了非对称加密，对称加密以及hash等。具体过程请参考经典的阮一峰先生的博客TLS/SSL握手过程。HTTPS相比于HTTP，虽然提供了安全保证，但是势必会带来一些时间上的损耗，如握手和加密等过程，是否使用HTTPS需要根据具体情况在安全和性能方面做出权衡。 HTTP请求HTTP请求报文是由三部分组成：请求行，请求报头，和请求正文。 请求行格式Method Request-URL HTTP-Version CRLF eg:GET index.html HTTP/1.1 常用的方法有: GET, POST, PUT, DELETE, OPTIONS, HEAD。 请求报头请求报头允许客户端向服务器传递请求的附加信息和客户端自身的信息。PS: 客户端不一定特指浏览器，有时候也可使用Linux下的CURL命令以及HTTP客户端测试工具等。常见的请求报头有: Accept, Accept-Charset, Accept-Encoding, Accept-Language, Content-Type, Authorization, Cookie, User-Agent等。 请求正文当使用POST, PUT等方法时，通常需要客户端向服务器传递数据。这些数据就储存在请求正文中。在请求包头中有一些与请求正文相关的信息，例如: 现在的Web应用通常采用Rest架构，请求的数据格式一般为json。这时就需要设置Content-Type: application/json。 服务器处理请求并返回HTTP报文然而然这部分对应的就是后端工程师眼中的HTTP。后端从在固定的端口接收到TCP报文开始，这一部分对应于编程语言中的socket。它会对TCP连接进行处理，对HTTP协议进行解析，并按照报文格式进一步封装成HTTP Request对象，供上层使用。这一部分工作一般是由Web服务器去进行，我使用过的Web服务器有Tomcat, Jetty和Netty等等。 HTTP响应报文也是三部分组成：状态码，响应报头，响应报文 状态码状态码是由3位数组成，第一个数字定义了响应的类别，且有五种可能取值: 1xx：指示信息–表示请求已接收，继续处理。 2xx：成功–表示请求已被成功接收、理解、接受。 3xx：重定向–要完成请求必须进行更进一步的操作。 4xx：客户端错误–请求有语法错误或请求无法实现。 5xx：服务器端错误–服务器未能实现合法的请求。 平时遇到比较常见的状态码有:200, 204, 301, 302, 304, 400, 401, 403, 404, 422, 500 响应报头常见的响应报头字段有: Server, Connection…。 响应报文服务器返回给浏览器的文本信息，通常HTML, CSS, JS, 图片等文件就放在这一部分。 浏览器解析渲染页面浏览器在收到HTML,CSS,JS文件后，它是如何把页面呈现到屏幕上的？下图对应的就是WebKit渲染的过程。 浏览器是一个边解析边渲染的过程。首先浏览器解析HTML文件构建DOM树，然后解析CSS文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。这个过程比较复杂，涉及到两个概念: reflow(回流)和repain(重绘)。DOM节点中的各个元素都是以盒模型的形式存在，这些都需要浏览器去计算其位置和大小等，这个过程称为relow;当盒模型的位置,大小以及其他属性，如颜色,字体,等确定下来之后，浏览器便开始绘制内容，这个过程称为repain。页面在首次加载时必然会经历reflow和repain。reflow和repain过程是非常消耗性能的，尤其是在移动设备上，它会破坏用户体验，有时会造成页面卡顿。所以我们应该尽可能少的减少reflow和repain。 JS的解析是由浏览器中的JS解析引擎完成的。JS是单线程运行，也就是说，在同一个时间内只能做一件事，所有的任务都需要排队，前一个任务结束，后一个任务才能开始。但是又存在某些任务比较耗时，如IO读写等，所以需要一种机制可以先执行排在后面的任务，这就是：同步任务(synchronous)和异步任务(asynchronous)。JS的执行机制就可以看做是一个主线程加上一个任务队列(task queue)。同步任务就是放在主线程上执行的任务，异步任务是放在任务队列中的任务。所有的同步任务在主线程上执行，形成一个执行栈;异步任务有了运行结果就会在任务队列中放置一个事件；脚本运行时先依次运行执行栈，然后会从任务队列里提取事件，运行任务队列中的任务，这个过程是不断重复的，所以又叫做事件循环(Event loop)。 浏览器在解析过程中，如果遇到请求外部资源时，如图像,iconfont,JS等。浏览器将重复1-6过程下载该资源。请求过程是异步的，并不会影响HTML文档进行加载，但是当文档加载过程中遇到JS文件，HTML文档会挂起渲染过程，不仅要等到文档中JS文件加载完毕还要等待解析执行完毕，才会继续HTML的渲染过程。原因是因为JS有可能修改DOM结构，这就意味着JS执行完成前，后续所有资源的下载是没有必要的，这就是JS阻塞后续资源下载的根本原因。CSS文件的加载不影响JS文件的加载，但是却影响JS文件的执行。JS代码执行前浏览器必须保证CSS文件已经下载并加载完毕。 Web优化上面部分主要介绍了一次完整的请求对应的过程，了解该过程的目的无非就是为了Web优化。在谈到Web优化之前，我们回到一个更原始的问题，Web前端的本质是什么。我的理解是: 将信息快速并友好的展示给用户并能够与用户进行交互。快速的意思就是在尽可能短的时间内完成页面的加载，试想一下当你在淘宝购买东西的时候，淘宝页面加载了10几秒才显示出物品，这个时候你还有心情去购买吗？怎么快速的完成页面的加载呢？优雅的学院派雅虎给出了常用的一些手段，也就是我们熟悉的https://developer.yahoo.com/performance/。这34军规实际上就是围绕请求过程进行的一些优化方式。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql的索引原理和运用]]></title>
    <url>%2F2019%2F01%2F29%2FMysql%E7%9A%84%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%92%8C%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[索引的目的在于提高查询，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？ 原理除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。 数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。 磁盘IO和预读寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但要知道一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。 考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。 索引的数据结构B+树 如上图，是一颗b+树，关于b+树的定义可以参见B+树，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 B+树的查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 b+树性质 通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 建立索引的原则 最左前缀匹配原则，非常重要，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 尽量选择分度高的列作为索引 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。 索引列不能参与计算 查询优化神器 - explain命令这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。 慢查询优化基本步骤 先运行看看是否真的很慢，注意设置SQL_NO_CACHE where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高 explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询） order by limit 形式的sql语句让排序的表优先查 了解业务方使用场景 加索引时参照建索引的几大原则 观察结果，不符合预期继续从0分析 索引类型 主键索引 PRIMARY KEY：它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引。注意：一个表只能有一个主键。 唯一索引 UNIQUE：唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。可以通过ALTER TABLE table_name ADD UNIQUE (column); 普通索引 INDEX：这是最基本的索引，它没有任何限制。可以通过ALTER TABLE table_name ADD INDEX index_name (column); 组合索引 INDEX：即一个索引包含多个列，多用于避免回表查询。可以通过ALTER TABLE table_name ADD INDEX index_name(column1,column2, column3); 全文索引 FULLTEXT：也称全文检索，是目前搜索引擎使用的一种关键技术。可以通过ALTER TABLE table_name ADD FULLTEXT (column); 索引一经创建不能修改，如果要修改索引，只能删除重建。可以使用DROP INDEX index_name ON table_name;删除索引。 总结：a. 更新十分频繁的字段上不宜建立索引：因为更新操作会变更B+树，重建索引。这个过程是十分消耗数据库性能的。 b. 区分度不大的字段上不宜建立索引：类似于性别这种区分度不大的字段，建立索引的意义不大。因为不能有效过滤数据，性能和全表扫描相当。另外返回数据的比例在30%以外的情况下，优化器不会选择使用索引。 c. 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。虽然唯一索引会影响insert速度，但是对于查询的速度提升是非常明显的。另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，在并发的情况下，依然有脏数据产生。 d. 多表关联时，要保证关联字段上一定有索引。 e. 创建索引时避免以下错误观念：索引越多越好，认为一个查询就需要建一个索引；宁缺勿滥，认为索引会消耗空间、严重拖慢更新和新增速度；抵制唯一索引，认为业务的唯一性一律需要在应用层通过“先查后插”方式解决；过早优化，在不了解系统的情况下就开始优化。1/29/2019 10:53:40 AM]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之树结构]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%A0%91%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[二叉树 完全二叉树若高度为h，除h层，其他各层（1-h-1）的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树。 满二叉树除叶子节点外，每一个左右节点都有左右子树，且叶子节点都在底层 平衡二叉树又被称作ALV树，也是二叉排序树（BST）性质：空树或者他的左右两个子树的高度差绝对值不超过1，并且左右两个子树都时一颗平衡二叉树。 堆堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆 二叉查找树（BST）二叉查找树的特点： 若任意节点的左子树不空，则左子树上所有结点的 值均小于它的根结点的值； 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树。 没有键值相等的节点（no duplicate nodes）。 平衡二叉树平衡二叉树实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等 红黑树特点： 每个节点非红即黑 根是黑的 每个叶子节点都是黑色的空节点 如果节点是红色的，则他的子节点必须是黑色的（反之不一定 从根节点到叶节点的每条路径必须包含相同数目的黑色节点 应用：TreeMap TreeSet 以及JDK1.8之后的HashMap底层都用到了红黑树 为什么用红黑树简单来说红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。详细了解可以查看看漫画理解 B- B+ B*树 B- 即B树是一种平衡的多路查找树，在文件系统中有所应用，主要用作文件的索引。 B+树的叶子节点链表结构相比B树便于扫库和范围检索。B+树支持区间查询，非常方便，而B树不支持，这是数据库选用B+树的最主要原因 B/树是B+树的变体， B/树分配新节点的概率比B+树低，空间使用率更高。 LSM树(Log-Structured Merge-Trees)B+树的弱点B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，但做范围查询时，会产生大量读随机IO。 对于大量的随机写也一样，举一个插入key跨度很大的例子，如7-&gt;1000-&gt;3-&gt;2000 … 新插入的数据存储在磁盘上相隔很远，会产生大量的随机写IO. 从上面可以看出，低下的磁盘寻道速度严重影响性能（近些年来，磁盘寻道速度的发展几乎处于停滞的状态）. 它的原理是把一颗大树拆分成N棵小树， 它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历所有的小树，但在每颗小树内部数据是有序的。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非阻塞同步和非阻塞异步的区别]]></title>
    <url>%2F2019%2F01%2F20%2F%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%90%8C%E6%AD%A5%E5%92%8C%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%BC%82%E6%AD%A5%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[这两篇文章分析了Linux下的5种IO模型 http://blog.csdn.net/historyasamirror/article/details/5778378 http://blog.csdn.net/hguisu/article/details/7453390 很多人对阻塞 / 非阻塞， 同步 / 异步 的概念理解的不深入，搞不清楚非阻塞和异步IO的区别，笼统的认为非阻塞IO就是异步IO。其实区别很大，编程模型完全不同。 阻塞 / 非阻塞描述的是函数，指访问某个函数时是否会阻塞线程(block，线程进入阻塞状态)。 同步 / 异步描述的是执行IO操作的主体是谁，同步是由用户进程自己去执行最终的IO操作。异步是用户进程自己不关系实际IO操作的过程，只需要由内核在IO完成后通知它既可，由内核进程来执行最终的IO操作。 这两组概念交集在一起参生的非阻塞同步IO和非阻塞异步IO的概念就不难理解。 非阻塞同步IO指的是用户调用读写方法是不阻塞的，立刻返回的，而且需要用户线程来检查IO状态。需要注意的是，如果发现有可以操作的IO，那么实际用户进程还是会阻塞等待内核复制数据到用户进程，它与同步阻塞IO的区别是后者全程等待。 非阻塞异步IO指的是用户调用读写方法是不阻塞的，立刻返回，而且用户不需要关注读写，只需要提供回调操作，内核线程在完成读写后回调用户提供的callback。 这两个概念的不同造成了编程模型的不同。 非阻塞同步IO由于读写方法非阻塞，并且需要用户自己来进行读写，所以每次调用读写方法实际读写的字节数是不确定的，所以需要一个Buffer来保存每次读写的字节状态。更重要的是用户不知道什么时候完成了读写，一般需要用while循环判断Buffer的状态来跟踪读写。 非阻塞异步IO由于是内核线程进行读写，并且在IO完成后会回调用户提供的callback，编程模型就比较简单，用户只需要调用读写，提供回调就可以了，比如 read(filename, callback) select / poll / epoll 从本质上说都是非阻塞同步IO，select会收到IO就绪的状态，然后通知用户去处理IO，实际的IO操作还需要用户等待内核复制操作。 要理解IO就绪和完成的区别。就绪指的是还需要用户自己去处理，完成指的是内核帮助完成了，用户不用关心IO过程，只需要提供回调函数。 理解了非阻塞同步IO和非阻塞异步IO的区别之后，就不难理解Java NIO的设计了。NIO是围绕ByteBuffer来进行读写的，ByteBuffer是一个缓冲区，用来记录读写的状态，通过多次检查ByteBuffer的状态来确定IO是否完成。 Java 1.7的NIO2.0 引入了非阻塞异步IO的概念，编程模型大大简化了。用户只需要关注回调函数即可。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java IO&NIO]]></title>
    <url>%2F2019%2F01%2F20%2FJava-IO-NIO%2F</url>
    <content type="text"><![CDATA[图解 分类IO流的分类： ·按照流的流向分，可以分为输入流和输出流； ·按照操作单元划分，可以划分为字节流和字符流； ·按照流的角色划分为节点流和处理流。 常见面试题 什么是IO流？ 它是一种数据的流从源头流到目的地。比如文件拷贝，输入流和输出流都包括了。输入流从文件中读取数据存储到进程(process)中，输出流从进程中读取数据然后写入到目标文件。 字节流和字符流的区别。 字节流在JDK1.0中就被引进了，用于操作包含ASCII字符的文件。JAVA也支持其他的字符如Unicode，为了读取包含Unicode字符的文件，JAVA语言设计者在JDK1.1中引入了字符流。ASCII作为Unicode的子集，对于英语字符的文件，可以可以使用字节流也可以使用字符流。 Java中流类的超类主要由那些？ java.io.InputStreamjava.io.OutputStreamjava.io.Readerjava.io.Writer FileInputStream和FileOutputStream是什么？ 这是在拷贝文件操作的时候，经常用到的两个类。在处理小文件的时候，它们性能表现还不错，在大文件的时候，最好使用BufferedInputStream (或 BufferedReader) 和 BufferedOutputStream (或 BufferedWriter) 字节流和字符流，你更喜欢使用拿一个？ 个人来说，更喜欢使用字符流，因为他们更新一些。许多在字符流中存在的特性，字节流中不存在。比如使用BufferedReader而不是BufferedInputStreams或DataInputStream，使用newLine()方法来读取下一行，但是在字节流中我们需要做额外的操作。 System.out.println()是什么？ println是PrintStream的一个方法。out是一个静态PrintStream类型的成员变量，System是一个java.lang包中的类，用于和底层的操作系统进行交互。 什么是Filter流？ Filter Stream是一种IO流主要作用是用来对存在的流增加一些额外的功能，像给目标文件增加源文件中不存在的行数，或者增加拷贝的性能。 有哪些可用的Filter流？ 在java.io包中主要由4个可用的filter Stream。两个字节filter stream，两个字符filter stream. 分别是FilterInputStream, FilterOutputStream, FilterReader and FilterWriter.这些类是抽象类，不能被实例化的。 有些Filter流的子类: LineNumberInputStream 给目标文件增加行号 DataInputStream 有些特殊的方法如readInt(), readDouble()和readLine() 等可以读取一个 int, double和一个string一次性的, BufferedInputStream 增加性能 PushbackInputStream 推送要求的字节到系统中 SequenceInputStream的作用？ 这个类的作用是将多个输入流合并成一个输入流，通过SequenceInputStream类包装后形成新的一个总的输入流。在拷贝多个文件到一个目标文件的时候是非常有用的。可用使用很少的代码实现 说说PrintStream和PrintWriter 他们两个的功能相同，但是属于不同的分类。字节流和字符流。他们都有println()方法。 在文件拷贝的时候，那一种流可用提升更多的性能？在字节流的时候，使用BufferedInputStream和BufferedOutputStream。在字符流的时候，使用BufferedReader 和 BufferedWriter 说说管道流(Piped Stream) 有四种管道流， PipedInputStream, PipedOutputStream, PipedReader 和 PipedWriter.在多个线程或进程中传递数据的时候管道流非常有用。 说说File类它不属于 IO流，也不是用于文件操作的，它主要用于知道一个文件的属性，读写权限，大小等信息。注意：Java7中文件IO发生了很大的变化，专门引入了很多新的类来取代原来的基于java.io.File的文件IO操作方式。 说说RandomAccessFile? 它在java.io包中是一个特殊的类，既不是输入流也不是输出流，它两者都可以做到。他是Object的直接子类。通常来说，一个流只有一个功能，要么读，要么写。但是RandomAccessFile既可以读文件，也可以写文件。 DataInputStream 和 DataOutStream有的方法，在RandomAccessFile中都存在。 NIO与AIO学习总结 简介Java NIO 是 java 1.4 之后新出的一套IO接口，这里的的新是相对于原有标准的Java IO和Java Networking接口。NIO提供了一种完全不同的操作方式。 NIO中的N可以理解为Non-blocking，不单纯是New。 它支持面向缓冲的，基于通道的I/O操作方法。 随着JDK 7的推出，NIO系统得到了扩展，为文件系统功能和文件处理提供了增强的支持。 由于NIO文件类支持的这些新的功能，NIO被广泛应用于文件处理。 NIO的特性/NIO与IO区别: 1)IO是面向流的，NIO是面向缓冲区的；2)IO流是阻塞的，NIO流是不阻塞的;3)NIO有选择器，而IO没有。 读数据和写数据方式: 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。 NIO核心组件简单介绍 ChannelsBuffersSelectors 在理解了NIO的基础上，看AIO，区别在于AIO是等读写过程完成后再去调用回调函数。 NIO是同步非阻塞的 AIO是异步非阻塞的 由于NIO的读写过程依然在应用线程里完成，所以对于那些读写过程时间长的，NIO就不太适合。 而AIO的读写过程完成后才被通知，所以AIO能够胜任那些重量级，读写过程长的任务。 小型网络服务器 http://www.importnew.com/21341.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java jvm 相关命令]]></title>
    <url>%2F2019%2F01%2F20%2Fjava-jvm-%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[概述程序运行中经常会遇到各种问题，定位问题时通常需要综合各种信息，如系统日志、堆dump文件、线程dump文件、GC日志等。通过虚拟机监控和诊断工具可以帮忙我们快速获取、分析需要的数据，进而提高问题解决速度。 本文将介绍虚拟机常用监控和问题诊断命令工具的使用方法，主要包含以下工具: jps: 显示系统中所有Hotspot虚拟机进程jstack：显示虚拟机的线程栈信息jstat：收集hotspot虚拟机各方面运行的数据jmap：用于生成虚拟机内存快照信息jinfo：显示虚拟机的配置信息jconsole：一个java GUI监视工具，可以以图表化的形式显示各种数据jvisualvm：一个基于图形化界面的、可以查看本地及远程的JAVA GUI监控工具jhat：用于对JAVA heap进行离线分析的工具Jdb：对core文件和正在运行的Java进程进行实时地调试 jps 命令格式 jps [ options ] [ hostid ] 和Linux的ps类似 常用参数说明 -q 忽略输出的类名、Jar名以及传递给main方法的参数，只输出pid。 -m 输出传递给main方法的参数，如果是内嵌的JVM则输出为null。 -l 输出应用程序主类的完整包名，或者是应用程序JAR文件的完整路径。 -v 输出传给JVM的参数。 -V 输出通过标记的文件传递给JVM的参数（.hotspotrc文件，或者是通过参数-XX:Flags=&lt;filename&gt;指定的文件）。 -J 用于传递jvm选项到由javac调用的java加载器中，例如，“-J-Xms48m”将把启动内存设置为48M，使用-J选项可以非常方便的向基于Java的开发的底层虚拟机应用程序传递参数。 jstack命令(Java Stack Trace)https://bijian1013.iteye.com/blog/2221340 jstathttps://bijian1013.iteye.com/blog/2221351 jmaphttps://bijian1013.iteye.com/blog/2221386 其他https://bijian1013.iteye.com/blog/2221334]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三次握手，四次挥手详解]]></title>
    <url>%2F2019%2F01%2F18%2F%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%EF%BC%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[介绍TCP是一种面向连接的单播协议，在发送数据前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服务器的内存里保存的一份关于对方的信息，如ip地址、端口号等。 TCP可以看成是一种字节流，它会处理IP层或以下的层的丢包、重复以及错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在TCP头部。 TCP提供了一种可靠、面向连接、字节流、传输层的服务，采用三次握手建立一个连接。采用4次挥手来关闭一个连接。 TCP服务模型在了解了建立连接、关闭连接的“三次握手和四次挥手”后，我们再来看下TCP相关的东西。 一个TCP连接由一个4元组构成，分别是两个IP地址和两个端口号。一个TCP连接通常分为三个阶段：启动、数据传输、退出（关闭）。 当TCP接收到另一端的数据时，它会发送一个确认，但这个确认不会立即发送，一般会延迟一会儿。ACK是累积的，一个确认字节号N的ACK表示所有直到N的字节（不包括N）已经成功被接收了。这样的好处是如果一个ACK丢失，很可能后续的ACK就足以确认前面的报文段了。 一个完整的TCP连接是双向和对称的，数据可以在两个方向上平等地流动。给上层应用程序提供一种双工服务。一旦建立了一个连接，这个连接的一个方向上的每个TCP报文段都包含了相反方向上的报文段的一个ACK。 序列号的作用是使得一个TCP接收端可丢弃重复的报文段，记录以杂乱次序到达的报文段。因为TCP使用IP来传输报文段，而IP不提供重复消除或者保证次序正确的功能。另一方面，TCP是一个字节流协议，绝不会以杂乱的次序给上层程序发送数据。因此TCP接收端会被迫先保持大序列号的数据不交给应用程序，直到缺失的小序列号的报文段被填满。 为什么要“三次握手，四次挥手”谢希仁版《计算机网络》中的例子是这样的，“已失效的连接请求报文段” 的产生在这样一种情况下：client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。” 但是在rfc中，也就是 TCP 的协议 RFC，你就会发现里面就讲到了为什么三次握手是必须的——TCP 需要 seq 序列号来做可靠重传或接收，而避免连接复用时无法分辨出 seq 是延迟或者是旧链接的 seq，因此需要三次握手来约定确定双方的 ISN（初始 seq 序列号）。 TCP 协议是不限制一个特定的连接（两端 socket 一样）被重复使用的。 所以这样就有一个问题：这条连接突然断开重连后，TCP 怎么样识别之前旧链接重发的包？——这就需要独一无二的 ISN（初始序列号）机制。 三次握手（A three way handshake）是必须的， 因为 sequence numbers（序列号）没有绑定到整个网络的全局时钟（全部统一使用一个时钟，就可以确定这个包是不是延迟到的）以及 TCPs 可能有不同的机制来选择 ISN（初始序列号）。接收方接收到第一个 SYN 时，没有办法知道这个 SYN 是是否延迟了很久了，除非他有办法记住在这条连接中，最后接收到的那个sequence numbers（然而这不总是可行的）。这句话的意思是：一个 seq 过来了，跟现在记住的 seq 不一样，我怎么知道他是上条延迟的，还是上上条延迟的呢？所以，接收方一定需要跟发送方确认 SYN。假设不确认 SYN 中的 SEQ，那么就只有：1) A –&gt; B SYN my sequence number is X 2) A &lt;– B ACK your sequence number is X SYN my sequence number is Y只有B确认了收到了 A 的 SEQ， A 无法确认收到 B 的。也就是说，只有 A 发送给 B 的包都是可靠的， 而 B 发送给 A 的则不是，所以这不是可靠的连接。这种情况如果只需要 A 发送给 B ，B 无需回应，则可以不做三次握手。 所以，正确的类比应该是这样的：TCP 传递信息可以理解为美国与中国用货船来传货物，但因为一首轮船穿放不下，货物要分开一只只轮船来发货。所以需要一个序列号来识别该货物是第几个，以便到达后将其拼接回原来的货物。因为同一条航道（也就是 tcp连接）上，可能会有多批货物发送（复用 tcp 连接）。发货时，双方需要通知对方这个序列号是从哪里开始（init seq）的，这样才能辨识过来的是不是一个对的货物，以及能拼接成完整的货物。货物运输拼接（tcp）最重要的是可靠性，如果没有用三次握手来确认双方都可以获得对方的 序列号（seq）的话，就无法知道当前航班（连接）中，对的货物序号是怎么样的了。 三次握手详细过程 TCP A TCP B​ CLOSED LISTEN​ SYN-SENT –&gt; –&gt; SYN-RECEIVED​ ESTABLISHED &lt;– &lt;– SYN-RECEIVED​ ESTABLISHED –&gt; –&gt; ESTABLISHED​ ESTABLISHED –&gt; –&gt; ESTABLISHED​Basic 3-Way Handshake for Connection Synchronization ​Figure 7. 在上图第二行中， A 发送了 SEQ 100，标志位是 SYN；第三行，B 发回了 ACK 101 与 SEQ 300，标志位是 SYN 与 ACK（两个过程合并了）。注意，ACK 是101意味着，B 希望接收到 101序列号开始的数据段。第四行，A 返回了空的数据，SEQ 101， ACK 301，标志位为 ACK。至此，双方的开始 SEQ （也就是 ISN）号100与300都被确认接收到了。第五行，开始正式发送数据包，注意的是 ACK 依旧是第四行的301，因为没有需要 ACK 的 SYN 了（第四行已经 ACK 完）。 换个易于理解的视角来看为什么要3次握手。客户端和服务端通信前要进行连接，“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。 从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。 第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。 经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的。之后就可以正常通信了。 每次都是接收到数据包的一方可以得到一些结论，发送的一方其实没有任何头绪。我虽然有发包的动作，但是我怎么知道我有没有发出去，而对方有没有接收到呢？ 而从上面的过程可以看到，最少是需要三次握手过程的。两次达不到让双方都得出自己、对方的接收、发送能力都正常的结论。其实每次收到网络包的一方至少是可以得到：对方的发送、我方的接收是正常的。而每一步都是有关联的，下一次的“响应”是由于第一次的“请求”触发，因此每次握手其实是可以得到额外的结论的。比如第三次握手时，服务端收到数据包，表明看服务端只能得到客户端的发送能力、服务端的接收能力是正常的，但是结合第二次，说明服务端在第二次发送的响应包，客户端接收到了，并且作出了响应，从而得到额外的结论：客户端的接收、服务端的发送是正常的。 四次挥手TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了。这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，等到发送完了所有的数据后，会发送一个FIN段来关闭此方向上的连接。接收方发送ACK确认关闭连接。注意，接收到FIN报文的一方只能回复一个ACK, 它是无法马上返回对方一个FIN报文段的，因为结束数据传输的“指令”是上层应用层给出的，我只是一个“搬运工”，我无法了解“上层的意志”。 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方ACK和FIN一般都会分开发送。 进阶syn flood攻击最基本的DoS攻击就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。syn flood属于Dos攻击的一种。 如果恶意的向某个服务器端口发送大量的SYN包，则可以使服务器打开大量的半开连接，分配TCB（Transmission Control Block）, 从而消耗大量的服务器资源，同时也使得正常的连接请求无法被相应。当开放了一个TCP端口后，该端口就处于Listening状态，不停地监视发到该端口的Syn报文，一 旦接收到Client发来的Syn报文，就需要为该请求分配一个TCB，通常一个TCB至少需要280个字节，在某些操作系统中TCB甚至需要1300个字节，并返回一个SYN ACK命令，立即转为SYN-RECEIVED即半开连接状态。系统会为此耗尽资源。 常见的防攻击方法有： 无效连接的监视释放监视系统的半开连接和不活动连接，当达到一定阈值时拆除这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，而且由于SYN Flood造成的半开连接数量很大，正常连接请求也被淹没在其中被这种方式误释放掉，因此这种方法属于入门级的SYN Flood方法。 延缓TCB分配方法消耗服务器资源主要是因为当SYN数据报文一到达，系统立即分配TCB，从而占用了资源。而SYN Flood由于很难建立起正常连接，因此，当正常连接建立起来后再分配TCB则可以有效地减轻服务器资源的消耗。常见的方法是使用Syn Cache和Syn Cookie技术。 Syn Cache技术系统在收到一个SYN报文时，在一个专用HASH表中保存这种半连接信息，直到收到正确的回应ACK报文再分配TCB。这个开销远小于TCB的开销。当然还需要保存序列号。 Syn Cookie技术Syn Cookie技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS(Maximum Segment Size，最大报文段大小，指的是TCP报文的最大数据报长度，其中不包括TCP首部长度。)、时间等，在收到对方 的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源。 使用SYN Proxy防火墙一种方式是防止墙dqywb连接的有效性后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c, 而真正的服务器回应的序列号为c’, 这样，在每个数据报文经过防火墙的时候进行序列号的修改。另一种方式是防火墙确定了连接的安全后，会发出一个safe reset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。 连接队列在外部请求到达时，被服务程序最终感知到前，连接可能处于SYN_RCVD状态或是ESTABLISHED状态，但还未被应用程序接受。 对应地，服务器端也会维护两种队列，处于SYN_RCVD状态的半连接队列，而处于ESTABLISHED状态但仍未被应用程序accept的为全连接队列。如果这两个队列满了之后，就会出现各种丢包的情形。 查看是否有连接溢出netstat -s | grep LISTEN半连接队列满了 在三次握手协议中，服务器维护一个半连接队列，该队列为每个客户端的SYN包开设一个条目(服务端在接收到SYN包的时候，就已经创建了request_sock结构，存储在半连接队列中)，该条目表明服务器已收到SYN包，并向客户发出确认，正在等待客户的确认包。这些条目所标识的连接在服务器处于Syn_RECV状态，当服务器收到客户的确认包时，删除该条目，服务器进入ESTABLISHED状态。 目前，Linux下默认会进行5次重发SYN-ACK包，重试的间隔时间从1s开始，下次的重试间隔时间是前一次的双倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s, 总共31s, 称为指数退避，第5次发出后还要等32s才知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 63s, TCP才会把断开这个连接。由于，SYN超时需要63秒，那么就给攻击者一个攻击服务器的机会，攻击者在短时间内发送大量的SYN包给Server(俗称SYN flood攻击)，用于耗尽Server的SYN队列。对于应对SYN 过多的问题，linux提供了几个TCP参数：tcp_syncookies、tcp_synack_retries、tcp_max_syn_backlog、tcp_abort_on_overflow 来调整应对。 全连接队列满当第三次握手时，当server接收到ACK包之后，会进入一个新的叫 accept 的队列。 当accept队列满了之后，即使client继续向server发送ACK的包，也会不被响应，此时ListenOverflows+1，同时server通过tcp_abort_on_overflow来决定如何返回，0表示直接丢弃该ACK，1表示发送RST通知client；相应的，client则会分别返回read timeout 或者 connection reset by peer。另外，tcp_abort_on_overflow是0的话，server过一段时间再次发送syn+ack给client（也就是重新走握手的第二步），如果client超时等待比较短，就很容易异常了。而客户端收到多个 SYN ACK 包，则会认为之前的 ACK 丢包了。于是促使客户端再次发送 ACK ，在 accept队列有空闲的时候最终完成连接。若 accept队列始终满员，则最终客户端收到 RST 包（此时服务端发送syn+ack的次数超出了tcp_synack_retries）。 服务端仅仅只是创建一个定时器，以固定间隔重传syn和ack到服务端 命令 netstat -s命令 [root@server ~]# netstat -s | egrep “listen|LISTEN” 667399 times the listen queue of a socket overflowed 667399 SYNs to LISTEN sockets ignored比如上面看到的 667399 times ，表示全连接队列溢出的次数，隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了。[root@server ~]# netstat -s | grep TCPBacklogDrop 查看 Accept queue 是否有溢出ss命令 [root@server ~]# ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 :6379 : LISTEN 0 128 :22 : 如果State是listen状态，Send-Q 表示第三列的listen端口上的全连接队列最大为50，第一列Recv-Q为全连接队列当前使用了多少。 非 LISTEN 状态中 Recv-Q 表示 receive queue 中的 bytes 数量；Send-Q 表示 send queue 中的 bytes 数值。小结 当外部连接请求到来时，TCP模块会首先查看max_syn_backlog，如果处于SYN_RCVD状态的连接数目超过这一阈值，进入的连接会被拒绝。根据tcp_abort_on_overflow字段来决定是直接丢弃，还是直接reset. 从服务端来说，三次握手中，第一步server接受到client的syn后，把相关信息放到半连接队列中，同时回复syn+ack给client. 第三步当收到客户端的ack, 将连接加入到全连接队列。 一般，全连接队列比较小，会先满，此时半连接队列还没满。如果这时收到syn报文，则会进入半连接队列，没有问题。但是如果收到了三次握手中的第3步(ACK)，则会根据tcp_abort_on_overflow字段来决定是直接丢弃，还是直接reset.此时，客户端发送了ACK, 那么客户端认为三次握手完成，它认为服务端已经准备好了接收数据的准备。但此时服务端可能因为全连接队列满了而无法将连接放入，会重新发送第2步的syn+ack, 如果这时有数据到来，服务器TCP模块会将数据存入队列中。一段时间后，client端没收到回复，超时，连接异常，client会主动关闭连接。 参考资料：简单的理解：https://juejin.im/post/5c078058f265da611c26c235 http://blog.51cto.com/changxy/751958]]></content>
      <categories>
        <category>计网</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[简介定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 作用：在我们的系统中，有一些对象其实我们只需要一个，比如说：线程池、缓存、对话框、注册表、日志对象、充当打印机、显卡等设备驱动程序的对象。事实上，这一类对象只能有一个实例，如果制造出多个实例就可能会导致一些问题的产生，比如：程序的行为异常、资源使用过量、或者不一致性的结果。 好处： · 对于频繁使用的对象，可以省略创建对象所花费的时间，对于重量级对象，是非常客观的一笔系统开销； · 由于new操作的次数减少，因而对系统内存的使用频率也会降低，减轻GC压力 为什么不使用全局变量确保一个类只有一个实例呢？ 我们知道全局变量分为静态变量和实例变量，静态变量也可以保证该类的实例只存在一个。只要程序加载了类的字节码，不用创建任何实例对象，静态变量就会被分配空间，静态变量就可以被使用了。 但是，如果说这个对象非常消耗资源，而且程序某次的执行中一直没用，这样就造成了资源的浪费。利用单例模式的话，我们就可以实现在需要使用时才创建对象，这样就避免了不必要的资源浪费。 不仅仅是因为这个原因，在程序中我们要尽量避免全局变量的使用，大量使用全局变量给程序的调试、维护等带来困难。 单例模式的实现通常单例模式在Java语言中，有两种构建方式： 饿汉方式。指全局的单例实例在类装载时构建懒汉方式。指全局的单例实例在第一次被使用时构建。 不管是那种创建方式，它们通常都存在下面几点相似处： 单例类必须要有一个 private 访问级别的构造函数，只有这样，才能确保单例不会在系统中的其他代码内被实例化;instance 成员变量和 uniqueInstance 方法必须是 static 的。 饿汉模式 （线程安全） 123456789public class Singleton&#123; private static Singleton uniqueSingleton = new Singleton(); private Singleton ()&#123; &#125; public static Singleton getInstance() &#123; return uniqueSingleton; &#125;&#125; 所谓 “饿汉方式” 就是说JVM在加载这个类时就马上创建此唯一的单例实例，不管你用不用，先创建了再说，如果一直没有被使用，便浪费了空间，典型的空间换时间，每次调用的时候，就不需要再判断，节省了运行时间。 懒汉式（非线程安全和synchronized关键字线程安全版本 ） 2.1 非线程安全 12345678910111213public class Singleton &#123; private static Singleton uniqueInstance; private Singleton ()&#123; &#125; //没有加入synchronized关键字的版本是线程不安全的 public static Singleton getInstance() &#123; //判断当前单例是否已经存在，若存在则返回，不存在则再建立单例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125; &#125; 所谓 “ 懒汉式” 就是说单例实例在第一次被使用时构建，而不是在JVM在加载这个类时就马上创建此唯一的单例实例。 但是上面这种方式很明显是线程不安全的，如果多个线程同时访问getInstance()方法时就会出现问题。 2.2 线程安全篇 123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125; 我们知道synchronized关键字偏重量级锁。虽然在JavaSE1.6之后synchronized关键字进行了主要包括：为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升。 但是在程序中每次使用getInstance() 都要经过synchronized加锁这一层，这难免会增加getInstance()的方法的时间消费，而且还可能会发生阻塞。我们下面介绍到的 双重检查加锁版本 就是为了解决这个问题而存在的。 2.3 双重锁 1234567891011121314151617181920public class Singleton &#123; //volatile保证，当uniqueInstance变量被初始化成Singleton实例时，多个线程可以正确处理uniqueInstance变量 private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; //检查实例，如果不存在，就进入同步代码块 if (uniqueInstance == null) &#123; //只有第一次才彻底执行这里的代码 synchronized(Singleton.class) &#123; //进入同步代码块后，再检查一次，如果仍是null，才创建实例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次面试]]></title>
    <url>%2F2019%2F01%2F06%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[前言一次没有准备的面试，刚考完试，想放松几天，没想到昨天投的简历这么快就有面试。凉凉。 Java基础1.1 == 和 equals的区别在基本数据类型中== 比较的是值，在对象中比较的是内存地址equals有两种情况1）是没有重写equals方法，相当于==2）重写了equals方法，通常比较两个对象的内容，若想等返回true。 延申：hashCode() 和equals的关系 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）结论：重写equals后必须重写hashCode，确保相同的对象有相同的hashCode。 以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode： 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head fist java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 1.2 HashMap怎么实现https://github.com/Snailclimb/JavaGuide/blob/master/Java%E7%9B%B8%E5%85%B3/HashMap.mdHashSet怎么实现CourrentHashMap 怎么实现线程安全 Jdk的内存模型 程序计数器：较小的内存空间，他的作用看作是当前线程所执行的字节码的行号指示器，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个程序计数器。线程私有。 虚拟机栈：线程私有。描述的是Java方法执行的内存模型：每个方法被执行时都会创建一个栈帧用于存储局部变量表，操作栈、动态连接、方法出口等信息，每一个方法被调用直至到执行完成的过程，就对应着一个栈帧在虚拟机中从入栈到出栈的过程。会抛出StackOverflowError和OutOfMemoryError异常。 本地方法栈：为虚拟机使用到的Native方法服务。 Java堆：被所有线程共享的一块内存区域，在虚拟机启动时创建。唯一目的是存放对象实例，几乎所有的对象实例都在这里分配内存。垃圾收集器管理的主要区域，被叫做GC堆，分为新生代和老年代 方法区：线程共享，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码。别名：nonHeap。 运行时常量池时方法区的一部分 数据库两个引擎的区别MyISAM：默认的MySQL插件式存储引擎，它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。注意，通过更改STORAGE_ENGINE配置变量，能够方便地更改MySQL服务器的默认存储引擎。 InnoDB：用于事务处理应用程序，具有众多特性，包括ACID事务支持。(提供行级锁)一般来说不使用事务的话，请使用MyISAM引擎，使用事务的话，一般使用InnoDB 怎么优化数据库 选取最适用的字段属性MySQL可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小另外一个提高效率的方法是在可能的情况下，应该尽量把字段设置为NOT NULL，这样在将来执行查询的时候，数据库不用去比较NULL值。 、使用连接（JOIN）来代替子查询(Sub-Queries) 慢查询怎么实现 索引怎么分类有没有用过redis 计算机网络TCP的四次挥手 操作系统系统态和用户态的区别 框架Hibernate和MyBatics的区别Mybatis：小巧、方便、高效、简单、直接、半自动化 Hibernate：强大、方便、高效、复杂、间接、全自动化 两者对比总结两者相同点Hibernate与MyBatis都可以是通过SessionFactoryBuider由XML配置文件生成SessionFactory，然后由SessionFactory 生成Session，最后由Session来开启执行事务和SQL语句。其中SessionFactoryBuider，SessionFactory，Session的生命周期都是差不多的。如下图所示： Hibernate优势Hibernate的DAO层开发比MyBatis简单，Mybatis需要维护SQL和结果映射。 Hibernate对对象的维护和缓存要比MyBatis好，对增删改查的对象的维护要方便。 Hibernate数据库移植性很好，MyBatis的数据库移植性不好，不同的数据库需要写不同SQL。 Hibernate有更好的二级缓存机制，可以使用第三方缓存。MyBatis本身提供的缓存机制不佳。 Mybatis优势MyBatis可以进行更为细致的SQL优化，可以减少查询字段。 MyBatis容易掌握，而Hibernate门槛较高。 算法怎么识别一个链表有环top k问题怎么实现排序，最小堆，还有快速排序的方法eg：有1亿个浮点数，如果找出期中最大的10000个？ 1）直接排序最快复杂度为O(nlogn),在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。 2) 局部淘汰法用一个容器保存前10000个数，先让10000个数进容器排序，后续的数在一一与最小的数比较，大于就删去最小的，把新的元素插进去排序，最后得到结果，时间复杂度O(n+m^2)。 3)分治法参考快速排序的思想，将数据分成两堆，如果大的那堆个数N大于10000个，继续分成两堆，将数据分成两堆，如果大的那堆个数N大于10000个，继续分成两堆，如果大的那堆小于1w个，就在小的那堆快速排序一次，找到1w-n的大数字，每次需要的内存空间为10^6*4=4MB,一共需要101次这样的比较。 4）Hash法如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。 5）最小堆法（注意不是最大堆，我们要确认拿到的top是10000个中最小的）首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kmp详解]]></title>
    <url>%2F2018%2F12%2F08%2Fkmp%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[暴力匹配 如果用暴力匹配的思路，并假设现在文本串S匹配到 i 位置，模式串P匹配到 j 位置，则有： 如果当前字符匹配成功（即S[i] == P[j]），则i++，j++，继续匹配下一个字符；如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0。相当于每次匹配失败时，i 回溯，j 被置为0。 理清楚了暴力匹配算法的流程及内在的逻辑，咱们可以写出暴力匹配的代码，如下： 12345678910111213141516171819202122232425262728int ViolentMatch(char* s, char* p)&#123; int sLen = strlen(s); int pLen = strlen(p); int i = 0; int j = 0; while (i &lt; sLen &amp;&amp; j &lt; pLen) &#123; if (s[i] == p[j]) &#123; //①如果当前字符匹配成功（即S[i] == P[j]），则i++，j++ i++; j++; &#125; else &#123; //②如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0 i = i - j + 1; j = 0; &#125; &#125; //匹配成功，返回模式串p在文本串s中的位置，否则返回-1 if (j == pLen) return i - j; else return -1;&#125; kmp优化的是不匹配的时候字符串滑动到哪里。 int kmpSearch(String a,String b, int[] next) { int i = 0; int j = 0; int slen = a.length(); int plen = b.length(); char s[] = a.toCharArray(); char p[] = b.toCharArray(); while (i &lt; slen &amp;&amp; j &lt; plen) { if (j == -1 || s[i]== p[j]) { i++; j++; }else { j = next[j]; } } if (j==plen) { return i-j; } return -1; } next数组是前缀和后缀的最大匹配，运用k = next[k] 缩短寻找时间。 ``` int[] getNext(String s) { int []next = new int[s.length()]; next[0] = -1; int k = -1; int j = 0; char p[] = s.toCharArray(); while (j &lt; p.length-1) { if (k==-1 || p[j] == p[k]) { ++j; ++k; next[j] = k; }else{ k = next[k]; } } for ( int i = 0; i&lt; next.length; i++) { System.out.print(next[i] + &quot; &quot;); } return next; } 参考资料：https://blog.csdn.net/v_july_v/article/details/7041827 最全资料 https://www.bilibili.com/video/av11866460?from=search&amp;seid=12730654434238709250 视频]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程读写文件]]></title>
    <url>%2F2018%2F11%2F09%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[前言无意看到一道多线程的题目，据说是网易的面试题，试着网上的思路code一遍。 题目：一个文件中有10000个数，用Java实现一个多线程程序将这个10000个数输出到5个不用文件中（不要求输出到每个文件中的数量相同）。 要求启动10个线程，两两一组，分为5组。 每组两个线程分别将文件中的奇数和偶数输出到该组对应的一个文件中， 需要偶数线程每打印10个偶数以后，就将奇数线程打印10个奇数，如此交替进行。 同时需要记录输出进度，每完成1000个数就在控制台中打印当前完成数量，并在所有线程结束后，在控制台打印”Done”. 分析分析：可以将10000个数分成5份，每一份（2000个数）对应一组，即两个线程，来分别输出这一份的奇数和偶数，同时声明一个共享变量，用于统计当前所有线程输出的个数，反映记录的输出进度 源码 随机生成10000个数，并输出到文件，然后文件读取到字符串中， ‘ // 生成一个10000个数的文件 PrintWriter pw = new PrintWriter(new FileWriter(new File( “input.txt”), true)); Random random = new Random(); for (int i = 0; i &lt; 10000; i++) { pw.print(Math.abs(random.nextInt()) % 100 + “ “); } pw.flush(); pw.close(); // 读取文件中的数字，分5次读取，每次读取2000个 BufferedReader reader = new BufferedReader(new FileReader( &quot;input.txt&quot;)); String str = reader.readLine(); reader.close(); ‘ 把线程分成五组，然后两个两个执行，首先生成printWriter,再生成printThread，再生成两个线程来start ‘ // 将一行字符串全部解析为10000个数字 String[] strs = str.split(“ “); // 10000个数的索引计数 int j = 0; for (int i = 0; i &lt; 5; i++) { int[] records = new int[2000]; for (int k = 0; k &lt; 2000; k++) { records[k] = Integer.parseInt(strs[j]); j++; } // 定义输出文件 PrintWriter writer = new PrintWriter(new FileWriter(new File( “output” + i + “.txt”)), true); // 定义实现的方法 ThreadGroup group = new ThreadGroup(records, writer); // 开启一队线程 new Thread(group).start(); new Thread(group).start(); }‘ 每个线程共享的静态变量‘// 所有的ThreadGroup类对象共享一个count变量，用来记录输出的总数 private static int count; // 所有的ThreadGroup类对象共享一个锁，用于count变量的同步，任何一个线程需要修改count变量，必须取得该锁 private static Object lock = new Object(); // 用0代表偶数 public static final int EVEN = 0; // -1代表奇数 public static final int ODD = -1; // *以上静态变量，属于整个类所有*‘ run方法一直执行while(print()), 而print() 方法用synchronize锁定，并根据type判断奇偶数，其中锁定lock方便输出信息。当奇偶的位置都超过record.length()的时候，就返回false中止该线程，唤醒其他线程。执行完10次后，就进入等待，唤醒其他线程，等待唤醒。算法很简单，不多说，重点是多线程的运行。 ‘ // 线程实现方法 @Override public void run() { while (print()) ; } private synchronized boolean print() { for (int i = 0; i &lt; 10;) { // 如果奇数和偶数都打印完成以后，就直接停止打印循环，等待该线程自己结束 if (oddPoint &gt;= records.length &amp;&amp; evenPoint &gt;= records.length) { notifyAll(); return false; } // 如果该线程该打印奇数，但奇数已经打印晚了，就直接停止本次10个数的打印， // 同理偶数，等下次切换打印类型后，再开始打印另外一种类型 if ((oddPoint &gt;= records.length &amp;&amp; type == ODD) || (evenPoint &gt;= records.length &amp;&amp; type == EVEN)) { break; } // 判断开始打印偶数 if (type == EVEN) { if (records[evenPoint] % 2 == 0) { i++; writer.print(records[evenPoint] + &quot; &quot;); writer.flush(); // 锁定全局变量方便线程输出后计数 synchronized (lock) { count++; if (count % 1000 == 0) { System.out.println(&quot;当前完成数量：&quot; + count); if (count == 10000) { System.out.println(&quot;Done!&quot;); } } } } // 无论是否是偶数，打印成功一个后，偶数的起始位置都要后移 evenPoint++; } else { // 打印奇数 if (records[oddPoint] % 2 == 1) { i++; writer.print(records[oddPoint] + &quot; &quot;); writer.flush(); // 锁定全局变量方便线程输出后计数 synchronized (lock) { count++; if (count % 1000 == 0) { System.out.println(&quot;当前完成数量：&quot; + count); if (count == 10000) { System.out.println(&quot;Done!&quot;); } } } } // 无论是否是奇数，打印成功一个后，偶数的起始位置都要后移 oddPoint++; } } // 切换打印类型 type = ~type; // 一组中的任一线程打印完后唤醒另一个线程 notifyAll(); try { // 释放锁进入等待状态，等待另一线程打印 wait(); } catch (Exception e) { e.printStackTrace(); } return true; } ‘]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql基本知识]]></title>
    <url>%2F2018%2F09%2F09%2Fmysql%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言复习常用的sql命令，记录常用常考的。 基本命令进入mysql的方法mysql -hlocalhost -uroot -p 然后输入数据库密码就行。 数据库的基本操作use [database]; 进入该数据库show databases; 展示所有的数据库show tables; 展示该数据库下的所有tableshow columns from customers; 展示所有的列show status; 显示广泛的服务器状态信息；show grants; 显示授予用户的安全权限。show error; show warnings; 显示服务器错误或警告help show 查看更多功能 select的基本操作检查单列select prod_name from products; 检查多列select prod_id，prod_name, prod_price from products; 检查所有列select *from products 返回不同的值 distinct关键字select distinct vend_id from products； 限制返回结果 limit关键字select prod_name from products limit 5; 使用完全限定的表名select products.prod_name from products;select products.prod_name from cracourse.products; 排序检索数据按单个列排序select prod_name from products order by prod_name; 按多个列select prod_id, prod_price, prod_name from products order by prod_price,prod_name; 指定方向排序（降序）select prod_id, prod_price, prod_name from products order by prod_price desc; 多个列排序select prod_id, prod_price ,prod_name from products order by prod_price desc, prod_name desc; 与dsec相反的关键字asc，但默认是升序，没什么卵用。 在mysql中大小写不分 过滤数据where搜索过滤select prod_name,prod_price from products where prod_price=2.50;= &gt; &lt; != &lt;= &gt;= between 都可以 不匹配检查select vend_id, prod_name from products where vend_id &lt;&gt;1003; 范围检查select prod_name,prod_price from products where prod_price between 5 and 10; 空值检查select prod_name,prod_price from products where prod_price is null; AND操作符select prod_id,prod_price,prod_name from products where vend_id = 1003 and prod_price &lt;=10; OR 操作符select prod_name,prod_price from products where vend_id =1002 or vend_id =1003; IN操作符select prod_name,prod_price from products where vend_id IN(1002,1003) order by prod_name; Not 操作符select prod_name,prod_price from products where vend_id NOT IN(1002,1003) order by prod_name; 用通配符过滤like操作符%通配符，表示任何字符出现的任意次数select prod_id,prod_name from products where prod_name like ‘jet%’; 下划线通配符select prod_id,prod_name from products where prodname like ‘ ton anvil’; 正则表达式匹配select prod_id,prod_name from products where prod_name regexp ‘1000’ order by prod_name; 拼接select Concat(vend_name,’(‘,vend_country,’)’) from vendors order by vend_name;返回结果：| Concat(vend_name,’(‘,vend_country,’)’) |+—————————————-+| ACME(USA) || Anvils R Us(USA) || Furball Inc.(USA) || Jet Set(England) || Jouets Et Ours(France) || LT Supplies(USA) RTrim(去除空格select Concat(RTrim(vend_name),’(‘,RTrim(vend_country),’)’) from vendors order by vend_name; 使用别名select Concat(RTrim(vend_name),’(‘,RTrim(vend_country),’)’) as vend_title from vendors order by vend_name; 执行算数计算Select prod_id,quantity,item_price from orderitems where order_num = 20005; Select prod_id,quantity,item_price,quantity*item_price AS expanded_price from orderitems where order_num = 20005; 使用函数Upper()select vend_name,Upper(vend_name) as vend_name_upcase from vendors order by vend_name; 日期类函数Date()select cust_id,order_num from orders where Date(order_date) Between ‘2005-09-01’ and ‘2005-09-30’; 数值类函数 汇总数据avg()平均值select avg(prod_price) as avg_price from products;select avg(prod_price) as avg_price from products where vend_id = 1003; count()计数select count(*) as num_cust from customers;select count(cust_email) as num_cust from customers; Max()最大值,MIN()最小值select Max(prod_price) as max_price from products; sum()总计select sum(quantity) as items_ordered from orderitems where order_num =20005; 分组数据select vend_id, count(*) as num_prods from products group by vend_id; 过滤分组having关键字select cust_id,count() as orders from orders group by cust_id having count() &gt;=2; select order_num, sum(quantityitem_price) as ordertotal from orderitems group by order_num having sum(quantityitem_price)&gt;=50; 与order by组合select order_num, sum(quantityitem_price) as ordertotal from orderitems group by order_num having sum(quantityitem_price)&gt;=50 order by ordertotal; 使用子查询select cust_id from orders where order_num in (select order_num from orderitems where prod_id = ‘TNT2’); 连结表联结join创建联结，规定要联结的所有表以及它们如何关联即可。select vend_name,prod_name,prod_price from vendors,products where vendors.vend_id = products.vend_id order by vend_name,prod_name; 没有联结条件的表关系返回的结果为笛卡尔积。select vend_name,prod_name,prod_price from vendors,products order by vend_name,prod_name; 联结多个表(联结越多，性能下降得越厉害）select prod_name,vend_name,prod_price,quantity from orderitems,products,vendors where products.vend_id = vendors.vend_id and orderitems.prod_id = products.prod_id and order_num = 20005; 高级联结使用别名select cust_name,cust_contact from customers as c,orders as o,orderitems as oi where c.cust_id = o.order_num and prod_id = ‘TNT2’; 自联结(使用了子查询）select prod_id,prod_name from products where vend_id = (select vend_id from products where prod_id = ‘DTNTR’); select p1.prod_id,p1.prod_name from products as p1, products as p2 where p1.vend_id = p2.vend_id and p2.prod_id = ‘DINTR’; 外部联结select customers.cust_id,orders.order_num from customers left outer join orders on customers.cust_id = orders.cust_id; select customers.cust_id,orders.order_num from customers right outer join orders on customers.cust_id = orders.cust_id; 带聚集函数的联结 select customers.cust_name,customers.cust_id,count(orders,order_num)As num_ord from customers inner join orders on customers.cust_id = orders.cust_id group by customers.cust_id; 组合查询union 全文本搜索ENGINE=MYISAM; 更新删除数据update customers set cust_email = ‘elmer@fudd.com’ where cust_id = 10005; delete from customers where cust_id = 10006; 删除所有行truncate table 添加列alter table vendors add vend_phone char(20) 删除刚刚添加的列alter table vendors drop column vend_phone; 重命名表rename table customers2 to customers; 使用存储过程DELIMITER//CREATE PROCEDURE productpricing()BEGIN select Avg(prod_price) as priceaverage from products END//DELIMITER;]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 集合类和 JUC集合类]]></title>
    <url>%2F2018%2F09%2F04%2FJava-%E9%9B%86%E5%90%88%E7%B1%BB%E5%92%8C-JUC%E9%9B%86%E5%90%88%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[Java集合包LIst的实现类主要有： LInkedList， ArrayList， Vetcor，Stack（Stack继承自Vector） LInkedList是双向链表的实现的双端队列，他不是线程安全的，只适用于单线程。 ArrayList是数组的实现的队列，它是一个动态数组，也不是线程安全的，只适用于单线程。 Vector是数组实现的矢量队列，他也是一个动态数组，不过和ArrayList不同的是，Vector是支持并发的。 Stack是Vector实现的栈，和Vector一样，他也是线程安全。 Set实现类： HashSet和TreeSet。 HashSet是一个没有重复元素的集合，它通过HashMap实现的，HashSet不是线程安全的。 TreeSet也是一个没有重复元素的集合，其中的元素是有序的，她是通过TreeMap实现的，TreeSet也不是线程安全的，只适用于单线程。 Map的实现类主要有 HashMap，WeakHashMap, Hashtable和TreeMap HashMap是存储“键-值对”的哈希表；它不是线程安全的，只适用于单线程。 WeakHashMap是也是哈希表；和HashMap不同的是，HashMap的“键”是强引用类型，而WeakHashMap的“键”是弱引用类型，也就是说当WeakHashMap 中的某个键不再正常使用时，会被从WeakHashMap中被自动移除。WeakHashMap也不是线程安全的，只适用于单线程。 Hashtable也是哈希表；和HashMap不同的是，Hashtable是线程安全的，支持并发。 TreeMap也是哈希表，不过TreeMap中的“键-值对”是有序的，它是通过R-B Tree(红黑树)实现的；TreeMap不是线程安全的，只适用于单线程。 为了方便，我们将前面介绍集合类统称为”java集合包“。java集合包大多是“非线程安全的”，虽然可以通过Collections工具类中的方法获取java集合包对应的同步类，但是这些同步类的并发效率并不是很高。为了更好的支持高并发任务，并发大师Doug Lea在JUC(java.util.concurrent)包中添加了java集合包中单线程类的对应的支持高并发的类。例如，ArrayList对应的高并发类是CopyOnWriteArrayList，HashMap对应的高并发类是ConcurrentHashMap，等等。 JUC包在添加”java集合包“对应的高并发类时，为了保持API接口的一致性，使用了”Java集合包“中的框架。例如，CopyOnWriteArrayList实现了“Java集合包”中的List接口，HashMap继承了“java集合包”中的AbstractMap类，等等。得益于“JUC包使用了Java集合包中的类”，如果我们了解了Java集合包中的类的思想之后，理解JUC包中的类也相对容易；理解时，最大的难点是，对JUC包是如何添加对“高并发”的支持的！ JUC的集合类List和SetJUC集合包中的List和Set实现类包括: CopyOnWriteArrayList, CopyOnWriteArraySet和ConcurrentSkipListSet。ConcurrentSkipListSet稍后在说明Map时再说明，CopyOnWriteArrayList 和 CopyOnWriteArraySet的框架如下图所示： CopyOrWriteArrayList相当于线程安全的ArrayList，它实现了List接口，CopyOnWriteArrayList是支持高并发的。 CopyOnWriteArraySet相当于线程安全的HashSet，它继承于AbstractSet类。CopyOnWriteArraySet内部包含一个CopyOnWriteArrayList对象，它是通过CopyOnWriteArrayList实现的。 MapJUC集合包中Map的实现类包括: ConcurrentHashMap和ConcurrentSkipListMap。它们的框架如下图所示： ConcurrentHashMap是线程安全的哈希表(相当于线程安全的HashMap)；它继承于AbstractMap类，并且实现ConcurrentMap接口。（jdk7以前用锁分段实现，jdk8用CAS无锁算法实现） ConcurrentSkipListMap是线程安全的有序的哈希表(相当于线程安全的TreeMap); 它继承于AbstractMap类，并且实现ConcurrentNavigableMap接口。ConcurrentSkipListMap是通过“跳表”来实现的，它支持并发。 ConcurrentSkipListSet是线程安全的有序的集合(相当于线程安全的TreeSet)；它继承于AbstractSet，并实现了NavigableSet接口。ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，它也支持并发。 QueueJUC集合包中Queue的实现类包括: ArrayBlockingQueue， LinkedBlockQueue，LinkedBlockDeque，ConcurrentQueue和ConcurrentDeque。 ArrayBlockingQueue是数组实现线程安全的有节的阻塞队列； LinkedBLockingQueue是单向链表实现的（指定大小）阻塞对列，该队列按FIFO排序元素 LinkedBlockingDeque是双向链表实现的(指定大小)双向并发阻塞队列，该阻塞队列同时支持FIFO和FILO两种操作方式。 ConcurrentLinkedQueue是单向链表实现的无界队列，该队列按 FIFO（先进先出）排序元素。 ConcurrentLinkedDeque是双向链表实现的无界队列，该队列同时支持FIFO和FILO两种操作方式。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet 基础学习]]></title>
    <url>%2F2018%2F08%2F31%2FServlet-%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一、WEB应用的发展1.规律 由单机程序向网络程序发展 由CS程序向BS程序发展 2.CS和BS的区别CS Client Server 客户端服务程序，客户端由程序员开发，用户需要安装（安全性高，但 BS Browser Server 浏览器服务程序，不需要单独开发及安装 二、 Servlet介绍1.服务器如何给浏览器返回网页？1）返回静态网页 百度百科、新闻等 内容不变，任何人看都一样 服务器保存的一个HTML，访问时直接返回它 2）返回动态网页 微博、淘宝 每个人看的内容有差别 服务器保存一个组件，用它来拼一个动态网页 在Java项目中，这个组件就是Servlet 组件：就是满足规范的对象 2.Servlet具备的特征 Servlet是存储在服务器上的 Servlet满足sun的规范 它可以拼动态资源（网页、图片等） 可以处理HTTP协议 3.什么是Servlet 是sun推出的用来在服务器端处理HTTP协议的组件 三、服务器1.名称 Java服务器 WEB服务器 Java WEB服务器 Servlet容器 2.本质 是一个软件：能够运行Java项目的软件 和浏览器相对应、平级 3.举例 Tomcat JBoss WebLogic WebSphere 四、如何使用tomcat1.单独使用1)配置JAVA_HOME tomcat依赖于Java 2)下载及安装 在apache官网下载 直接解压缩(释放)即可，这是绿色免安装软件 3)启动tomcat Linux：打开/tomcat/bin目录，输入./startup.sh window：打开/tomcat/bin目录，双击startup.bat 给目录加权限：chmod +x *sh 4)访问tomcat 打开浏览器，输入http://localhost:8080 5)关闭tomcat Linux：打开/tomcat/bin目录，输入./shutdown.sh windows：打开/tomcat/bin目录，双击shutdown.bat 2.用Eclipse管理tomcat(开发时) 配置失败需要重来： window-&gt;preference-&gt;server-&gt;runtime 选择tomcat点击remove Eclipse左侧点击Servers项目将其删除 五、Servlet开发步骤1.创建WEB项目 WEB项目有标准的WEB目录： webapp/WEB-INF/web.xml 2.导入jar包1)用maven搜javaee 在搜索结果中选择javaee-api.jar 2)使用tomcat内置的jar包 右键项目-&gt;properties-&gt;targeted runtimes-&gt;勾选tomcat-&gt;apply 3.开发Servlet 继承于HttpServlet 间接实现了Servlet接口(sun的规范) 4.配置Servlet 在web.xml中加以配置 5.部署项目 在Servers下点击tomcat 右键点击Add and Remove 弹出框中将项目从左侧移动到右侧 启动tomcat 部署：就是拷贝 6.访问Servlet http://localhost:8080/servlet1/ts 源代码： https://github.com/8311431967/practiceCode/tree/master/src/servlet/servlet 六、代码执行过程及错误 补充一、端口占用错误1.出现问题的情况 报错：Address already in user,JVM_BIND:8080 2.原因及解决方案1)tomcat启动了2次，造成端口冲突 打开/tomcat/bin目录，执行shutdown命令，强制关闭它 2)其他软件占用了此端口(Oracle) 修改tomcat的端口 打开tomcat配置文件server.xml 在65行修改port=”8080”，建议改为8088、8089等 注意：关闭tomcat时修改，然后重新启动 在Servers项目下可以找到server.xml配置文件 一、HTTP协议1.什么是HTTP协议 就是一个规范(w3c) 规定了：浏览器和服务器如何通信及数据格式 2.如何通信 建立连接 发送请求 接收响应 关闭连接 3.数据格式1)请求数据(浏览器向服务器发送的数据) 请求行：请求的基本信息 消息头：请求数据的描述信息 实体内容：请求的业务数据 2)响应数据(服务器向浏览器发送的数据) 状态行：响应的基本信息 消息头：响应数据的描述信息 实体内容：响应的业务数据 4.对开发的要求1)不需要管的地方 通信的过程已经由浏览器和服务器实现了 请求数据的组装由浏览器实现了 响应数据的组装由服务器实现了 2)需要处理的地方 请求的业务数据由开发者提供 响应的业务数据由开发者提供 使用request处理请求数据，使用response处理响应数据 二、注册案例源代码： https://github.com/8311431967/practiceCode/tree/master/src/servlet/servlet2 三、Servlet运行原理 四、请求方式1.什么是请求方式 浏览器向服务器发送数据的方式 包括很多种方式，需要掌握的是GET和POST 2.GET和POST方式的区别1)GET 采用路径传参，参数在传递过程中可见(地址栏) 隐私性差 传参能力有限，只能传少量参数 所有的请求默认都是GET请求 2)POST 采用实体内容传参，参数在传递过程中不可见 隐私性好 实体内容专门用来传参，大小不受限制 在form上加method=”post” a、get是用来从服务器上获取数据，而post是用来向服务器传递数据； b、get将表单中数据按照variable=value的形式，添加到action所指向的URL后面，并且两者用”？”连接，变量之间用”&amp;”连接；而post是将表单中的数据放在form的数据体中，按照变量与值对应的方式，传递到action所指定的URL。 c、get是不安全的，因为在传输过程中，数据是被放在请求的URL中;而post的所有操作对用户来说都是不可见的。 d、get传输的数据量小，这主要应为受url长度限制;而post可以传输大量的数据，所有上传文件只能用post提交。 e、get限制form表单的数据集必须为ASCII字符；而post支持整个IS01 0646字符集。 f、get是form表单的默认方法。 3.如何选择请求方式 一般查询时使用GET请求，因为查询条件一般比较少 一般保存时使用POST请求，因为保存的数据一般较多 五、乱码解决方案 六、案例1.查询员工源代码： https://github.com/8311431967/practiceCode/tree/master/src/servlet/EmpManager 2.增加员工 补充1.什么是JavaBean 满足如下规范的类： 有package 有默认构造器 实现序列化接口 有get/set方法 一、重定向1.重定向在增加员工中的应用1response.sendRedirect(String url); 2.重定向的作用及原理在重定向的过程中，影响浏览器做出动作的关键点即响应中的状态码及Location这个消息头。302状态就像一道命令一样，使得浏览器做出新的一次请求，而请求的地址会从头信息中查找。由于这个新的请求动作是由浏览器发出的，所以浏览器的地址栏上的地址会变成Location消息头中的地址。 二、路径1.路径是什么 2.如何获取路径 项目名：req.getContextPath() Servlet路径：req.getServletPath() 绝对路径：req.getRequestURI() 完整路径：req.getRequestURL() 3.URI(Uniform Resource Identifier)和URL(Uniform Resource Locator)的区别1)狭义的理解(Java项目) URI(统一资源标识符)是绝对路径，而URL是完整路径 URL(全球资源定位器)包含了URI 2)广义的理解(Web项目) * URI是资源的名字 URL是资源的真名 URI包含了URL 真名只有一个，名字可以有多个 4.Servlet访问路径的配置方案1)精确匹配(/hello) 只有这一个路径可以访问此Servlet 此Servlet只能处理一个请求 2)通配符(/*) 所有的路径都可以访问此Servlet 此Servlet能处理所有请求 3)后缀(*.abc) 所有以abc为后缀的路径都可以访问此Servlet 此Serlvet能处理多个请求 4)用1个Servlet处理多个请求的方案 5)通配符和后缀的典型应用场景 Servlet容器如何创建Servlet对象、如何为Servlet对象分配、准备资源、如何调用对应的方法来处理请求以及如何销毁Servlet对象的整个过程即Servlet的生命周期。 1.生命周期相关方法的调用顺序 ###阶段一、实例化123456789&lt;servlet&gt; &lt;servlet-name&gt;someServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;test/SomeServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;someServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 配置文件中的load-on-startup节点用于设置该Servlet的创建时机。当其中的值大于等于0时，表示容器在启动时就会创建实例小于0时或没有指定时，代表容器在该Servlet被请求时再执行创建正数的值越小，优先级越高，应用启动时就越先被创建。 ###阶段二、初始化 在初始化阶段，init（）方法会被调用。这个方法在javax.servlet.Servlet接口中定义。其中，方法以一个ServletConfig类型的对象作为参数。ServletConfig对象由Servlet引擎负责创建，从中可以读取到事先在web.xml文件中通过节点配置的多个name-value名值对。ServletConfig对象还可以让Servlet接受一个ServletContext对象。一般情况下，init方法不需要编写，因GenericServlet已经提供了init方法的实现，并且提供了getServletConfig方法来获得ServletConfig对象。注：init方法只被执行一次。 ###阶段三、就绪 Servlet被初始化以后就处于能够响应请求的就绪状态。每个对Servlet的请求由一个ServletRequest对象代表，Servlet给客户端的响应由一个ServletResponse对象代表。当客户端有一个请求时，容器就会将请求与响应对象转给Servlet，以参数的形式传给service方法。service方法由javax.servlet.Servlet定义，由具体的Servlet实现。 ###阶段四、销毁 Servlet容器在销毁Servlet对象时会调用destroy方法来释放资源。通常情况下Servlet容器停止或者重新启动都会引起销毁Servlet对象的动作，但除此之外，Servlet容器也有自身管理Servlet对象的准则，整个生命周期并不需要人为进行干预。 2.config和context的联系和区别 3.ServletConfig 4.ServletContext 一、context的特殊用法1.使用场景 之前使用config和context读取的都是web.xml中配置的常量 有时候我们需要存取的可能是变量 context支持存取变量，给多个Servlet共用 2.案例 给软件做一个统计流量(访问量)的功能 流量是一个变量，无论访问哪个Servlet，流量+1 二、线程安全问题1.什么时候会出现线程安全问题 多人同时修改同一份数据时有此问题 局部变量存储在栈里，每个线程有自己的栈帧，没有问题 成员变量存储在堆里，所有线程共享这个数据，可能有问题 多个人同时修改成员变量 2.如何解决线程安全问题 加锁 三、HttpServlet介绍(了解) sun这样设计是为了让开发者有更多选择的空间 制定的这种规范在实际使用中发现，并不会扩展为HTTP协议之外，所以有了过度设计的缺陷，也为在编写HTTP协议的Web应用时添加了一些不必要的操作。 四、JSPJSP（Java Server Page）是Sun公司制定的一种服务器端动态页面技术的组件规范，以“.jsp”为后缀的文件中既包含HTML静态标记用于表现页面，也包含特殊的代码，用于生成动态内容。JSP作为简化Servlet开发的一种技术，实质上最终依然要转变为Servlet才可能运行，只不过这个转变过程由Servlet容器来完成。所以遵循JSP的编写规范才能使得JSP转变为需要的Servlet。 JSP页面中的Java代码###JSP表达式（方便输出）1234&lt;%=3+5%&gt;&lt;%=add()%&gt;&lt;%=xx.getName()%&gt;&lt;%=xx.getName()+“abc”%&gt; 这种形式的Java代码在转译成Servlet时，会成为service（）方法中使用out.print语句的输出。1234out.print(3+5);out.print(add());out.print(xx.getName());out.print(xx.getName()+“abc”)); ###JSP小脚本（完成相对较长的逻辑运算）12345678910111213table&gt;&lt;%List&lt;User&gt; allUser = (List&lt;User&gt;)request.getAttribute(“users“);for(User u : allUser)&#123;%&gt; &lt;tr&gt; &lt;td&gt; &lt;%=u.getId()%&gt; &lt;/td&gt; &lt;td&gt; &lt;%=u.getName()%&gt; &lt;/td&gt; &lt;/tr&gt;&lt;% &#125;%&gt;&lt;/table&gt; 123456789101112public void service(…)&#123;out.write(“&lt;table&gt;”);List&lt;User&gt; allUser = (List&lt;User&gt;)request.getAttribute(“users“);for(User u : allUser)&#123;out.write(“&lt;tr&gt; &lt;td&gt;”);out.print(u.getId());out.write(“&lt;/td&gt;&lt;td&gt;”);out.print(u.getName());out.write(“&lt;/td&gt;&lt;/tr&gt;”); &#125; out.write(“&lt;/table&gt;”);&#125; ###JSP声明（添加属性或方法）12345&lt;%! public void fun()&#123; //… 方法体&#125;%&gt; 1234567public class XXX_JSP extends JSPBase&#123;public void fun()&#123; // … 方法体 &#125; public void service(… …)&#123;&#125;&#125; ###JSP指令 ####page指令 #####导包123&lt;%-- 导包 --%&gt;&lt;%@ page import=“java.util.*“%&gt;&lt;%@ page import=“java.util.*,java.sql.*“%&gt; #####设置response.setContentType（）方法的参数值12&lt;%-- 设置response.setConentType方法的参数值 --%&gt;&lt;%@ page contentType=“text/html;charset=utf-8“%&gt; #####设置容器读取该文件时的解码方法12&lt;%-- 设置容器读取该文件时的解码方式 --%&gt;&lt;%@ page pageEncoding=“UTF-8“%&gt; ####include指令1&lt;%@ include file=“header.html” %&gt; JSP运行原理 隐含(内置)对象什么是隐含对象 就是在JSP上可以直接使用的对象 这些对象是在service方法一开始就声明的 有哪些隐含对象1) request HttpServletRequest 2) response HttpServletResponse 3) out JSPWriter 等价于PrintWriter 4) config ServletConfig 5) application ServletContext 6) exception Throwable 是JSP生成的Servlet所报的错 7) session HttpSession 8) page Object 相当于this 9) pageContext PageContext 管理者，引用了其他8个隐含对象 总结 上述9个对象的名字是固定的 它们都可以在JSP上直接使用 使用的例子12&lt;%String user = request.getParameter(&quot;user&quot;);%&gt;&lt;%=request.getParameter(&quot;user&quot;)%&gt; 一、开发模式1. Model 1 使用一个组件(Servlet/JSP)处理请求 缺点：该组件将java和HTML高度耦合在一起 2. Model 2(MVC) 使用2个组件协同处理请求 优点：将java和HTML代码解耦 二、转发和重定向1.它们的相同点 都是用来解决web组件之间的跳转问题 web组件：Servlet/JSP 2.它们的区别 3.它们的一般使用场景 一般查询时从查询Servlet转发到查询JSP 一般增加、修改、删除(Servlet)后重定向到查询(Servlet) 三、EL和JSTL1.作用 2.案例 3.JSTL运行原理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对婚姻，楼市，资本，文化的一些看法]]></title>
    <url>%2F2018%2F08%2F04%2F%E5%AF%B9%E5%A9%9A%E5%A7%BB%EF%BC%8C%E6%A5%BC%E5%B8%82%EF%BC%8C%E8%B5%84%E6%9C%AC%EF%BC%8C%E6%96%87%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9C%8B%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言近日发生的事情比较多，接触的信息也比较杂乱，思考也比较频繁，决定写一下当下感触。 婚姻的变迁从古代的拜堂成亲到现代的一夫一妻，恋爱和婚姻像其他文化一样，都是被塑造出来的社会关系。而一夫一妻制从某种程度上，保证屌丝也能也有娶上老婆的机会，但随着工业化，科技现代化的推进，结婚也成了一个人的累赘。听起以前我妈那个年代，彩礼也只是一头猪，到现在的车，房子的首付，甚至是房子。 知乎上有个有趣的提问，为什么男人越来越不想结婚，有个高票回答。男人觉得结婚吃亏所以不想结婚，女人也觉得结婚吃亏不想结婚，说明结婚内耗太大。 虚高的房价恋爱和婚姻是被塑造出来的一种社会关系，在资本的眼里，，就只能被资本改造和裹挟，成了绑架大众的工具。 资本先利用舆论把房价炒上天，然后告诉我们，没房没资格结婚。依靠着大众对婚姻的向往，逼迫年轻人掏空父母，用六个钱包，来接盘虚高的房价。我姐今年买房，首付不够，到处借钱，已经不止是六个钱包了，挤入了婚姻的门槛，却又过上了省吃俭用的生活。 仍旧是将婚姻和家庭作为人质，依靠着大众对婚姻和家庭的责任，资本逼迫着大众接受996，繁重而苦役的劳作。最后，到35岁的时候，资本还会将这些失去剥夺价值的劳工扫地出门，近来连续跳楼的中年程序员，给我敲响了警钟，要给自己留后路。 有能力接盘的被收割，而没有能力接盘，同样无法逃脱。在资本主导的舆论下，他们（可能就是我）要一辈子在社会的歧视下单独过活。更糟糕的是，现实里并不是看穿这场阴谋和骗局就能解决问题，钻石的营销手段广为人知，各种金融骗局的手段，也被暴露在阳光下，但人们看到了问题所在，却被利益驱使，主动迎合骗局，自愿地参与了这样的狂欢。 社会关系和观念的改造一旦完成，人们自发的成了体制的一部分，自发的维护着这个体系。 资本改造过后的婚姻婚姻和爱情已经被改造，大面积的表现出对资本的崇拜，对消费的依赖，对成员的绑架和裹挟。没钱不配结婚，没钱不配生孩子，没钱不配有家庭。 社会关系带给人们的痛苦，最终会驱使人们放弃社会关系。 发达国家广泛的不婚不育，慢性自杀，是生命自发的反抗。 日本和韩国的不婚率和不育率将是我国的未来。 结语什么人才会发这样的牢骚呢，对，就是我这样的穷人。老家的今年房价由于碧桂园的强势介入，上限已经突破了8000元/平方米(垃圾五线城市），哥又买了房，又刚生了小孩，两个小孩，吃力。而听师兄说他们认识的几个技术大牛，都没能留在一线城市，去了二三线城市，玩技术的终究是玩不过玩资本的，我又何去何从,怀疑人生。8/4/2018 1:18:12 AM]]></content>
      <categories>
        <category>杂文</category>
      </categories>
      <tags>
        <tag>感触</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的反射]]></title>
    <url>%2F2018%2F05%2F24%2FJava%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[什么是反射反射是动态加载对象，并对对象进行剖析。在运行状态中，对于任意的一个类，都能够知道这个类的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法，这种动态获取信息以及动态调用对象方法的功能成为Java反射机制。 反射的基本操作获取类中的所有方法1234567891011121314151617181920212223242526272829303132public class Student &#123; private long id; private String name; public long getId() &#123; return id; &#125; public void setId(long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public static void main(String[] args) &#123; try &#123; Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;); Method[] methods = clz.getMethods(); for (Method method : methods) &#123; System.out.println(&quot;方法名：&quot; + method.getName()); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Class.forName(“reflect.Student”)：初始化指定的类 clz。getMethods():获取勒种所有的方法 如果只需要获取加载类中的方法，不要父类的方法，可以使用下面的代码： `Method[] methods = clz.getDeclaredMethods();` Method是方法类，可以获取方法相关的信息，除了我们上面的方法名称，我们还可以获取其他的一些信息，比如： 方法返回类型：method.getReturnType().getName() 方法修饰符：Modifier.toString(method.getModifiers()) 方法参数信息： method.getParameters() 方法上的注解： method.getAnnotations() 等等……. 通过反射来调用方法12345678910try &#123; Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;); Student stu = (Student) clz.newInstance(); System.out.println(stu.getName()); Method method = clz.getMethod(&quot;setName&quot;, String.class); method.invoke(stu, &quot;kun&quot;); System.out.println(stu.getName()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; 通过class的newInstance()方法构造一个Student对象，然后调用getName()方法，这个时候输出的是null,然后通过方法名获取到setName方法，通过invoke调用方法，传入参数，然后调用getName()方法可以看到输出的就是我们设置的值“kun”. 获取类中的所有属性12345Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;);Field[] fields = clz.getFields();for (Field field : fields) &#123; System.out.println(&quot;属性名：&quot; + field.getName());&#125; clz.getFields()只能获取public的属性，包括父类的。 如果需要获取自己声明的各种字段，包括public，protected，private得用clz.getDeclaredFields() Field是属性类，可以获取属性相关的信息，比如： 属性类型：field.getType().getName() 属性修饰符：Modifier.toString(field.getModifiers()) 属性上的注解： field.getAnnotations() 等等……. 通过clz.getDeclaredField(“name”);获取name属性，调用get方法获取属性的值，第一次肯定是没有值的，然后调用set方法设置值，最后再次获取就有值了，在get之前有field.setAccessible(true);这个代码，如果不加的话就会报下面的错误信息： &apos;Class fs.Test can not access a member of class fs.Student with modifiers &quot;private&quot; &apos; setAccessible(true);以取消Java的权限控制检查，让我们在用反射时可以访问访问私有变量 反射的优缺点优点 反射提高了程序的灵活性和扩展性,在底层框架中用的比较多，业务层面的开发过程中尽量少用。 缺点： 性能不好 反射是一种解释操作,用于字段和方法接入时要远慢于直接代码，下面通过2段简单的代码来比较下执行的时间就可以体现出性能的问题 直接创建对象，时间787ms#### 12345678long start = System.currentTimeMillis(); for (int i = 0; i &lt; 100000; i++) &#123; Student stu = new Student(); stu.setName(&quot;kun&quot;); System.out.println(stu.getName()); &#125; long end = System.currentTimeMillis(); System.out.println(end - start); 利用反射来实现上面的功能，时间在2982ms左右，我是在我本机测试的#### 1234567891011121314long start1 = System.currentTimeMillis(); for (int i = 0; i &lt; 100000; i++) &#123; try &#123; Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;); Student stu = (Student) clz.newInstance(); Method method = clz.getMethod(&quot;setName&quot;, String.class); method.invoke(stu, &quot;kun&quot;); System.out.println(stu.getName()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; long end1 = System.currentTimeMillis(); System.out.println(end1 - start1); 反射的使用场景 实现RPC框架 实现ORM框架 拷贝属性值（BeanUtils.copyProperties） …… 就先这样，又空再看一下相关源码。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组中出现次数超过一半的数字]]></title>
    <url>%2F2018%2F05%2F12%2F%E6%95%B0%E7%BB%84%E4%B8%AD%E5%87%BA%E7%8E%B0%E6%AC%A1%E6%95%B0%E8%B6%85%E8%BF%87%E4%B8%80%E5%8D%8A%E7%9A%84%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[题意：现在有一数组存放int型整数，数字有重复，且有一数字出现的频率超过了50%，请找出这个数字。 乍一看，这是个水题，但如何提高查找性能也是很有意思的。 方法一将数组排序，然后中间的数一定是要求的。排序最小的时间复杂度（快速排序）O(NlogN)，加上遍历。不过Jvm的sort也是很快的。 1234public int MoreHalf_1(int[] nums) &#123; Arrays.sort(nums); return nums[nums.length/2]; &#125; 方法二用一个Map来存储，大于数组的一半就找到。这个方法的时间复杂度是O(N)，空间复杂度是O(n)。 123456789101112131415public int MoreHalf_2(int[] nums) &#123; HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); int i =0; for (;i &lt; nums.length; i++)&#123; if (map.containsKey(nums[i]))&#123; map.put(nums[i],map.get(nums[i])+1); if (map.get(nums[i]) &gt;=nums.length/2)&#123; break; &#125; &#125;else&#123; map.put(nums[i],1); &#125; &#125; return nums[i]; &#125; 方法三出现的次数超过数组长度的一半，表明这个数字出现的次数比其他数出现的次数的总和还多。 考虑每次删除两个不同的数，那么在剩下的数中，出现的次数仍然超过总数的一般，不断重复该过程，排除掉其他的数，最终找到那个出现次数超过一半的数字。这个方法的时间复杂度是O(N)，空间复杂度是O(1)。但删除开销大，可以用标记代替。 在遍历数组的过程中，保存两个值，一个是数组中数字，一个是出现次数。当遍历到下一个数字时，如果这个数字跟之前保存的数字相同，则次数加1，如果不同，则次数减1。如果次数为0，则保存下一个数字并把次数设置为1，由于我们要找的数字出现的次数比其他所有数字出现的次数之和还要多，那么要找的数字肯定是最后一次把次数设为1时对应的数字。 1234567891011121314151617181920212223242526public int MoreHalf_3(int[] nums) &#123; int result = 0; int count = 1; if (nums.length == 0) return -1; result = nums[0]; for (int i = 1 ; i &lt; nums.length; i++)&#123; if (count==0)&#123; result = nums[i]; count = 1; continue; &#125; if (nums[i]==result)&#123; count++; &#125;else &#123; count--; &#125; &#125; count = 0; for (int i = 1; i &lt; nums.length; i++) &#123; if(result == nums[i])count++; &#125; if(count &gt; nums.length/2) return result ; return 0; &#125; 方法四改进快排，利用Partition来确定index，然后mid比较，等于mid就找到了。（Partition确定的是index左边的数比nums[index]小，右边的数比nums[index]大） 12345678910111213141516171819202122232425262728293031323334353637public int MoreThanHalf_4(int[] nums)&#123; if(nums.length==0) return -1; int start = 0; int end = nums.length-1; int index = Partition(nums, start, end); int mid = nums.length/2; while(index!=mid)&#123; if(index&gt;mid) //如果调整数组以后获得的index大于middle，则继续调整start到index-1区段的数组 index = Partition(nums, start, index-1); else&#123; //否则调整index+1到end区段的数组 index = Partition(nums, index+1, end); &#125; &#125; return nums[index]; &#125; public int Partition(int[] nums,int start,int end)&#123; int pivotkey = nums[start]; int origin = start; while(start&lt;end)&#123; while(start&lt;end&amp;&amp;nums[end]&gt;=pivotkey) end--; while(start&lt;end&amp;&amp;nums[start]&lt;pivotkey) start++; swap(nums,start,end); &#125; swap(nums,start,end); swap(nums,origin,end); return end; &#125; public int[] swap(int[] ints, int x, int y) &#123; int temp = ints[x]; ints[x] = ints[y]; ints[y] = temp; return ints; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库的四大特性以及隔离级别]]></title>
    <url>%2F2018%2F05%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7%E4%BB%A5%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[今天有空来了解一下数据的事务四大特性，以及它的隔离级别。下周线代考试，明天再复习吧。 事务的四大特性原子性（Atomicity) 原子性是指事务包含的操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果失败则不能对数据库有任何影响。 一致性（Consisitency) 一致性是指必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说完一个事务行之前和执行之后都必须处于一致性状态。 一个比较好的例子就是转账，假设用户A和用户B两者的前加起来一共是10000，那不管A和B之间如何转账，转多少次账，事务结束后两个用户的钱相加还是10000，这就是事务的一致性。 隔离性（Isolation）隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作干扰，多个并发的事务之间要相互隔离。 即要达到一种效果，对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束了，要么在T1结束后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 持久性（Durability）持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 以上四大事务简称ACID 事务隔离级别Read uncommitted 读未提交 公司发工资了，领导把5000元打到singo的账号上，但是该事务并未提交，而singo正好去查看账户，发现工资已经到账，是5000元整，非常高兴。可是不幸的是，领导发现发给singo的工资金额不对，是2000元，于是迅速回滚了事务，修改金额后，将事务提交，最后singo实际的工资只有2000元，singo空欢喜一场。 出现上述情况，即我们所说的脏读，两个并发的事务，“事务A：领导给singo发工资”、“事务B：singo查询工资账户”，事务B读取了事务A尚未提交的数据。 当隔离级别设置为Read uncommitted时，就可能出现脏读，如何避免脏读，请看下一个隔离级别。 Read commited 读已提交 singo拿着工资卡去消费，系统读取到卡里确实有2000元，而此时她的老婆也正好在网上转账，把singo工资卡的2000元转到另一账户，并在singo之前提交了事务，当singo扣款时，系统检查到singo的工资卡已经没有钱，扣款失败，singo十分纳闷，明明卡里有钱，为何…… 出现上述情况，即我们所说的不可重复读，两个并发的事务，“事务A：singo消费”、“事务B：singo的老婆网上转账”，事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。 当隔离级别设置为Read committed时，避免了脏读，但是可能会造成不可重复读。 大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。如何解决不可重复读这一问题，请看下一个隔离级别。 Repeat read 重复读 当隔离级别设置为Repeatable read时，可以避免不可重复读。当singo拿着工资卡去消费时，一旦系统开始读取工资卡信息（即事务开始），singo的老婆就不可能对该记录进行修改，也就是singo的老婆不能在此时转账。 虽然Repeatable read避免了不可重复读，但还有可能出现幻读。 singo的老婆工作在银行部门，她时常通过银行内部系统查看singo的信用卡消费记录。有一天，她正在查询到singo当月信用卡的总消费金额（select sum(amount) from transaction where month = 本月）为80元，而singo此时正好在外面胡吃海塞后在收银台买单，消费1000元，即新增了一条1000元的消费记录（insert transaction … ），并提交了事务，随后singo的老婆将singo当月信用卡消费的明细打印到A4纸上，却发现消费总额为1080元，singo的老婆很诧异，以为出现了幻觉，幻读就这样产生了。 注：Mysql的默认隔离级别就是Repeatable read。 Serializable 序列化Serializable是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arrays.sort和Collections.sort实现原理探究]]></title>
    <url>%2F2018%2F05%2F04%2FArrays-sort%E5%92%8CCollections-sort%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[前言一直对Arrays.sort()和Collections.sort()的有什么区别好奇，有时间就对源码分析一下。 Arrays.sort()先看Arrays.sort()，一进去是这样的。果然没有那么简单，DualPivotQuicksort翻译过来就是双轴快速排序，关于双轴排序可以去这里http://www.cnblogs.com/nullzx/p/5880191.html 看看。那再次点进去，可以发现有这么一段代码 1234if (right - left &lt; QUICKSORT_THRESHOLD) &#123; sort(a, left, right, true); return;&#125; 可以发现如果数组的长度小于QUICKSORT_THRESHOLD的话就会使用这个双轴快速排序，而这个值是286。 那如果大于286呢，它就会坚持数组的连续升序和连续降序性好不好，如果好的话就用归并排序，不好的话就用快速排序，看下面这段注释就可以看出 The array is not highly structured, use Quicksort instead of merge sort. 那现在再回到上面的决定用双轴快速排序的方法上，再点进去，发现又会多一条判断 // Use insertion sort on tiny arraysif (length &lt; INSERTION_SORT_THRESHOLD) 所以总结一下Arrays.sort()方法，如果数组长度大于等于286且连续性好的话，就用归并排序，如果大于等于286且连续性不好的话就用双轴快速排序。如果长度小于286且大于等于47的话就用双轴快速排序，如果长度小于47的话就用插入排序。 Collections.sort() Collections.sort()底层调用的是array.sort(). 写个demo跟踪下 ** 123456789101112public class TestSort &#123; public static void main(String[] args) &#123; List&lt;String&gt; strings = Arrays.asList(&quot;6&quot;, &quot;1&quot;, &quot;3&quot;, &quot;1&quot;,&quot;2&quot;); Collections.sort(strings);//sort方法在这里 for (String string : strings) &#123; System.out.println(string); &#125; &#125;&#125; 然后发现Collections.sort()调用的是list.sort() 而在list.sort()中调用了Arrays.sort() 然后发现里面调用的Arrays.sort(a, c); a是list,c是一个比较器，我们来看一下这个方法 由网上查得，LegacyMergeSort是一个老的归并排序，不过不用管了现在默认是关的。 我们走的是sort(a)这个方法，接着进入这个 5.最后就是TimSort()的源码了 12345678910111213141516171819202122232425262728293031323334353637383940414243static void sort(Object[] a, int lo, int hi, Object[] work, int workBase, int workLen) &#123; assert a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // array的大小为0或者1就不用排了 // 当数组大小小于MIN_MERGE(32)的时候，就用一个&quot;mini-TimSort&quot;的方法排序，jdk1.7新加 if (nRemaining &lt; MIN_MERGE) &#123; //这个方法比较有意思，其实就是将我们最长的递减序列，找出来，然后倒过来 int initRunLen = countRunAndMakeAscending(a, lo, hi); //长度小于32的时候，是使用binarySort的 binarySort(a, lo, hi, lo + initRunLen); return; &#125; //先扫描一次array，找到已经排好的序列，然后再用刚才的mini-TimSort，然后合并，这就是TimSort的核心思想 ComparableTimSort ts = new ComparableTimSort(a, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1; &#125; TimSort的算法性能分析详见：https://blog.csdn.net/yangzhongblog/article/details/8184707]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Jdk源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合框架总结与分析(二)]]></title>
    <url>%2F2018%2F04%2F25%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E6%80%BB%E7%BB%93%E4%B8%8E%E5%88%86%E6%9E%90-%E4%BA%8C%2F</url>
    <content type="text"></content>
      <categories>
        <category>集合框架</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合框架总结与思考（一）]]></title>
    <url>%2F2018%2F04%2F24%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[前言对Java的集合框架用得比较频繁，但疏于总结，今天就从源码来分析一波。 集合框架（Collection Framework）首先要明确，集合代表了一组对象（和数组一样，但数组长度不能变，而集合能）。Java中的集合框架定义了一套规范，用来表示、操作集合，使具体操作与实现细节解耦。 先来整体来分析 简单说明 ： 集合接口：6个接口（短虚线表示），表示不同集合类型，是集合框架的基础。 抽象类：5个抽象类（长虚线表示），对集合接口的部分实现。可扩展为自定义集合类。 实现类：8个实现类（实线表示），对接口的具体实现。 Collection 接口是一组允许重复的对象。 Set 接口继承 Collection，集合元素不重复。 List 接口继承 Collection，允许重复，维护元素插入顺序。 Map接口是键－值对象，与Collection接口没有什么关系。 . Set 接口继承 Collection，集合元素不重复。 List 接口继承 Collection，允许重复，维护元素插入顺序。 Map接口是键－值对象，与Collection接口没有什么关系。 .Set、List和Map可以看做集合的三大类： List集合是有序集合，集合中的元素可以重复，访问集合中的元素可以根据元素的索引来访问。 Set集合是无序集合，集合中的元素不可以重复，访问集合中的元素只能根据元素本身来访问（也是集合里元素不允许重复的原因）。 Map集合中保存Key-value对形式的元素，访问时只能根据每项元素的key来访问其value。 两大基类Collection与Map在集合框架的类继承体系中，最顶层有两个接口 Collection表示一组纯数据 Map表示一组key-value对 一般继承自Collection或Map的集合类，会提供两个“标准”的构造函数 没有参数的构造函数，创建一个空的集合类 有一个类型与基类（Collection或Map）相同的构造函数，创建一个与给定参数具有相同元素的新集合类Collection 如上图所示，Collection类主要有三个接口： Set表示不允许有重复元素的集合（A collection that contains no duplicate elements） List表示允许有重复元素的集合（An ordered collection (also known as a sequence)） Queue JDK1.5新增，与上面两个集合类主要是的区分在于Queue主要用于存储数据，而不是处理数据。（A collection designed for holding elements prior to processing.） Map 接口说明Collection接口除了Map接口，其他集合都是Collection的子类，并且在我们的实际编程中，由于多态的原因，我们一般都会使用这个的编码方式，如：Inter i1 = new ImplementInter();(其中，Inter表示一个接口，ImplementInter表示对此接口的实现)，此时i1调用的方法只能是Inter接口中的方法，无法调用ImplementInter中新增的方法（除非进行向下类型转化）。所以，很有必要了解一下Collection根接口中都有哪些方法。 1234567891011121314151617181920212223242526272829303132333435363738394041public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; &#123; int size(); boolean isEmpty(); boolean contains(Object o); Iterator&lt;E&gt; iterator(); Object[] toArray(); &lt;T&gt; T[] toArray(T[] a); boolean add(E e); boolean remove(Object o); boolean containsAll(Collection&lt;?&gt; c); boolean addAll(Collection&lt;? extends E&gt; c); boolean removeAll(Collection&lt;?&gt; c); boolean retainAll(Collection&lt;?&gt; c); void clear(); boolean equals(Object o); int hashCode(); // jdk1.8添加的方法 default boolean removeIf(Predicate&lt;? super E&gt; filter) &#123; Objects.requireNonNull(filter); boolean removed = false; final Iterator&lt;E&gt; each = iterator(); while (each.hasNext()) &#123; if (filter.test(each.next())) &#123; each.remove(); removed = true; &#125; &#125; return removed; &#125; @Override default Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0); &#125; default Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false); &#125; default Stream&lt;E&gt; parallelStream() &#123; return StreamSupport.stream(spliterator(), true); &#125;&#125; 其中，有几个比较常用的方法，比如方法add()添加一个元素到集合中，addAll()将指定集合中的所有元素添加到集合中，contains()方法检测集合中是否包含指定的元素，toArray()方法返回一个表示集合的数组。 另外，Collection中有一个iterator()函数，它的作用是返回一个Iterator接口。通常，我们通过Iterator迭代器来遍历集合。ListIterator是List接口所特有的，在List接口中，通过ListIterator()返回一个ListIterator对象。 Collection接口有两个常用的子接口，下面详细介绍。 1.List接口 List集合代表一个有序集合，集合中每个元素都有其对应的顺序索引。List集合允许使用重复元素，可以通过索引来访问指定位置的集合元素。 List接口继承于Collection接口，它可以定义一个允许重复的有序集合。因为List中的元素是有序的，所以我们可以通过使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。 List接口为Collection直接接口。List所代表的是有序的Collection，即它用某种特定的插入顺序来维护元素顺序。用户可以对列表中每个元素的插入位置进行精确地控制，同时可以根据元素的整数索引（在列表中的位置）访问元素，并搜索列表中的元素。实现List接口的集合主要有：ArrayList、LinkedList、Vector、Stack。 （1）ArrayList ArrayList是一个动态数组，也是我们最常用的集合。它允许任何符合规则的元素插入甚至包括null。每一个ArrayList都有一个初始容量（10），该容量代表了数组的大小。随着容器中的元素不断增加，容器的大小也会随着增加。在每次向容器中增加元素的同时都会进行容量检查，当快溢出时，就会进行扩容操作。所以如果我们明确所插入元素的多少，最好指定一个初始容量值，避免过多的进行扩容操作而浪费时间、效率。 size、isEmpty、get、set、iterator 和 listIterator 操作都以固定时间运行。add 操作以分摊的固定时间运行，也就是说，添加 n 个元素需要 O(n) 时间（由于要考虑到扩容，所以这不只是添加元素会带来分摊固定时间开销那样简单）。 ArrayList擅长于随机访问。同时ArrayList是非同步的。 （2）LinkedList 同样实现List接口的LinkedList与ArrayList不同，ArrayList是一个动态数组，而LinkedList是一个双向链表。所以它除了有ArrayList的基本操作方法外还额外提供了get，remove，insert方法在LinkedList的首部或尾部。 由于实现的方式不同，LinkedList不能随机访问，它所有的操作都是要按照双重链表的需要执行。在列表中索引的操作将从开头或结尾遍历列表（从靠近指定索引的一端）。这样做的好处就是可以通过较低的代价在List中进行插入和删除操作。 与ArrayList一样，LinkedList也是非同步的。如果多个线程同时访问一个List，则必须自己实现访问同步。一种解决方法是在创建List时构造一个同步的List：List list = Collections.synchronizedList(new LinkedList(…)); （3）Vector 与ArrayList相似，但是Vector是同步的。所以说Vector是线程安全的动态数组。它的操作与ArrayList几乎一样。 （4）Stack Stack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。 2.Set接口 Set是一种不包括重复元素的Collection。它维持它自己的内部排序，所以随机访问没有任何意义。与List一样，它同样允许null的存在但是仅有一个。由于Set接口的特殊性，所有传入Set集合中的元素都必须不同，同时要注意任何可变对象，如果在对集合中元素进行操作时，导致e1.equals(e2)==true，则必定会产生某些问题。Set接口有三个具体实现类，分别是散列集HashSet、链式散列集LinkedHashSet和树形集TreeSet。 Set是一种不包含重复的元素的Collection，无序，即任意的两个元素e1和e2都有e1.equals(e2)=false，Set最多有一个null元素。需要注意的是:虽然Set中元素没有顺序，但是元素在set中的位置是由该元素的HashCode决定的，其具体位置其实是固定的。 此外需要说明一点，在set接口中的不重复是有特殊要求的。 举一个例子:对象A和对象B，本来是不同的两个对象，正常情况下它们是能够放入到Set里面的，但是如果对象A和B的都重写了hashcode和equals方法，并且重写后的hashcode和equals方法是相同的话。那么A和B是不能同时放入到Set集合中去的，也就是Set集合中的去重和hashcode与equals方法直接相关。 （1）HashSet HashSet 是一个没有重复元素的集合。它是由HashMap实现的，不保证元素的顺序(这里所说的没有顺序是指：元素插入的顺序与输出的顺序不一致)，而且HashSet允许使用null 元素。HashSet是非同步的，如果多个线程同时访问一个哈希set，而其中至少一个线程修改了该set，那么它必须保持外部同步。 HashSet按Hash算法来存储集合的元素，因此具有很好的存取和查找性能。 HashSet的实现方式大致如下，通过一个HashMap存储元素，元素是存放在HashMap的Key中，而Value统一使用一个Object对象。 HashSet使用和理解中容易出现的误区: a.HashSet中存放null值 HashSet中是允许存入null值的，但是在HashSet中仅仅能够存入一个null值。 b.HashSet中存储元素的位置是固定的 HashSet中存储的元素的是无序的，这个没什么好说的，但是由于HashSet底层是基于Hash算法实现的，使用了hashcode，所以HashSet中相应的元素的位置是固定的。 c.必须小心操作可变对象（Mutable Object）。如果一个Set中的可变元素改变了自身状态导致Object.equals(Object)=true将导致一些问题。 （2）LinkedHashSet LinkedHashSet继承自HashSet，其底层是基于LinkedHashMap来实现的，有序，非同步。LinkedHashSet集合同样是根据元素的hashCode值来决定元素的存储位置，但是它同时使用链表维护元素的次序。这样使得元素看起来像是以插入顺序保存的，也就是说，当遍历该集合时候，LinkedHashSet将会以元素的添加顺序访问集合的元素。 （3）TreeSet TreeSet是一个有序集合，其底层是基于TreeMap实现的，非线程安全。TreeSet可以确保集合元素处于排序状态。TreeSet支持两种排序方式，自然排序和定制排序，其中自然排序为默认的排序方式。当我们构造TreeSet时，若使用不带参数的构造函数，则TreeSet的使用自然比较器；若用户需要使用自定义的比较器，则需要使用带比较器的参数。 注意：TreeSet集合不是通过hashcode和equals函数来比较元素的.它是通过compare或者comparaeTo函数来判断元素是否相等.compare函数通过判断两个对象的id，相同的id判断为重复元素，不会被加入到集合中。 其中在jdk1.8后添加的方法对我们的分析不会产生影响，添加的方法有关键字default修饰，为缺省方法，是一个新特性。 对集合而言，都会包含添加、删除、判断、清空、大小等基本操作。 Map接口对于Map接口而言，是键值对集合，特别适用于那种情形，一个主属性，另外一个副属性（如：姓名，性别；kr,男），添加元素时，若存在相同的键，则会用新值代替旧值。方法如下 ： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188public interface Map&lt;K,V&gt; &#123; int size(); boolean isEmpty(); boolean containsKey(Object key); boolean containsValue(Object value); V get(Object key); V put(K key, V value); V remove(Object key); void putAll(Map&lt;? extends K, ? extends V&gt; m); void clear(); Set&lt;K&gt; keySet(); Collection&lt;V&gt; values(); Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); interface Entry&lt;K,V&gt; &#123; K getKey(); V getValue(); V setValue(V value); boolean equals(Object o); int hashCode(); // jdk1.8 后添加的方法 public static &lt;K extends Comparable&lt;? super K&gt;, V&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByKey() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getKey().compareTo(c2.getKey()); &#125; public static &lt;K, V extends Comparable&lt;? super V&gt;&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByValue() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getValue().compareTo(c2.getValue()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByKey(Comparator&lt;? super K&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getKey(), c2.getKey()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByValue(Comparator&lt;? super V&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getValue(), c2.getValue()); &#125; &#125; boolean equals(Object o); int hashCode(); default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key))? v: defaultValue; &#125; default void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Objects.requireNonNull(action); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; action.accept(k, v); &#125; &#125; default void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Objects.requireNonNull(function); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; // ise thrown from function is not a cme. v = function.apply(k, v); try &#123; entry.setValue(v); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; &#125; &#125; default V putIfAbsent(K key, V value) &#123; V v = get(key); if (v == null) &#123; v = put(key, value); &#125; return v; &#125; default boolean remove(Object key, Object value) &#123; Object curValue = get(key); if (!Objects.equals(curValue, value) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; remove(key); return true; &#125; default boolean replace(K key, V oldValue, V newValue) &#123; Object curValue = get(key); if (!Objects.equals(curValue, oldValue) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; put(key, newValue); return true; &#125; default V replace(K key, V value) &#123; V curValue; if (((curValue = get(key)) != null) || containsKey(key)) &#123; curValue = put(key, value); &#125; return curValue; &#125; default V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) &#123; V newValue; if ((newValue = mappingFunction.apply(key)) != null) &#123; put(key, newValue); return newValue; &#125; &#125; return v; &#125; default V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue; if ((oldValue = get(key)) != null) &#123; V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) &#123; put(key, newValue); return newValue; &#125; else &#123; remove(key); return null; &#125; &#125; else &#123; return null; &#125; &#125; default V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue = get(key); V newValue = remappingFunction.apply(key, oldValue); if (newValue == null) &#123; // delete mapping if (oldValue != null || containsKey(key)) &#123; // something to remove remove(key); return null; &#125; else &#123; // nothing to do. Leave things as they were. return null; &#125; &#125; else &#123; // add or replace old mapping put(key, newValue); return newValue; &#125; &#125; default V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) &#123; remove(key); &#125; else &#123; put(key, newValue); &#125; return newValue; &#125;&#125; 1.HashMap 以哈希表数据结构实现，查找对象时通过哈希函数计算其位置，它是为快速查询而设计的，其内部定义了一个hash表数组（Entry[] table），元素会通过哈希转换函数将元素的哈希地址转换成数组中存放的索引，如果有冲突，则使用散列链表的形式将所有相同哈希地址的元素串起来，可能通过查看HashMap.Entry的源码它是一个单链表结构。 2.LinkedHashMap LinkedHashMap是HashMap的一个子类，它保留插入的顺序，如果需要输出的顺序和输入时的相同，那么就选用LinkedHashMap。 LinkedHashMap是Map接口的哈希表和链接列表实现，具有可预知的迭代顺序。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 LinkedHashMap实现与HashMap的不同之处在于，后者维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。 根据链表中元素的顺序可以分为：按插入顺序的链表，和按访问顺序(调用get方法)的链表。默认是按插入顺序排序，如果指定按访问顺序排序，那么调用get方法后，会将这次访问的元素移至链表尾部，不断访问可以形成按访问顺序排序的链表。 注意，此实现不是同步的。如果多个线程同时访问链接的哈希映射，而其中至少一个线程从结构上修改了该映射，则它必须保持外部同步。 由于LinkedHashMap需要维护元素的插入顺序，因此性能略低于HashMap的性能，但在迭代访问Map里的全部元素时将有很好的性能，因为它以链表来维护内部顺序。 3.TreeMap TreeMap 是一个有序的key-value集合，非同步，基于红黑树（Red-Black tree）实现，每一个key-value节点作为红黑树的一个节点。TreeMap存储时会进行排序的，会根据key来对key-value键值对进行排序，其中排序方式也是分为两种，一种是自然排序，一种是定制排序，具体取决于使用的构造方法。 自然排序：TreeMap中所有的key必须实现Comparable接口，并且所有的key都应该是同一个类的对象，否则会报ClassCastException异常。 定制排序：定义TreeMap时，创建一个comparator对象，该对象对所有的treeMap中所有的key值进行排序，采用定制排序的时候不需要TreeMap中所有的key必须实现Comparable接口。 TreeMap判断两个元素相等的标准：两个key通过compareTo()方法返回0，则认为这两个key相等。 如果使用自定义的类来作为TreeMap中的key值，且想让TreeMap能够良好的工作，则必须重写自定义类中的equals()方法，TreeMap中判断相等的标准是：两个key通过equals()方法返回为true，并且通过compareTo()方法比较应该返回为0。 简单说明： Map接口有一个内部接口Entry,对集合中的元素定义了一组通用的操作，维护这键值对，可以对键值对进行相应的操作，通过Map接口的entrySet可以返回集合对象的视图集，方便对集合对象进行遍历等操作。 对Map而言，也会包含添加、删除、判断、清空、大小等基本操作。]]></content>
      <categories>
        <category>集合框架</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之decorator模式]]></title>
    <url>%2F2018%2F04%2F10%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8Bdecorator%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言如果把程序中的对象比作蛋糕，然后想不断地向装饰蛋糕一样地不断地对其增加功能，它就变成了使用目的更加明确的对象。像这种不断为对象添加装饰的设计模式称之为decorator模式。 示例UML图 代码在https://github.com/8311431967/practiceCode Display类abstract class Display &#123;123456789 public abstract int getColumns(); // 获取横向字符数 public abstract int getRows(); // 获取纵向行数 public abstract String getRowText(int row); // 获取第row行的字符串 public void show() &#123; // 全部显示 for (int i = 0; i &lt; getRows(); i++) &#123; System.out.println(getRowText(i)); &#125; &#125;&#125; StringDisplay类用于显示单行字符串的类，肩负着实现Display类中的声明的抽象方法的重任。其相当于生日蛋糕中的核心蛋糕。 class StringDisplay extends Display &#123;123456789101112131415161718 private String string; // 要显示的字符串 public StringDisplay(String string) &#123; // 通过参数传入要显示的字符串 this.string = string; &#125; public int getColumns() &#123; // 字符数 return string.getBytes().length; &#125; public int getRows() &#123; // 行数是1 return 1; &#125; public String getRowText(int row) &#123; // 仅当row为0时返回值 if (row == 0) &#123; return string; &#125; else &#123; return null; &#125; &#125;&#125; Border作为装饰边框的抽象类 abstract class Border extends Display &#123;12345 protected Display display; // 表示被装饰物 protected Border(Display display) &#123; // 在生成实例时通过参数指定被装饰物 this.display = display; &#125;&#125; SideBorder类在两侧在上”|” class SideBorder extends Border &#123;123456789101112131415 private char borderChar; // 表示装饰边框的字符 public SideBorder(Display display, char ch) &#123; // 通过构造函数指定Display和装饰边框字符 super(display); this.borderChar = ch; &#125; public int getColumns() &#123; // 字符数为字符串字符数加上两侧边框字符数 return 1 + display.getColumns() + 1; &#125; public int getRows() &#123; // 行数即被装饰物的行数 return display.getRows(); &#125; public String getRowText(int row) &#123; // 指定的那一行的字符串为被装饰物的字符串加上两侧的边框的字符 return borderChar + display.getRowText(row) + borderChar; &#125;&#125; FullBorder类添加上下左右边框 class FullBorder extends Border &#123;1234567891011121314151617181920212223242526 public FullBorder(Display display) &#123; super(display); &#125; public int getColumns() &#123; // 字符数为被装饰物的字符数加上两侧边框字符数 return 1 + display.getColumns() + 1; &#125; public int getRows() &#123; // 行数为被装饰物的行数加上上下边框的行数 return 1 + display.getRows() + 1; &#125; public String getRowText(int row) &#123; // 指定的那一行的字符串 if (row == 0) &#123; // 上边框 return &quot;+&quot; + makeLine(&apos;-&apos;, display.getColumns()) + &quot;+&quot;; &#125; else if (row == display.getRows() + 1) &#123; // 下边框 return &quot;+&quot; + makeLine(&apos;-&apos;, display.getColumns()) + &quot;+&quot;; &#125; else &#123; // 其他边框 return &quot;|&quot; + display.getRowText(row - 1) + &quot;|&quot;; &#125; &#125; private String makeLine(char ch, int count) &#123; // 生成一个重复count次字符ch的字符串 StringBuffer buf = new StringBuffer(); for (int i = 0; i &lt; count; i++) &#123; buf.append(ch); &#125; return buf.toString(); &#125;&#125; Main类class Main &#123;123456789101112131415161718192021222324 public static void main(String[] args) &#123; Display b1 = new StringDisplay(&quot;Hello, world.&quot;); Display b2 = new SideBorder(b1, &apos;#&apos;); Display b3 = new FullBorder(b2); b1.show(); b2.show(); b3.show(); Display b4 = new SideBorder( new FullBorder( new FullBorder( new SideBorder( new FullBorder( new StringDisplay(&quot;你好，世界。&quot;) ), &apos;*&apos; ) ) ), &apos;/&apos; ); b4.show(); &#125;&#125; 结果如下： 要点接口的透明性1.在decorator模式中，装饰边框和装饰物具有一致性，也就是说Border类（及其子类）与表示被装饰物的Display类具有相同的接口。这样即使被装饰物被边框装饰起来，接口API也不会被隐藏起来，其他类依然可以调用getColumn(),getRows(),show()方法，这就是API接口的“透明性”。 2.得益于接口的透明化，Decorator模式中形成了类似Composite模式中的递归结构，装饰边框里面的被装饰物实际上又是别的物体的“装饰边框”。 在不改变被装饰物的前提下增加功能虽然接口是相同的，但是越装饰，功能则越多，eg，用sideborder装饰display后，在字符串两侧可以加上装饰字符，也可在加上FullBorder。此时，我们完全不需要对被装饰的类做任何修改。 decorator模式中使用了委托，它使类之间形成弱关联关系，因此不必改变框架代码，就可以生成一个与其他对象具有不同关系的新对象。 Java.io包与Decorator模式首先如读取文件的示例：Reader reader = new FileReader(“datafile.txt”); 然后我们可以向下面这样在读取文件时将文件内容放入缓冲区中。 Reader reader = new BufferReader(new FileReader(“data.txt”)); 还可以Reader reader = new LineNumberReader(new BufferReader(new FileReader(“data.txt”))); 无论是LineNumReader类的构造函数还是BufferedReader类的构造函数，都可以接受Reader类（子类）的实例作为参数，因此我们可以像上面那样自由的进行各种自由组合。 缺点导致程序中增加许多功能类似的很小的类，Java.io包的类我就还没记完，orz。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>装饰模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之抽象工厂模式]]></title>
    <url>%2F2018%2F04%2F04%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[抽象工厂模式抽象工厂的工作就是将抽象零件组装为抽象产品，也就是我们并不关心零件的具体实现，而是只关心接口（API）。 示例抽象的零件：Item类abstract class Item &#123;123456 protected String caption; public Item(String caption) &#123; this.caption = caption; &#125; public abstract String makeHTML();//抽象方法由子类实现&#125; 抽象的零件：Link类abstract class Link extends Item &#123;123456 protected String url; public Link(String caption, String url) &#123; super(caption); this.url = url; &#125;&#125; 抽象的零件：Tray类abstract class Tray extends Item &#123;12345678 protected ArrayList tray = new ArrayList(); public Tray(String caption) &#123; super(caption); &#125; public void add(Item item) &#123; tray.add(item); &#125;&#125; 抽象的产品：Page类abstract class Page &#123;1234567891011121314151617181920212223 protected String title; protected String author; protected ArrayList content = new ArrayList(); public Page(String title, String author) &#123; this.title = title; this.author = author; &#125; public void add(Item item) &#123; content.add(item); &#125; public void output() &#123; try &#123; String filename = title + &quot;.html&quot;; Writer writer = new FileWriter(filename); writer.write(this.makeHTML()); writer.close(); System.out.println(filename + &quot; 编写完成。&quot;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public abstract String makeHTML();&#125; 抽象的工厂：Factory类getFactory()通过调用Class类的forName方法动态地读取类信息，接着用newInstance方法生成该类的实例，并将其作为返回值返回调用者。 请注意：虽然getFactory()方法生成的是具体工厂的实例，但是返回值是抽象工厂类型的。 abstract class Factory &#123;123456789101112131415 public static Factory getFactory(String classname) &#123; Factory factory = null; try &#123; factory = (Factory)Class.forName(classname).newInstance(); &#125; catch (ClassNotFoundException e) &#123; System.err.println(&quot;没有找到 &quot; + classname + &quot;类。&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return factory; &#125; public abstract Link createLink(String caption, String url); public abstract Tray createTray(String caption); public abstract Page createPage(String title, String author);&#125; 具体的工厂：ListFactory类class ListFactory extends Factory &#123;12345678910 public Link createLink(String caption, String url) &#123; return new ListLink(caption, url); &#125; public Tray createTray(String caption) &#123; return new ListTray(caption); &#125; public Page createPage(String title, String author) &#123; return new ListPage(title, author); &#125;&#125; 具体的零件：ListLink类class ListLink extends Link &#123;1234567 public ListLink(String caption, String url) &#123; super(caption, url); &#125; public String makeHTML() &#123; return &quot; &lt;li&gt;&lt;a href=\&quot;&quot; + url + &quot;\&quot;&gt;&quot; + caption + &quot;&lt;/a&gt;&lt;/li&gt;\n&quot;; &#125;&#125; 具体的零件：ListTray类划重点：通过使用迭代器，调用Item的makeHTML()，请注意，这里并不关心变量Item中保存的实例究竟是ListLink的实例还是ListTray的实例，只是简单的调用makeHTML(),之后item会帮我们处理，这是面向对象编程的好处。 class ListTray extends Tray &#123;123456789101112131415161718 public ListTray(String caption) &#123; super(caption); &#125; public String makeHTML() &#123; StringBuffer buffer = new StringBuffer(); buffer.append(&quot;&lt;li&gt;\n&quot;); buffer.append(caption + &quot;\n&quot;); buffer.append(&quot;&lt;ul&gt;\n&quot;); Iterator it = tray.iterator(); while (it.hasNext()) &#123; Item item = (Item)it.next(); buffer.append(item.makeHTML()); &#125; buffer.append(&quot;&lt;/ul&gt;\n&quot;); buffer.append(&quot;&lt;/li&gt;\n&quot;); return buffer.toString(); &#125;&#125; 具体的产品：ListPage类class ListPage extends Page &#123;1234567891011121314151617181920 public ListPage(String title, String author) &#123; super(title, author); &#125; public String makeHTML() &#123; StringBuffer buffer = new StringBuffer(); buffer.append(&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;&quot; + title + &quot;&lt;/title&gt;&lt;/head&gt;\n&quot;); buffer.append(&quot;&lt;body&gt;\n&quot;); buffer.append(&quot;&lt;h1&gt;&quot; + title + &quot;&lt;/h1&gt;\n&quot;); buffer.append(&quot;&lt;ul&gt;\n&quot;); Iterator it = content.iterator(); while (it.hasNext()) &#123; Item item = (Item)it.next(); buffer.append(item.makeHTML()); &#125; buffer.append(&quot;&lt;/ul&gt;\n&quot;); buffer.append(&quot;&lt;hr&gt;&lt;address&gt;&quot; + author + &quot;&lt;/address&gt;&quot;); buffer.append(&quot;&lt;/body&gt;&lt;/html&gt;\n&quot;); return buffer.toString(); &#125;&#125; 使用工厂将零件组装成为产品：Main类该类只是引入了factory包，并没有使用任何具体的零件，产品和工厂 class Main &#123;12345678910111213141516171819202122232425262728293031323334353637 public static void main(String[] args) &#123; if (args.length != 1) &#123; System.out.println(&quot;Usage: java Main class.name.of.ConcreteFactory&quot;); System.out.println(&quot;Example 1: java Main listfactory.ListFactory&quot;); System.out.println(&quot;Example 2: java Main tablefactory.TableFactory&quot;); System.exit(0); &#125; // Factory factory = Factory.getFactory(&quot;abstractFactory.listfactory.ListFactory&quot;); Factory factory = Factory.getFactory(args[0]); Link people = factory.createLink(&quot;People Daily&quot;, &quot;http://www.people.com.cn/&quot;); Link gmw = factory.createLink(&quot;GuangMing Daily&quot;, &quot;http://www.gmw.cn/&quot;); Link us_yahoo = factory.createLink(&quot;Yahoo!&quot;, &quot;http://www.yahoo.com/&quot;); Link jp_yahoo = factory.createLink(&quot;Yahoo!Japan&quot;, &quot;http://www.yahoo.co.jp/&quot;); Link excite = factory.createLink(&quot;Excite&quot;, &quot;http://www.excite.com/&quot;); Link google = factory.createLink(&quot;Google&quot;, &quot;http://www.google.com/&quot;); Tray traynews = factory.createTray(&quot;NewsPaper&quot;); traynews.add(people); traynews.add(gmw); Tray trayyahoo = factory.createTray(&quot;Yahoo!&quot;); trayyahoo.add(us_yahoo); trayyahoo.add(jp_yahoo); Tray traysearch = factory.createTray(&quot;searchEngine&quot;); traysearch.add(trayyahoo); traysearch.add(excite); traysearch.add(google); Page page = factory.createPage(&quot;LinkPage&quot;, &quot;kr&quot;); page.add(traynews); page.add(traysearch); page.output(); &#125;&#125; 抽象工厂的优劣点####易于增加具体的工厂 这里说的容易是指需要编写哪些类和需要实现哪些方法都非常清楚。假设我们要在示例中增加新的具体工厂，那么需要做的就是编写Factory，Link，Tray，Page这四个类的子类，并实现他们定义的抽象方法。这样一来，无论要增加多少个具体工厂（或者是修改具体工厂的BUG），都无需修改抽象工厂。 ####难于增加新的零件 如果要增加新的零件时，就必须要对所有的具体工厂进行相应的修改。例如要在factory包中增加一个表示图像的Picture零件，就要在listfactory中作如下修改： 在ListFactory中加入createPicture； 新增ListPicture类 而且编写完成的具体工厂越多，修改的工作量越多。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式 抽象工厂</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对抖音和快手的体验与分析]]></title>
    <url>%2F2018%2F04%2F02%2F%E5%AF%B9%E6%8A%96%E9%9F%B3%E5%92%8C%E5%BF%AB%E6%89%8B%E7%9A%84%E4%BD%93%E9%AA%8C%E4%B8%8E%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[序言虽然以前就听过快手和抖音了，但好似对我的作用不大，就一直没有上手。But，快手和抖音都在2018的春节期间大放异彩，逐步占领市场。还有看到了中央颁布的互联网独角兽公司，我惊奇地发现快手竟然排到了61，而抖音也是有前一百的，被学生党喜闻乐见的知乎排在了110+。果然人民群众相对于.txt,.jpg,更喜欢*.avi啊。所以决定下载抖音和快手，来体验一下，顺便来为我拓宽一下设计思路。 界面和交互设计抖音的界面初始只有一个视频，不用点击就自动播放，双击点赞，上下滑下一个视频，很简单方便，但可选率低。而快手初始界面四张图片，需要点击进去才能播放，下滑可以看更多的缩略图。抖音的设计必须依靠强大的推荐系统，不然滑了几个视频都是不好看的就gg了。 推荐系统和算法毕竟一开始还是要给三无用户作推荐，大概是推荐点赞比较多的和关注度比较高的大v吧。而抖音请了明星入驻，一点开的都是明星的视频，而快手更多的是妹纸的，不过标题真的太太太尴尬了。那么如何给新用户增加曝光机会呢？ 在视频推荐中会穿插一些新用户的视频，我的观察大概是10条有1条。这样保证了在用户不会觉得烦的同时，也给了新的创作者一定流量。当新的视频达到一定的赞后，可能会被推送更多用户，而没有达到某个标准的视频可能会“进入冷宫“。这样的设计防止了像微博这类网站的大V把持流量所造成的马太效应，越来越多的平台在采取相同的策略 这样就能吸引新用户，增加优质资源的同时防止大v的流量劫持。 内容抖音的内容还算是积极向上，明星们都比较接地气，而且配上特定的BGM真的很魔性，还有一些人拍的情景剧，也就十秒左右，后来发现还是续集来的，orz。 而快手的内容就比较接地气，或者是少部分人说的俗，视频里主要是妹子跳舞，泳装…..还有农村里面的奇人异事，工厂妹的一天之类的。我觉得快手是切入点很准，面向二线三线四线的人，得屌丝者得天下啊。 不过上一次的十四岁怀孕少女的视频引起了人们的关注，进而对快手的鄙视，我还在live中发现了色情引流，虽然说可以举报，但管理员根本忙不过来啊。 监管这一方面还要加强吧，感觉要变成直播软件了。共青团入驻快手和抖音，我还特意搜了账号看作品，作品量低啊。 推荐广告这种流量软件当然少不了广告的，不然怎生存，穿插于视频中，用户不仔细看可能就已经当成一个普通视频看完了。我刚注册，广告遇见率不高，可能还是杀熟吧。再者听说抖音和快手的广告费是比知乎高几倍的，果然还是学生党比屌丝更穷啊。 结语抖音和快手的界面和交互设计都做得很好，也很快（只是我的辣鸡校园网不给力），智能推荐也很好，但过于沉溺于某个方面就会错过外面精彩的世界。就好像快手现在就只推荐都是妹纸的视频给我了，明明我本意是用快手和抖音记单词的。我觉得俗或不俗都是人民群众说了算，快手和抖音都是一个成功的app，既满足了人民的需求也从中捞到了利益。]]></content>
      <categories>
        <category>杂文</category>
      </categories>
      <tags>
        <tag>杂文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之Iterator模式]]></title>
    <url>%2F2018%2F04%2F02%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BIterator%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Iterator模式刚看完23种设计模式，就先来总结一下Iterator模式。重点是掌握使用抽象类和接口来编程。先来回忆一下这个例子： 定义Aggregate接口（集合）interface Aggregate &#123;12 public abstract Iterator iterator();&#125; 定义Iterator接口（迭代器）interface Iterator &#123;123public abstract boolean hasNext();public abstract Object next();&#125; 定义Book类class Book &#123;12345678private String name;public Book(String name) &#123; this.name = name;&#125;public String getName() &#123; return name;&#125;&#125; 定义BookSelf类（具体的集合）class BookShelf implements Aggregate &#123;1234567891011121314151617private ArrayList books; public BookShelf(int initialsize) &#123; this.books = new ArrayList(initialsize); &#125; public Book getBookAt(int index) &#123; return (Book)books.get(index); &#125;public void appendBook(Book book) &#123; books.add(book); &#125;public int getLength() &#123; return books.size(); &#125;public Iterator iterator() &#123; return new BookShelfIterator(this);&#125;&#125; 这里用了ArrayList来实现动态数组，避免当书本过多时而受到限制，有时间在分析ArrayList的源码 定义BookShelfIterator（具体的迭代器）class BookShelfIterator implements Iterator &#123;12345678910111213141516171819private BookShelf bookShelf;private int index;public BookShelfIterator(BookShelf bookShelf) &#123; this.bookShelf = bookShelf; this.index = 0;&#125;public boolean hasNext() &#123; if (index &lt; bookShelf.getLength()) &#123; return true; &#125; else &#123; return false; &#125;&#125;public Object next() &#123; Book book = bookShelf.getBookAt(index); index++; return book;&#125;&#125; 因为BookShelfIterator类要发挥Iterator的作用，so实现了Iterator的接口 UML图如下： 使用Iterator的作用引入Iterator模式后把遍历和实现分离开来，如下 (it.hasNext()) &#123;123 Book book = (Book)it.next(); System.out.println(book.getName());&#125; 这里只使用了Iterator的next和hasNext，并没有调用Bookshelf的方法，也就是说，这里的while循环并不依赖Bookshelf的实现。 如果Bookshelf的开发人员放弃ArrayList来管理书本，而是用vector来取而代之，不管Bookshelf如何变化，只要Bookshelf的iterator方法能够正确返回Iterator的实例，即使不对while的循环作任何修改，代码都可以正常工作。 如果只使用具体的类来解决问题，很容易导致类之间的强耦合，这些类也难以作为组件被再次利用。为了弱化类之间的耦合，进而使得类更加容易作为组件被再次利用，我们需要引入抽象类和接口。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫分析微信好友]]></title>
    <url>%2F2017%2F12%2F10%2Findex%2F</url>
    <content type="text"><![CDATA[昨晚了解到Python的itchat包，很强，已经完成了wechat的个人账号API接口，就可以用他来做很多数据分析的有趣事情了。首先引入各个包 itchat # itchat documentation -- https:/ itchat.readthedocs.io/zh/latest/api/1234567891011import matplotlib.pyplot as pltimport seaborn as snsimport numpy as npimport pandas as pdimport refrom wordcloud import WordCloud, ImageColorGeneratorimport PIL.Image as Image # pillowimport jieba # chinese word segementation toolfrom matplotlib.font_manager import FontProperties# since matplotlib and pandas.plot cannot display chinesefont = FontProperties(fname=&apos;./data/test.ttf&apos;, size=14) # load chinese font 引入包时遇到很多麻烦，首先很多包不支持3.7，然后我又下了个3.6的，应该把2.7的也下载，Python的版本啊~~~~ 我一般直接用Pycharm的直接下载，但到了wordcloud却不支持了，经过我不懈的查找，踩了很多坑，在stackOverflow查到了 download wordcloud‑1.3.2‑cp36‑cp36m‑win_amd64.whl from http://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud Copy the file to your current working directory Open command prompt from Tools python -m pip install wordcloud-1.3.2-cp36-cp36m-win_amd64.whl 然后登陆网页版微信获取好友数据#login, default a QR code will be generated, scan for login itchat.login() friends = itchat.get_friends(update=True)[0:] # get all friends print(friends[0]) # the first one is yourself 扫描二维码来登陆即可对我好友的男女比例进行统计`male, female, others = get_male_female_count(friends[1:]) total = len(friends[1:]) print(&apos;Male population: {:d}, ratio: {:.4f}&apos;.format(male, male / float(total))) print(&apos;Female population: {:d}, ratio: {:.4f}&apos;.format(female, female / float(total))) print(&apos;Others: {:d}, ratio: {:.4f}&apos;.format(others, others / float(total)))` 函数： `def get_male_female_count(friends): male = 0 female = 0 others = 0 for friend in friends: sex = friend[&apos;Sex&apos;] if sex == 1: male += 1 elif sex == 2: female += 1 else: others += 1 return male, female, others` 用PIL画图 `# plot male-female-ratio index = np.arange(3) genders = (male, female, others) bar_width = 0.35 plt.figure(figsize=(14, 7)) plt.bar(index, genders, bar_width, alpha=0.6, color=&apos;rgb&apos;) plt.xlabel(&apos;Gender&apos;, fontsize=16) plt.ylabel(&apos;Population&apos;, fontsize=16) plt.title(&apos;Male-Female Population&apos;, fontsize=18) plt.xticks(index, (&apos;Male&apos;, &apos;Female&apos;, &apos;Others&apos;), fontsize=14, rotation=20) plt.ylim(0, 220) for idx, gender in zip(index, genders): plt.text(idx, gender + 0.1, &apos;%.0f&apos; % gender, ha=&apos;center&apos;, va=&apos;bottom&apos;, fontsize=14, color=&apos;black&apos;) plt.show()` 结果嘛为什么这么少呢，哦，好像前阵子删除了很多无联系的账号，重点是比例，ozx。 对好友城市的分布也做了分析`# extract the variables: NickName, Sex, City, Province, Signature def get_features(friends): features = [] for friend in friends: feature = {&apos;NickName&apos;: friend[&apos;NickName&apos;], &apos;Sex&apos;: friend[&apos;Sex&apos;], &apos;City&apos;: friend[&apos;City&apos;], &apos;Province&apos;: friend[&apos;Province&apos;], &apos;Signature&apos;: friend[&apos;Signature&apos;]} features.append(feature) return pd.DataFrame(features) features = get_features(friends[1:]) print(features.columns) features.head() locations = features.loc[:, [&apos;Province&apos;, &apos;City&apos;]] # get location columns locations = locations[locations[&apos;Province&apos;] != &apos;&apos;] # clean empty city or province records data = locations.groupby([&apos;Province&apos;, &apos;City&apos;]).size().unstack() # group by and count count_subset = data.take(data.sum(1).argsort())[-20:] # obtain the 20 highest data # plot subset_plot = count_subset.plot(kind=&apos;bar&apos;, stacked=True, figsize=(24, 24))` 结果都是广东的多，其他的几乎没有。 将好友的个性签名用wordcloud生成词云` set fonts xtick_labels = subset_plot.get_xticklabels() for label in xtick_labels: label.set_fontproperties(font) legend_labels = subset_plot.legend().texts for label in legend_labels: label.set_fontproperties(font) label.set_fontsize(10) plt.xlabel(&apos;Province&apos;, fontsize=20) plt.ylabel(&apos;Number&apos;, fontsize=20) plt.show() sigature_list = [] for signature in features[&apos;Signature&apos;]: signature = signature.strip().replace(&apos;span&apos;, &apos;&apos;).replace(&apos;class&apos;, &apos;&apos;).replace(&apos;emoji&apos;, &apos;&apos;) # re.compile(ur&apos;[^a-zA-Z0-9\u4e00-\u9fa5 ]&apos;).sub(&apos;&apos;, signature) signature = re.compile(&apos;1f\d+\w*|[&lt;&gt;/=]&apos;).sub(&apos;&apos;, signature) if (len(signature) &gt; 0): sigature_list.append(signature) text = &apos;&apos;.join(sigature_list) # print(text) word_list = jieba.cut(text, cut_all=True) words = &apos; &apos;.join(word_list) # print(words) coloring = np.array(Image.open(&apos;./data/wechat3.png&apos;)) wc = WordCloud(background_color=&apos;white&apos;, max_words=2000, mask=coloring, max_font_size=60, random_state=42, font_path=&apos;./data/test.ttf&apos;, scale=2).generate(words) image_color = ImageColorGenerator(coloring) plt.figure(figsize=(32, 16)) plt.imshow(wc.recolor(color_func=image_color)) plt.imshow(wc) plt.axis(&apos;off&apos;) plt.show()` 结果啊 我的好友还是很积极向上的，学习奋斗和努力还是有一定比例的，喜欢也可以理解，但为何生活人生世界这么大比例，ozx，这么多人看破尘世了？还是鸡汤看多了。 参考 https://github.com/amueller/word_cloud https://github.com/littlecodersh/ItChat http://www.36dsj.com/archives/88199 https://isaacchanghau.github.io/2017/09/10/Python-itchat%E5%8C%85%E5%88%86%E6%9E%90%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B/]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[热度榜]]></title>
    <url>%2F2017%2F12%2F10%2Fpage%2F</url>
    <content type="text"><![CDATA[AV.initialize("", "");热度排行Top： var time=0 var title="" var url="" var query = new AV.Query('Counter');//表名 query.notEqualTo('id',0); //id不为0的结果 query.descending('time'); //结果按阅读次数降序排序 query.limit(20); //最终只返回10条结果 query.find().then(function (todo) { for (var i=0;i]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F12%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[优秀的人，不是不合群，而是他们合群的人里面没有你Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 最近访客]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>杂文</tag>
      </tags>
  </entry>
</search>
