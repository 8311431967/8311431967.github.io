<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[sql的执行顺序]]></title>
    <url>%2F2019%2F02%2F20%2Fsql%E7%9A%84q%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[SQL语言不同于其他编程语言的最明显特征是处理代码的顺序。在大多数据库语言中，代码按编码顺序被处理。但在SQL语句中，第一个被处理的子句式FROM，而不是第一出现的SELECT。SQL查询处理的步骤序号： sql 的select语句的完整执行顺序 from字句组装来自不同的数据源的数据 join table连接 on where 字句基于指定条件对纪录进行筛选 group by字句将数据分为多个分组 使用聚集函数进行计算 with{cube|rollup} having 计算所有表达式 select distinct order by 以上每个步骤都会产生一个虚拟表，该虚拟表被用作下一个步骤的输入。这些虚拟表对调用者(客户端应用程序或者外部查询)不可用。只有最后一步生成的表才会会给调用者。如果没有在查询中指定某一个子句，将跳过相应的步骤。 逻辑查询处理阶段简介： 1、 FROM：对FROM子句中的前两个表执行笛卡尔积(交叉联接)，生成虚拟表VT1。 2、 ON：对VT1应用ON筛选器，只有那些使为真才被插入到TV2。 3、 OUTER (JOIN):如果指定了OUTER JOIN(相对于CROSS JOIN或INNER JOIN)，保留表中未找到匹配的行将作为外部行添加到VT2，生成TV3。如果FROM子句包含两个以上的表，则对上一个联接生成的结果表和下一个表重复执行步骤1到步骤3，直到处理完所有的表位置。 4、 WHERE：对TV3应用WHERE筛选器，只有使为true的行才插入TV4。 5、 GROUP BY：按GROUP BY子句中的列列表对TV4中的行进行分组，生成TV5。 6、 CUTE|ROLLUP：把超组插入VT5，生成VT6。 7、 HAVING：对VT6应用HAVING筛选器，只有使为true的组插入到VT7。 8、 SELECT：处理SELECT列表，产生VT8。 9、 DISTINCT：将重复的行从VT8中删除，产品VT9。 10、ORDER BY：将VT9中的行按ORDER BY子句中的列列表顺序，生成一个游标(VC10)。 11、TOP：从VC10的开始处选择指定数量或比例的行，生成表TV11，并返回给调用 联合查询时过滤条件放在ON之后和放在WHERE之后的区别 有两个表，A表和B表，我们经常会通过一些关键字段来联合查询两张表里的数据，如: select * from A left join B on A.bizNo = B.bizNo 如果我们想要在上述条件上再增加一些过滤条件，比如B.name = ‘XXX’。 那么我们有两种写法: 写法1: select * from A left join B on A.bizNo = B.bizNo and B.name = ‘XXX’ 写法2: select * from A left join B on A.bizNo = B.bizNo where B.name = ‘XXX’ 这两种写法的区别在于，过滤条件放在ON的后面是在联合之前就进行过滤，放在WHERE后面是在联合之后的结果集上进行过滤。 如果A的记录在B中都能够查到数据的话，那么两种写法的结果是一样的。 否则会有差别，假如A中有两条记录a1,a2，其中a1可以在B中查到记录，a2无法查到记录。 那么在写法1的情况下，最终的结果集会有两条记录如下: a1 b1 a2 null 在写法2的情况下，最终的结果集只有一条记录: a1 b1]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何判断一个元素在亿级数据中是否存在]]></title>
    <url>%2F2019%2F02%2F20%2F%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0%E5%9C%A8%E4%BA%BF%E7%BA%A7%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%2F</url>
    <content type="text"><![CDATA[前言看到的一道面试题 现在有一个非常庞大的数据，假设全是 int 类型。现在我给你一个数，你需要告诉我它是否存在其中(尽量高效)。 常规实现用hashMap来存放数据，他的写效率都非常高 单测用HashSet，底层也是Hashmap 12345678910111213@Testpublic void hashMapTest() &#123; long start = System.currentTimeMillis(); Set&lt;Integer&gt; hashSet = new HashSet&lt;&gt;(); for (int i = 0; i &lt; 100; i++) &#123; hashSet.add(i); &#125; Assert.assertTrue(hashSet.contains(67)); Assert.assertTrue(hashSet.contains(670)); long end = System.currentTimeMillis(); System.out.println(end-start);&#125; 100没有问题尝试1千万，就内存溢出了 可见在内存有限的情况下我们不能使用这种方式。 实际情况也是如此；既然要判断一个数据是否存在于集合中，考虑的算法的效率以及准确性肯定是要把数据全部 load 到内存中的。 BloomFilter基于上面分析的条件，要实现这个需求最需要解决的是 如何将庞大的数据load到内存中。 而我们是否可以换种思路，因为只是需要判断数据是否存在，也不是需要把数据查询出来，所以完全没有必要将真正的数据存放进去。 伟大的科学家们已经帮我们想到了这样的需求。 BurtonHowardBloom 在 1970 年提出了一个叫做 BloomFilter（中文翻译：布隆过滤）的算法。 它主要就是用于解决判断一个元素是否在一个集合中，但它的优势是只需要占用很小的内存空间以及有着高效的查询效率。 所以在这个场景下在合适不过了。 Bloom Filter 原理下面来分析下它的实现原理 官方的说法是：它是一个保存了很长的二级制向量，同时结合 Hash 函数实现的。 如图所示： 首先需要初始化一个二进制的数组，长度设为 L（图中为 8），同时初始值全为 0 。 当写入一个 A1=1000 的数据时，需要进行 H 次 hash 函数的运算（这里为 2 次）；与 HashMap 有点类似，通过算出的 HashCode 与 L 取模后定位到 0、2 处，将该处的值设为 1。 A2=2000 也是同理计算后将 4、7 位置设为 1。 当有一个 B1=1000 需要判断是否存在时，也是做两次 Hash 运算，定位到 0、2 处，此时他们的值都为 1 ，所以认为 B1=1000 存在于集合中。 当有一个 B2=3000 时，也是同理。第一次 Hash 定位到 index=4 时，数组中的值为 1，所以再进行第二次 Hash 运算，结果定位到 index=5 的值为 0，所以认为 B2=3000 不存在于集合中。 整个的写入、查询的流程就是这样，汇总起来就是： 对写入的数据做 H 次 hash 运算定位到数组中的位置，同时将数据改为 1 。当有数据查询时也是同样的方式定位到数组中。一旦其中的有一位为 0 则认为数据肯定不存在于集合，否则数据可能存在于集合中。 所以布隆过滤有以下几个特点： 只要返回数据不存在，则肯定不存在。 返回数据存在，但只能是大概率存在。 同时不能清除其中的数据。 第一点应该都能理解，重点解释下 2、3 点。 为什么返回存在的数据却是可能存在呢，这其实也和 HashMap 类似。 在有限的数组长度中存放大量的数据，即便是再完美的 Hash 算法也会有冲突，所以有可能两个完全不同的 A、B 两个数据最后定位到的位置是一模一样的。 这时拿 B 进行查询时那自然就是误报了。 删除数据也是同理，当我把 B 的数据删除时，其实也相当于是把 A 的数据删掉了，这样也会造成后续的误报。 基于以上的 Hash 冲突的前提，所以 BloomFilter 有一定的误报率，这个误报率和 Hash 算法的次数 H，以及数组长度 L 都是有关的。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结排序算法]]></title>
    <url>%2F2019%2F02%2F16%2F%E6%80%BB%E7%BB%93%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法的总结 算法分类 比较和非比较的区别常见的快速排序、归并排序、堆排序、冒泡排序等属于比较排序 在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置。 在冒泡排序之类的排序中，问题规模为n，又因为需要比较n次，所以平均时间复杂度为O(n²)。 在归并排序、快速排序之类的排序中，问题规模通过分治法消减为logN次，所以时间复杂度平均O(nlogn)。 比较排序的优势是，适用于各种规模的数据，也不在乎数据的分布，都能进行排序。可以说，比较排序适用于一切需要排序的情况。 计数排序、基数排序、桶排序属于非比较排序针对数组arr，计算arr[i]之前有多少个元素，则唯一确定了arr[i]在排序后数组中的位置。 非比较排序只要确定每个元素之前的已有的元素个数即可，所有一次遍历即可解决。算法时间复杂度O(n)。 非比较排序时间复杂度底，但由于非比较排序需要占用空间来确定唯一位置。所以对数据规模和数据分布有一定的要求。 冒泡排序（bubble sort)冒泡排序是一种简单的排序算法，他重复地走过要排列的数列，一次比较两个元素，如果他们的顺序错误就交换过来 走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成 动图演示 代码演示： 123456789101112131415public int[] bubbleSort(int[] array) &#123; if (array.length==0) return array; for (int i = 0; i &lt; array.length-1; i++) &#123; for (int j = 0; j&lt;array.length-i-1; j++)&#123; if(array[j]&gt;array[j+1]) &#123; int tmp = array[j]; array[j] = array[j+1]; array[j+1] = tmp; &#125; &#125; &#125; return array;&#125; 算法分析: 最佳T(n) = O(n)最差T(n) = O(n^2)平均T(n) = O(n^2) 选择排序表现稳定，因为无论什么数据进去都是O(n^2)的时间复杂度，所以用到他时，数据规模越小越好。 它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 代码实现： 12345678910111213141516public int[] selectSort(int[] array) &#123; if (array.length == 0) return array; for (int i = 0; i &lt; array.length-1; i++) &#123; int minIndex = i; for (int j = i+1; j &lt; array.length; j++) &#123; if (array[minIndex] &gt; array[j]) &#123; minIndex = j; &#125; &#125; int tmp = array[minIndex]; array[minIndex] = array[i]; array[i] = tmp; &#125; return array;&#125; 算法分析：最佳情况：T(n) = O(n2) 最差情况：T(n) = O(n2) 平均情况：T(n) = O(n2) 插入排序工作原理：对于未排序的数据，在已经排序中从后向前扫描，找到相应位置并插入 动图演示： 代码实现： 1234567891011121314151617public static int[] insertSort(int[] array) &#123; if (array.length == 0) &#123; return array; &#125; int current= 0; for (int i = 0; i &lt; array.length-1; i++) &#123; int preIndex = i; current =array[i+1]; while (preIndex&gt;=0&amp;&amp; current&lt;array[preIndex])&#123; array[preIndex+1] = array[preIndex]; preIndex--; &#125; array[preIndex+1] = current; &#125; return array; &#125; 算法分析： 最佳情况：T(n) = O(n) 最坏情况：T(n) = O(n2) 平均情况：T(n) = O(n2) 希尔排序希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破O(n2）的第一批算法之一。 它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。 希尔排序是把记录按下表的一定增量分组，对每组使用直接插入排序算法排序； 随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 动图展示： 代码实现 1234567891011121314151617181920public static int[] shellSort(int[] array) &#123; if (array.length== 0) return array; int len = array.length; int gap = len/2; while (gap&gt;0) &#123; for (int i = gap; i&lt;len; i+=gap) &#123; int tmp = array[i]; int preIndex = i-gap; while (preIndex&gt;=0 &amp;&amp; array[preIndex] &gt; tmp) &#123; array[preIndex+gap] = array[preIndex]; preIndex-=gap; &#125; array[preIndex+gap] = tmp; &#125; gap/=2; &#125; return array;&#125; 算法分析最佳情况：T(n) = O(nlog2 n) 最坏情况：T(n) = O(nlog2 n) 平均情况：T(n) =O(nlog2n) 归并排序和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(n log n）的时间复杂度。 代价是需要额外的内存空间。 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并 动图演示 代码实现： 1234567891011121314151617181920212223242526272829public static int[] mergeSort(int []array) &#123; if (array.length&lt;2) &#123; return array; &#125; int len = array.length; int mid = len/2; int []left = Arrays.copyOfRange(array,0,mid); int []right = Arrays.copyOfRange(array,mid,len); return merge(mergeSort(left),mergeSort(right));&#125;public static int[] merge(int []left, int []right) &#123; int[] result = new int[left.length+right.length]; int l=0; int r = 0; for (int i = 0 ; i &lt; left.length || i&lt;result.length; i++) &#123; if (l&gt;=left.length)&#123; result[i] = right[r++]; &#125;else if (r&gt;=right.length) &#123; result[i] = left[l++]; &#125;else if (left[l]&lt;right[r])&#123; result[i] = left[l++]; &#125;else &#123; result[i] = right[r++]; &#125; &#125; return result;&#125; 算法分析: 最佳情况：T(n) = O(n) 最差情况：T(n) = O(nlogn) 平均情况：T(n) = O(nlogn) 快速排序快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。即每次使一个数达到要求，而且左边的小于他，右边的大于他。 动图展示： 123456789101112131415161718192021public static void quickSort(int []array, int start, int end) &#123; if (start &gt;= end) return ; int pivot = partion(array, start,end); quickSort(array,start,pivot-1); quickSort(array,pivot+1,end);&#125;public static int partion(int[] array, int low, int high) &#123; int pivot = array[low];//枢轴纪录 while (low&lt;high) &#123; while (low&lt;high &amp;&amp; array[high]&gt;pivot) --high; array[low] = array[high];//交换比枢轴小的 while (low&lt;high &amp;&amp; array[low]&lt;pivot) ++low; array[high] = array[low];//交换比枢轴大的 &#125; array[low] = pivot; //返回枢轴的位置 return low;&#125; 算法分析 最佳情况：T(n) = O(nlogn) 最差情况：T(n) = O(n2) 平均情况：T(n) = O(nlogn) 堆排序堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 算法描述：先建立最大堆，然后交换把堆顶交换到尾部，然后再次成立最大堆，循环执行，最后形成从小到大排列 动图展示： 代码展示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static int len;public static void main(String[] args)&#123; int[] array = &#123;1,2,4,6,5,9,8,7,3&#125;; int[] newArray = HeapSort(array); for (int i = 0; i &lt; newArray.length; i++) &#123; System.out.print(array[i]); &#125;&#125;public static int[] HeapSort(int[] array) &#123; len = array.length; if (len &lt; 1) return array; //1.构建一个最大堆 buildMaxHeap(array); //2.循环将堆首位（最大值）与末位交换，然后在重新调整最大堆 while (len &gt; 0) &#123; swap(array, 0, len - 1); len--; adjustHeap(array, 0); &#125; return array;&#125;/** * 建立最大堆 * * @param array */public static void buildMaxHeap(int[] array) &#123; //从最后一个非叶子节点开始向上构造最大堆 for (int i = (len - 1) / 2; i &gt;= 0; i--) &#123; adjustHeap(array, i); &#125;&#125;/** * 调整使之成为最大堆 * * @param array * @param i */public static void adjustHeap(int[] array, int i) &#123; int maxIndex = i; //如果有左子树，且左子树大于父节点，则将最大指针指向左子树 if (i * 2 &lt; len &amp;&amp; array[i * 2] &gt; array[maxIndex]) maxIndex = i * 2; //如果有右子树，且右子树大于父节点，则将最大指针指向右子树 if (i * 2 + 1 &lt; len &amp;&amp; array[i * 2 + 1] &gt; array[maxIndex]) maxIndex = i * 2 + 1; //如果父节点不是最大值，则将父节点与最大值交换，并且递归调整与父节点交换的位置。 if (maxIndex != i) &#123; swap(array, maxIndex, i); adjustHeap(array, maxIndex); &#125;&#125;public static void swap(int[] array, int x,int y) &#123; int temp = array[x]; array[x] = array[y]; array[y] = temp;&#125; 算法分析 最佳情况：T(n) = O(nlogn) 最差情况：T(n) = O(nlogn) 平均情况：T(n) = O(nlogn) 计数排序计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。 然后根据数组C来将A中的元素排到正确的位置。它只能对整数进行排序 动图展示： 代码展示： 123456789101112131415161718192021222324252627public static int[] CountingSort(int[] array) &#123; if (array.length == 0) return array; int bias, min = array[0], max = array[0]; for (int i = 1; i &lt; array.length; i++) &#123; if (array[i] &gt; max) max = array[i]; if (array[i] &lt; min) min = array[i]; &#125; bias = 0 - min; int[] bucket = new int[max - min + 1]; Arrays.fill(bucket, 0); for (int i = 0; i &lt; array.length; i++) &#123; bucket[array[i] + bias]++; &#125; int index = 0, i = 0; while (index &lt; array.length) &#123; if (bucket[i] != 0) &#123; array[index] = i - bias; bucket[i]--; index++; &#125; else i++; &#125; return array; &#125; 算法分析 当输入的元素是n 个0到k之间的整数时，它的运行时间是 O(n + k)。 计数排序不是比较排序，排序的速度快于任何比较排序算法。 由于用来计数的数组C的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。 最佳情况：T(n) = O(n+k) 最差情况：T(n) = O(n+k) 平均情况：T(n) = O(n+k) 桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。 桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排 9.1 算法描述人为设置一个BucketSize，作为每个桶所能放置多少个不同数值（例如当BucketSize==5时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放100个3）； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序； 从不是空的桶里把排好序的数据拼接起来。 注意，如果递归使用桶排序为各个桶排序，则当桶数量为1时要手动减小BucketSize增加下一循环桶的数量，否则会陷入死循环，导致内存溢出。 代码展示： 12345678910111213141516171819202122232425262728293031public static ArrayList BucketSort(ArrayList&lt;Integer&gt; array, int bucketSize) &#123; if (array == null || array.size() &lt; 2) return array; int max = array.get(0); int min = array.get(0); // 找到最大值最小值 for (int i = 0; i &lt; array.size(); i++) &#123; if (array.get(i) &gt; max) max = array.get(i); if (array.get(i) &lt; min) min = array.get(i); &#125; int bucketCount = (max - min) / bucketSize + 1; ArrayList&lt;ArrayList&gt; bucketArr = new ArrayList&lt;&gt;(bucketCount); ArrayList resultArr = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bucketCount; i++) &#123; bucketArr.add(new ArrayList()); &#125; for (int i = 0; i &lt; array.size(); i++) &#123; bucketArr.get((array.get(i) - min) / bucketSize).add(array.get(i)); &#125; for (int i = 0; i &lt; bucketCount; i++) &#123; if (bucketCount == 1) bucketSize--; ArrayList temp = BucketSort(bucketArr.get(i), bucketSize); for (int j = 0; j &lt; temp.size(); j++) resultArr.add(temp.get(j)); &#125; return resultArr;&#125; 算法分析桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 最佳情况：T(n) = O(n+k) 最差情况：T(n) = O(n+k) 平均情况：T(n) = O(n2) 基数排序（Radix Sort）基数排序也是非比较的排序算法，对每一位进行排序，从最低位开始排序，复杂度为O(kn),为数组长度，k为数组中的数的最大的位数； 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。 有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。 最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。 动图展示： 代码： 1234567891011121314151617181920212223242526272829303132 public static int[] RadixSort(int[] array) &#123; if (array == null || array.length &lt; 2) return array; // 1.先算出最大数的位数； int max = array[0]; for (int i = 1; i &lt; array.length; i++) &#123; max = Math.max(max, array[i]); &#125; int maxDigit = 0; while (max != 0) &#123; max /= 10; maxDigit++; &#125; int mod = 10, div = 1; ArrayList&lt;arraylist&gt; bucketList = new ArrayList&lt;arraylist&gt;(); for (int i = 0; i &lt; 10; i++) bucketList.add(new ArrayList()); for (int i = 0; i &lt; maxDigit; i++, mod *= 10, div *= 10) &#123; for (int j = 0; j &lt; array.length; j++) &#123; int num = (array[j] % mod) / div; bucketList.get(num).add(array[j]); &#125; int index = 0; for (int j = 0; j &lt; bucketList.size(); j++) &#123; for (int k = 0; k &lt; bucketList.get(j).size(); k++) array[index++] = bucketList.get(j).get(k); bucketList.get(j).clear(); &#125; &#125; return array;&#125; 算法分析最佳情况：T(n) = O(n * k) 最差情况：T(n) = O(n * k) 平均情况：T(n) = O(n * k) 基数排序有两种方法： MSD 从高位开始进行排序 LSD 从低位开始进行排序 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统相关知识点]]></title>
    <url>%2F2019%2F02%2F16%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[前言为了面试而翻起操作系统这本大book 进程间的通信方式(IPC) 共享内存 消息队列 信号 信号量 套接字 普通管道 有名管道 进程调度方法 先来先服务调度算法 短作业进程优先 优先权调度算法 高响应比优先调度算法 轮转法 多级反馈队列调度 线程间的通信方式锁机制: 互斥锁 条件变量 读写锁 信号量机制： 无名线程信号量和命名线程信号量 信号机制：类似进程间的信号处理机制 线程间的通信目的主要是用于线程同步，所以线程没有想进程通信中的用于数据交换的通信机制 ###操作系统组成部分 进程管理：实质上是对处理机执行“时间”的管理，即如何将CPU真正合理地分配给每个任务。 存储管理：实质是对存储“空间”的管理，主要指对主存的管理； 设备管理：实质是对硬件设备的管理，其中包括对输入输出设备的分配、启动、完成和回收 文件管理：又称为信息管理 程序接口 用户界面 用户态和系统态在什么时候进行切换？ 平时用的都是 64 位系统，那它和 32 位系统相比， 有什么区别和优点？以下三种情况会导致由用户态到内核态的切换 系统调用 异常，如缺页中断 外围设备的终端，当外围设备完成用户请求的操作，回向cpu发出中断操作 1）选址能力不同 2）计算速度不同 选择一个你熟悉的磁盘臂调度算法进行简单描 先来先服务： 这种算法的思想比较容易理解。假设当前磁道在某一位置，依次处理服务队列里的每一个磁道，这样做的优点是处理起来比较简单，但缺点是磁头移动的距离和平均移动距离会很大。 最短寻道时间优先算法：这种算法的本质是利用贪心算法来实现，假设当前磁道在某一位置，接下来处理的是距离当前磁道最近的磁道号，处理完成之后再处理离这个磁道号最近的磁道号，直到所有的磁道号都服务完了程序结束。这样做的优点是性能会优于FIFO算法，但是会产生距离当前磁道较远的磁道号长期得不到服务，也就是“饥饿”现象，因为要求访问的服务的序列号是动态产生的，即各个应用程序可能不断地提出访问不同的磁道号的请求。 scan算法：也就是很形象的电梯调度算法。先按照一个方向(比如从外向内扫描)，扫描的过程中依次访问要求服务的序列。当扫描到最里层的一个服务序列时反向扫描，这里要注意，假设最里层为0号磁道，最里面的一个要求服务的序列是5号，访问完5号之后，就反向了，不需要再往里扫。结合电梯过程更好理解，在电梯往下接人的时候，明知道最下面一层是没有人的，它是不会再往下走的 cscan算法：循环扫描算法，来看一下上一种算法，有什么问题。仔细一看，我们会发现，在扫描到最里面的要求服务的序列时，接着会反向，在接下来的很大一部分时间里，应该是没有要求服务的磁道号的，因为之前已经访问过了。什么意思，就是说从初始磁道号到最里层的一个磁道号之间的所有序列都已经访问过了，所以SCAN会增加等待的时间。为了解决这样的情况，CSCAN算法的思想是，访问完最里面一个要求服务的序列之后，立即回到最外层欲访问磁道。也就是始终保持一个方向。故也称之为单向扫描调度算法。从最里面的一个磁道立即回到最外层欲访问的磁道，这步的距离是两者磁道号差的绝对值。 进程和线程的区别 调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位 并发行：不仅进程之间可以并发执行，同一个进程的多个线程也可以并发执行 拥有资源：进程是拥有资源的一个独立单位， 线程自己基本上不拥有系统资源， 只拥有一点在运行中必不可少的资源（如程序计数器、 一组寄存器和栈),但是它可以与同属一个进程的其他线程共享进程所拥有的全部资源。 进程之间是不能共享地址空间的, 而线程是共享着所在进程的地址空间的 系统开销： 在创建或撤销进程是由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤销线程时的开销。 操作系统的换页方法opt：最佳替换算法（optional replacement）。替换下次访问距当前时间最长的页。opt算法需要知道操作系统将来的事件，显然不可能实现，只作为一种衡量其他算法的标准。 LRU:最近最少使用(Least Recently Used).替换上次使用距离当前最远的页。根据局部性原理：替换最近最不可能 访问到的页。性能最接近OPT，但难以实现。可以维护一个关于访问页的栈或者给每个页添加最后访问的时间标签，但开销都很大 FIFO:先进先出(First In First Out),将页面看做一个循环缓冲区，按循环方式替换。这是实现最为简单的算法，隐含的逻辑是替换驻留在内存时间最长的页。但由于一部分程序或数据在整个程序的生命周期中使用频率很高，所以会导致反复的换入换出 clock: 时钟替换算法（Clock）,给每个页帧关联一个使用位。当该页第一次装入内存或者被重新访问到时，将使用位置为1。每次需要替换时，查找使用位被置为0的第一个帧进行替换。在扫描过程中，如果碰到使用位为1的帧，将使用位置为0，在继续扫描。如果所谓帧的使用位都为0，则替换第一个帧 图解： 操作系统的内存管理计算机存储的层次结构图 内存管理方法内存管理主要包括虚地址、地址变换、内存分配和回收、内存扩充、内存共享和保护等功能。 连续分配存储管理方式连续分配是指为一个用户程序分配连续的内存空间，连续分配有单一连续存储管理和分区式储管理两种方式 单一连续存储管理 在这种管理方式中，内存被分为两个区域：系统区和用户区。应用程序装入到用户区，可使用用户区全部空间。其特点是，最简单，适用于单用户、单任务的操作系统。CP／M和 DOS 2．0以下就是采用此种方式。这种方式的最大优点就是易于管理。但也存在着一些问题和不足之处，例如对要求内存空间少的程序，造成内存浪费；程序全部装入，使得很少使用的程序部分也占用—定数量的内存 分区式存储管理为了支持多道程序系统和分时系统，支持多个程序并发执行，引入了分区式存储管理。分区式存储管理是把内存分为一些大小相等或不等的分区，操作系统占用其中一个分区，其余的分区由应用程序使用，每个应用程序占用一个或几个分区。分区式存储管理虽然可以支持并发，但难以进行内存分区的共享。 分区式存储管理引人了两个新的问题：内碎片和外碎片。内碎片是占用分区内未被利用的空间，外碎片是占用分区之间难以利用的空闲分区(通常是小空闲分区)。 为实现分区式存储管理，操作系统应维护的数据结构为分区表或分区链表。表中各表项一般包括每个分区的起始地址、大小及状态(是否已分配)。 分区式存储管理常采用的一项技术就是内存紧缩(compaction)。 固定分区固定式分区的特点是把内存划分为若干个固定大小的连续分区。分区大小可以相等：这种作法只适合于多个相同程序的并发执行(处理多个类型相同的对象)。分区大小也可以不等：有多个小分区、适量的中等分区以及少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区 优点：易于实现，开销小。缺点：主要有两个：内碎片造成浪费；分区总数固定，限制了并发执行的程序数目。 动态分区动态分区的特点是动态创建分区：在装入程序时按其初始要求分配，或在其执行过程中通过系统调用进行分配或改变分区大小。与固定分区相比较其优点是：没有内碎片。但它却引入了另一种碎片——外碎片。动态分区的分区分配就是寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。分区分配的先后次序通常是从内存低端到高端。动态分区的分区释放过程中有一个要注意的问题是，将相邻的空闲分区合并成一个大的空闲分区。 下面列出了几种常用的分区分配算法： 最先适配法(nrst-fit)：按分区在内存的先后次序从头查找，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，较大的空闲分区可以被保留在内存高端。但随着低端分区不断划分会产生较多小分区，每次分配时查找时间开销便会增大。 下次适配法(循环首次适应算法 next fit)：按分区在内存的先后次序，从上次分配的分区起查找(到最后{区时再从头开始}，找到符合要求的第一个分区进行分配。该算法的分配和释放的时间性能较好，使空闲分区分布得更均匀，但较大空闲分区不易保留。 最佳适配法(best-fit)：按分区在内存的先后次序从头查找，找到其大小与要求相差最小的空闲分区进行分配。从个别来看，外碎片较小；但从整体来看，会形成较多外碎片优点是较大的空闲分区可以被保留。 最坏适配法(worst- fit)：按分区在内存的先后次序从头查找，找到最大的空闲分区进行分配。基本不留下小空闲分区，不易形成外碎片。但由于较大的空闲分区不被保留，当对内存需求较大的进程需要运行时，其要求不易被满足。 伙伴系统固定分区和动态分区方式都有不足之处。固定分区方式限制了活动进程的数目，当进程大小与空闲分区大小不匹配时，内存空间利用率很低。动态分区方式算法复杂，回收空闲分区时需要进行分区合并等，系统开销较大。伙伴系统方式是对以上两种内存方式的一种折衷方案。伙伴系统规定，无论已分配分区或空闲分区，其大小均为 2 的 k 次幂，k 为整数， l≤k≤m，其中： 2^1 表示分配的最小分区的大小， 2^m 表示分配的最大分区的大小， 通常 2^m是整个可分配内存的大小。假设系统的可利用空间容量为2^m个字， 则系统开始运行时， 整个内存区是一个大小为2^m的空闲分区。在系统运行过中， 由于不断的划分，可能会形成若干个不连续的空闲分区，将这些空闲分区根据分区的大小进行分类，对于每一类具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表。这样，不同大小的空闲分区形成了k(0≤k≤m)个空闲分区链表。 分配步骤：当需要为进程分配一个长度为n 的存储空间时: 首先计算一个i 值，使 2^(i－1) &lt;n ≤ 2^i，然后在空闲分区大小为2^i的空闲分区链表中查找。若找到，即把该空闲分区分配给进程。否则，表明长度为2^i的空闲分区已经耗尽，则在分区大小为2^(i＋1)的空闲分区链表中寻找。 若存在 2^(i＋1)的一个空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于配， 而把另一个加入分区大小为2^i的空闲分区链表中。 若大小为2^(i＋1)的空闲分区也不存在，则需要查找大小为2^(i＋2)的空闲分区， 若找到则对其进行两次分割： 第一次，将其分割为大小为 2^(i＋1)的两个分区，一个用于分配，一个加入到大小为 2^(i＋1)的空闲分区链表中； 第二次，将第一次用于分配的空闲区分割为 2^i的两个分区，一个用于分配，一个加入到大小为 2^i的空闲分区链表中。 若仍然找不到，则继续查找大小为 2^(i＋3)的空闲分区，以此类推。由此可见，在最坏的情况下，可能需要对 2^k的空闲分区进行 k 次分割才能得到所需分区。 与一次分配可能要进行多次分割一样，一次回收也可能要进行多次合并，如回收大小为2^i的空闲分区时，若事先已存在2^i的空闲分区时，则应将其与伙伴分区合并为大小为2^i＋1的空闲分区，若事先已存在2^i＋1的空闲分区时，又应继续与其伙伴分区合并为大小为2^i＋2的空闲分区，依此类推。在伙伴系统中，其分配和回收的时间性能取决于查找空闲分区的位置和分割、合并空闲分区所花费的时间。与前面所述的多种方法相比较，由于该算法在回收空闲分区时，需要对空闲分区进行合并，所以其时间性能比前面所述的分类搜索算法差，但比顺序搜索算法好，而其空间性能则远优于前面所述的分类搜索法，比顺序搜索法略差。 需要指出的是，在当前的操作系统中，普遍采用的是下面将要讲述的基于分页和分段机制的虚拟内存机制，该机制较伙伴算法更为合理和高效，但在多处理机系统中，伙伴系统仍不失为一种有效的内存分配和释放的方法，得到了大量的应用。 页式和段式存储管理前面的几种存储管理方法中，为进程分配的空间是连续的，使用的地址都是物理地址。如果允许将一个进程分散到许多不连续的空间，就可以避免内存紧缩，减少碎片。基于这一思想，通过引入进程的逻辑地址，把进程地址空间与实际存储空间分离，增加存储管理的灵活性。地址空间和存储空间两个基本概念的定义如下： 地址空间：将源程序经过编译后得到的目标程序，存在于它所限定的地址范围内，这个范围称为地址空间。地址空间是逻辑地址的集合。 存储空间：指主存中一系列存储信息的物理单元的集合，这些单元的编号称为物理地址存储空间是物理地址的集合。 根据分配时所采用的基本单位不同，可将离散分配的管理方式分为以下三种：页式存储管理、段式存储管理和段页式存储管理。其中段页式存储管理是前两种结合的产物。 页式存储管理将程序的逻辑地址空间划分为固定大小的页(page)，而物理内存划分为同样大小的页框(page frame)。程序加载时，可将任意一页放人内存中任意一个页框，这些页框不必连续，从而实现了离散分配。该方法需要CPU的硬件支持，来实现逻辑地址和物理地址之间的映射。在页式存储管理方式中地址结构由两部构成，前一部分是页号，后一部分为页内地址w（位移量），如图4所示： 页式管理方式的优点是： 1）没有外碎片，每个内碎片不超过页大比前面所讨论的几种管理方式的最大进步是， 2）一个程序不必连续存放。 3）便于改变程序占用空间的大小(主要指随着程序运行，动态生成的数据增多，所要求的地址空间相应增长)。 缺点是：要求程序全部装入内存，没有足够的内存，程序就不能执行。 段式存储管理在段式存储管理中，将程序的地址空间划分为若干个段(segment)，这样每个进程有一个二维的地址空间。在前面所介绍的动态分区分配方式中，系统为整个进程分配一个连续的内存空间。而在段式存储管理系统中，则为每个段分配一个连续的分区，而进程中的各个段可以不连续地存放在内存的不同分区中。程序加载时，操作系统为所有段分配其所需内存，这些段不必连续，物理内存的管理采用动态分区的管理方法。 在为某个段分配物理内存时，可以采用首先适配法、下次适配法、最佳适配法等方法。 在回收某个段所占用的空间时，要注意将收回的空间与其相邻的空间合并。 段式存储管理也需要硬件支持，实现逻辑地址到物理地址的映射。 程序通过分段划分为多个模块，如代码段、数据段、共享段： –可以分别编写和编译–可以针对不同类型的段采取不同的保护–可以按段为单位来进行共享，包括通过动态链接进行代码共享这样做的优点是：可以分别编写和编译源程序的一个文件，并且可以针对不同类型的段采取不同的保护，也可以按段为单位来进行共享。 总的来说，段式存储管理的优点是：没有内碎片，外碎片可以通过内存紧缩来消除；便于实现内存共享。缺点与页式存储管理的缺点相同，进程必须全部装入内存。 页式和段式管理的区别页式和段式系统有许多相似之处。比如，两者都采用离散分配方式，且都通过地址映射机构来实现地址变换。但概念上两者也有很多区别，主要表现在：1)、需求：是信息的物理单位，分页是为了实现离散分配方式，以减少内存的碎片，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要，而不是用户的需要。段是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了更好地满足用户的需要。一条指令或一个操作数可能会跨越两个页的分界处，而不会跨越两个段的分界处。2)、大小：页大小固定且由系统决定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的。段的长度不固定，且决定于用户所编写的程序，通常由编译系统在对源程序进行编译时根据信息的性质来划分。3)、逻辑地址表示：页式系统地址空间是一维的，即单一的线性地址空间，程序员只需利用一个标识符，即可表示一个地址。分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。4)、段比页大，因而段表比页表短，可以缩短查找时间，提高访问速度。 线程的同步机制 临界区（Critical Section)：通过对多线程的串行化来访问公共资源或一段代码， 速度快， 适合控制数据访问。 在任意时刻只允许一个线程对共享资源进行访问， 如果有多个线程试图访问公共资源， 那么在有一个线程进入后， 其他试图访问公共资源的线程将被挂起， 并一直等到进入临界区的线程离开， 临界区在被释放后， 其他线程才可以抢占。 互斥量（Mutex)：采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限， 因为互斥对象只有一个， 所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享， 还能实现不同应用程序的公共资源安全共享 信号量（semaphore）：它允许多个线程在同一时刻访问同一资源， 但是需要限制在同一时刻访问此资源的最大线程数目。 事件（Event）：通过通知操作的方式来保持线程的同步， 还可以方便实现对多个线程的优先级比较的操作]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>面试知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1-n中有多少个1]]></title>
    <url>%2F2019%2F01%2F30%2F1-n%E4%B8%AD%E6%9C%89%E5%A4%9A%E5%B0%91%E4%B8%AA1%2F</url>
    <content type="text"><![CDATA[题目给定一个整数 n，计算所有小于等于 n 的非负整数中数字 1 出现的个数。 示例: 输入: 13输出: 6解释: 数字 1 出现在以下数字中: 1, 10, 11, 12, 13 。 思路思路一从1到n，每个数再进行拆分，统计1的个数，显然这种方法不妥，当n等于一亿的时候，效率非常低。 思路二这时候只能到discuss上看一下别人的解法，比较震惊，这种解法很有技巧性。 代码 12345678int countDigitOne(int n) &#123; int ones = 0; for (long long m = 1; m &lt;= n; m *= 10) &#123; int a = n/m, b = n%m; ones += (a + 8) / 10 * m + (a % 10 == 1) * (b + 1); &#125; return ones;&#125; 原话 For each position, split the decimal representation into two parts, for example split n=3141592 into a=31415 and b=92 when we’re at m=100 for analyzing the hundreds-digit. And then we know that the hundreds-digit of n is 1 for prefixes “” to “3141”, i.e., 3142 times. Each of those times is a streak, though. Because it’s the hundreds-digit, each streak is 100 long. So (a / 10 + 1) 100 times, the hundreds-digit is 1. Consider the thousands-digit, i.e., when m=1000. Then a=3141 and b=592. The thousands-digit is 1 for prefixes “” to “314”, so 315 times. And each time is a streak of 1000 numbers. However, since the thousands-digit is a 1, the very last streak isn’t 1000 numbers but only 593 numbers, for the suffixes “000” to “592”. So (a / 10 1000) + (b + 1) times, the thousands-digit is 1. The case distincton between the current digit/position being 0, 1 and &gt;=2 can easily be done in one expression. With (a + 8) / 10 you get the number of full streaks, and aa % 10 == 1 tells you whether to add a partial streak. 个人理解 根据1，10.100，1000… 将n分为两部分,分别计算个位，十位，百位，千位上1的个数，如n=3141592 当m=100时，我们计算的是百位上1的个数，他的前缀是3141，又因为5&gt;1，所以共有3142m个1([a+8]/10m , +8的原因是0和1加八处以10没有意义，2以上+8就有进位)，但如果是3141192，百位上的是1，前面是就只有3141m个，还要根据后面有多少个数来决定有多少个1，应该是93个1（(a % 10 == 1) (b + 1)）。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从输入URL到页面加载发生了什么]]></title>
    <url>%2F2019%2F01%2F29%2F%E4%BB%8E%E8%BE%93%E5%85%A5URL%E5%88%B0%E9%A1%B5%E9%9D%A2%E5%8A%A0%E8%BD%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[前言知乎看到的面试题，一开始也答不上来，查阅相关资料写下笔记，顺便当是复习计算机网络了。 总体过程 dns解析 TCP请求 发送HTTP请求 服务器处理请求返回HTTP报文 浏览器解析渲染页面 连接结束 具体过程DNS解析DNS解析的过程就是寻找哪台机器上有你需要资源的过程。当你在浏览器中输入一个地址时，例如www.baidu.com，其实不是百度网站真正意义上的地址。互联网上每一台计算机的唯一标识是它的IP地址，但是IP地址并不方便记忆。用户更喜欢用方便记忆的网址去寻找互联网上的其它计算机，也就是上面提到的百度的网址。所以互联网设计者需要在用户的方便性与可用性方面做一个权衡，这个权衡就是一个网址到IP地址的转换，这个过程就是DNS解析。它实际上充当了一个翻译的角色，实现了网址到IP地址的转换。网址到IP地址转换的过程是如何进行的? 解析过程DNS解析是一个递归查询的过程。上述图片是查找www.google.com的IP地址过程。首先在本地域名服务器中查询IP地址，如果没有找到的情况下，本地域名服务器会向根域名服务器发送一个请求，如果根域名服务器也不存在该域名时，本地域名会向com顶级域名服务器发送一个请求，依次类推下去。直到最后本地域名服务器得到google的IP地址并把它缓存到本地，供下次查询使用。从上述过程中，可以看出网址的解析是一个从右向左的过程: com -&gt; google.com -&gt; www.google.com。但是你是否发现少了点什么，根域名服务器的解析过程呢？事实上，真正的网址是www.google.com.，并不是我多打了一个.，这个.对应的就是根域名服务器，默认情况下所有的网址的最后一位都是.，既然是默认情况下，为了方便用户，通常都会省略，浏览器在请求DNS的时候会自动加上，所有网址真正的解析过程为: . -&gt; .com -&gt; google.com. -&gt; www.google.com.。 TCP连接HTTP协议是使用TCP作为其传输层协议的，当TCP出现瓶颈时，HTTP也会受到影响。略，看另一篇博文。 HTTPS协议HTTP报文是包裹在TCP报文中发送的，服务器端收到TCP报文时会解包提取出HTTP报文。但是这个过程中存在一定的风险，HTTP报文是明文，如果中间被截取的话会存在一些信息泄露的风险。那么在进入TCP报文之前对HTTP做一次加密就可以解决这个问题了。HTTPS协议的本质就是HTTP + SSL(or TLS)。在HTTP报文进入TCP报文之前，先使用SSL对HTTP报文进行加密。从网络的层级结构看它位于HTTP协议与TCP协议之间。 HTTPS过程HTTPS在传输数据之前需要客户端与服务器进行一个握手(TLS/SSL握手)，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL使用了非对称加密，对称加密以及hash等。具体过程请参考经典的阮一峰先生的博客TLS/SSL握手过程。HTTPS相比于HTTP，虽然提供了安全保证，但是势必会带来一些时间上的损耗，如握手和加密等过程，是否使用HTTPS需要根据具体情况在安全和性能方面做出权衡。 HTTP请求HTTP请求报文是由三部分组成：请求行，请求报头，和请求正文。 请求行格式Method Request-URL HTTP-Version CRLF eg:GET index.html HTTP/1.1 常用的方法有: GET, POST, PUT, DELETE, OPTIONS, HEAD。 请求报头请求报头允许客户端向服务器传递请求的附加信息和客户端自身的信息。PS: 客户端不一定特指浏览器，有时候也可使用Linux下的CURL命令以及HTTP客户端测试工具等。常见的请求报头有: Accept, Accept-Charset, Accept-Encoding, Accept-Language, Content-Type, Authorization, Cookie, User-Agent等。 请求正文当使用POST, PUT等方法时，通常需要客户端向服务器传递数据。这些数据就储存在请求正文中。在请求包头中有一些与请求正文相关的信息，例如: 现在的Web应用通常采用Rest架构，请求的数据格式一般为json。这时就需要设置Content-Type: application/json。 服务器处理请求并返回HTTP报文然而然这部分对应的就是后端工程师眼中的HTTP。后端从在固定的端口接收到TCP报文开始，这一部分对应于编程语言中的socket。它会对TCP连接进行处理，对HTTP协议进行解析，并按照报文格式进一步封装成HTTP Request对象，供上层使用。这一部分工作一般是由Web服务器去进行，我使用过的Web服务器有Tomcat, Jetty和Netty等等。 HTTP响应报文也是三部分组成：状态码，响应报头，响应报文 状态码状态码是由3位数组成，第一个数字定义了响应的类别，且有五种可能取值: 1xx：指示信息–表示请求已接收，继续处理。 2xx：成功–表示请求已被成功接收、理解、接受。 3xx：重定向–要完成请求必须进行更进一步的操作。 4xx：客户端错误–请求有语法错误或请求无法实现。 5xx：服务器端错误–服务器未能实现合法的请求。 平时遇到比较常见的状态码有:200, 204, 301, 302, 304, 400, 401, 403, 404, 422, 500 响应报头常见的响应报头字段有: Server, Connection…。 响应报文服务器返回给浏览器的文本信息，通常HTML, CSS, JS, 图片等文件就放在这一部分。 浏览器解析渲染页面浏览器在收到HTML,CSS,JS文件后，它是如何把页面呈现到屏幕上的？下图对应的就是WebKit渲染的过程。 浏览器是一个边解析边渲染的过程。首先浏览器解析HTML文件构建DOM树，然后解析CSS文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。这个过程比较复杂，涉及到两个概念: reflow(回流)和repain(重绘)。DOM节点中的各个元素都是以盒模型的形式存在，这些都需要浏览器去计算其位置和大小等，这个过程称为relow;当盒模型的位置,大小以及其他属性，如颜色,字体,等确定下来之后，浏览器便开始绘制内容，这个过程称为repain。页面在首次加载时必然会经历reflow和repain。reflow和repain过程是非常消耗性能的，尤其是在移动设备上，它会破坏用户体验，有时会造成页面卡顿。所以我们应该尽可能少的减少reflow和repain。 JS的解析是由浏览器中的JS解析引擎完成的。JS是单线程运行，也就是说，在同一个时间内只能做一件事，所有的任务都需要排队，前一个任务结束，后一个任务才能开始。但是又存在某些任务比较耗时，如IO读写等，所以需要一种机制可以先执行排在后面的任务，这就是：同步任务(synchronous)和异步任务(asynchronous)。JS的执行机制就可以看做是一个主线程加上一个任务队列(task queue)。同步任务就是放在主线程上执行的任务，异步任务是放在任务队列中的任务。所有的同步任务在主线程上执行，形成一个执行栈;异步任务有了运行结果就会在任务队列中放置一个事件；脚本运行时先依次运行执行栈，然后会从任务队列里提取事件，运行任务队列中的任务，这个过程是不断重复的，所以又叫做事件循环(Event loop)。 浏览器在解析过程中，如果遇到请求外部资源时，如图像,iconfont,JS等。浏览器将重复1-6过程下载该资源。请求过程是异步的，并不会影响HTML文档进行加载，但是当文档加载过程中遇到JS文件，HTML文档会挂起渲染过程，不仅要等到文档中JS文件加载完毕还要等待解析执行完毕，才会继续HTML的渲染过程。原因是因为JS有可能修改DOM结构，这就意味着JS执行完成前，后续所有资源的下载是没有必要的，这就是JS阻塞后续资源下载的根本原因。CSS文件的加载不影响JS文件的加载，但是却影响JS文件的执行。JS代码执行前浏览器必须保证CSS文件已经下载并加载完毕。 Web优化上面部分主要介绍了一次完整的请求对应的过程，了解该过程的目的无非就是为了Web优化。在谈到Web优化之前，我们回到一个更原始的问题，Web前端的本质是什么。我的理解是: 将信息快速并友好的展示给用户并能够与用户进行交互。快速的意思就是在尽可能短的时间内完成页面的加载，试想一下当你在淘宝购买东西的时候，淘宝页面加载了10几秒才显示出物品，这个时候你还有心情去购买吗？怎么快速的完成页面的加载呢？优雅的学院派雅虎给出了常用的一些手段，也就是我们熟悉的https://developer.yahoo.com/performance/。这34军规实际上就是围绕请求过程进行的一些优化方式。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql的索引原理和运用]]></title>
    <url>%2F2019%2F01%2F29%2FMysql%E7%9A%84%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%92%8C%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[索引的目的在于提高查询，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？ 原理除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。 数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&gt;、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。 磁盘IO和预读寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17 = 9ms左右，听起来还挺不错的，但要知道一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。 考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。 索引的数据结构B+树 如上图，是一颗b+树，关于b+树的定义可以参见B+树，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 B+树的查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 b+树性质 通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 建立索引的原则 最左前缀匹配原则，非常重要，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 尽量选择分度高的列作为索引 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。 索引列不能参与计算 查询优化神器 - explain命令这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。 慢查询优化基本步骤 先运行看看是否真的很慢，注意设置SQL_NO_CACHE where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高 explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询） order by limit 形式的sql语句让排序的表优先查 了解业务方使用场景 加索引时参照建索引的几大原则 观察结果，不符合预期继续从0分析 索引类型 主键索引 PRIMARY KEY：它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引。注意：一个表只能有一个主键。 唯一索引 UNIQUE：唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。可以通过ALTER TABLE table_name ADD UNIQUE (column); 普通索引 INDEX：这是最基本的索引，它没有任何限制。可以通过ALTER TABLE table_name ADD INDEX index_name (column); 组合索引 INDEX：即一个索引包含多个列，多用于避免回表查询。可以通过ALTER TABLE table_name ADD INDEX index_name(column1,column2, column3); 全文索引 FULLTEXT：也称全文检索，是目前搜索引擎使用的一种关键技术。可以通过ALTER TABLE table_name ADD FULLTEXT (column); 索引一经创建不能修改，如果要修改索引，只能删除重建。可以使用DROP INDEX index_name ON table_name;删除索引。 总结：a. 更新十分频繁的字段上不宜建立索引：因为更新操作会变更B+树，重建索引。这个过程是十分消耗数据库性能的。 b. 区分度不大的字段上不宜建立索引：类似于性别这种区分度不大的字段，建立索引的意义不大。因为不能有效过滤数据，性能和全表扫描相当。另外返回数据的比例在30%以外的情况下，优化器不会选择使用索引。 c. 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。虽然唯一索引会影响insert速度，但是对于查询的速度提升是非常明显的。另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，在并发的情况下，依然有脏数据产生。 d. 多表关联时，要保证关联字段上一定有索引。 e. 创建索引时避免以下错误观念：索引越多越好，认为一个查询就需要建一个索引；宁缺勿滥，认为索引会消耗空间、严重拖慢更新和新增速度；抵制唯一索引，认为业务的唯一性一律需要在应用层通过“先查后插”方式解决；过早优化，在不了解系统的情况下就开始优化。1/29/2019 10:53:40 AM]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之树结构]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%A0%91%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[二叉树 完全二叉树若高度为h，除h层，其他各层（1-h-1）的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树。 满二叉树除叶子节点外，每一个左右节点都有左右子树，且叶子节点都在底层 平衡二叉树又被称作ALV树，也是二叉排序树（BST）性质：空树或者他的左右两个子树的高度差绝对值不超过1，并且左右两个子树都时一颗平衡二叉树。 堆堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆 二叉查找树（BST）二叉查找树的特点： 若任意节点的左子树不空，则左子树上所有结点的 值均小于它的根结点的值； 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树。 没有键值相等的节点（no duplicate nodes）。 平衡二叉树平衡二叉树实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等 红黑树特点： 每个节点非红即黑 根是黑的 每个叶子节点都是黑色的空节点 如果节点是红色的，则他的子节点必须是黑色的（反之不一定 从根节点到叶节点的每条路径必须包含相同数目的黑色节点 应用：TreeMap TreeSet 以及JDK1.8之后的HashMap底层都用到了红黑树 为什么用红黑树简单来说红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。详细了解可以查看看漫画理解 B- B+ B*树 B- 即B树是一种平衡的多路查找树，在文件系统中有所应用，主要用作文件的索引。 B+树的叶子节点链表结构相比B树便于扫库和范围检索。B+树支持区间查询，非常方便，而B树不支持，这是数据库选用B+树的最主要原因 B/树是B+树的变体， B/树分配新节点的概率比B+树低，空间使用率更高。 LSM树(Log-Structured Merge-Trees)B+树的弱点B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，但做范围查询时，会产生大量读随机IO。 对于大量的随机写也一样，举一个插入key跨度很大的例子，如7-&gt;1000-&gt;3-&gt;2000 … 新插入的数据存储在磁盘上相隔很远，会产生大量的随机写IO. 从上面可以看出，低下的磁盘寻道速度严重影响性能（近些年来，磁盘寻道速度的发展几乎处于停滞的状态）. 它的原理是把一颗大树拆分成N棵小树， 它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历所有的小树，但在每颗小树内部数据是有序的。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非阻塞同步和非阻塞异步的区别]]></title>
    <url>%2F2019%2F01%2F20%2F%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%90%8C%E6%AD%A5%E5%92%8C%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%BC%82%E6%AD%A5%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[这两篇文章分析了Linux下的5种IO模型 http://blog.csdn.net/historyasamirror/article/details/5778378 http://blog.csdn.net/hguisu/article/details/7453390 很多人对阻塞 / 非阻塞， 同步 / 异步 的概念理解的不深入，搞不清楚非阻塞和异步IO的区别，笼统的认为非阻塞IO就是异步IO。其实区别很大，编程模型完全不同。 阻塞 / 非阻塞描述的是函数，指访问某个函数时是否会阻塞线程(block，线程进入阻塞状态)。 同步 / 异步描述的是执行IO操作的主体是谁，同步是由用户进程自己去执行最终的IO操作。异步是用户进程自己不关系实际IO操作的过程，只需要由内核在IO完成后通知它既可，由内核进程来执行最终的IO操作。 这两组概念交集在一起参生的非阻塞同步IO和非阻塞异步IO的概念就不难理解。 非阻塞同步IO指的是用户调用读写方法是不阻塞的，立刻返回的，而且需要用户线程来检查IO状态。需要注意的是，如果发现有可以操作的IO，那么实际用户进程还是会阻塞等待内核复制数据到用户进程，它与同步阻塞IO的区别是后者全程等待。 非阻塞异步IO指的是用户调用读写方法是不阻塞的，立刻返回，而且用户不需要关注读写，只需要提供回调操作，内核线程在完成读写后回调用户提供的callback。 这两个概念的不同造成了编程模型的不同。 非阻塞同步IO由于读写方法非阻塞，并且需要用户自己来进行读写，所以每次调用读写方法实际读写的字节数是不确定的，所以需要一个Buffer来保存每次读写的字节状态。更重要的是用户不知道什么时候完成了读写，一般需要用while循环判断Buffer的状态来跟踪读写。 非阻塞异步IO由于是内核线程进行读写，并且在IO完成后会回调用户提供的callback，编程模型就比较简单，用户只需要调用读写，提供回调就可以了，比如 read(filename, callback) select / poll / epoll 从本质上说都是非阻塞同步IO，select会收到IO就绪的状态，然后通知用户去处理IO，实际的IO操作还需要用户等待内核复制操作。 要理解IO就绪和完成的区别。就绪指的是还需要用户自己去处理，完成指的是内核帮助完成了，用户不用关心IO过程，只需要提供回调函数。 理解了非阻塞同步IO和非阻塞异步IO的区别之后，就不难理解Java NIO的设计了。NIO是围绕ByteBuffer来进行读写的，ByteBuffer是一个缓冲区，用来记录读写的状态，通过多次检查ByteBuffer的状态来确定IO是否完成。 Java 1.7的NIO2.0 引入了非阻塞异步IO的概念，编程模型大大简化了。用户只需要关注回调函数即可。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java IO&NIO]]></title>
    <url>%2F2019%2F01%2F20%2FJava-IO-NIO%2F</url>
    <content type="text"><![CDATA[图解 分类IO流的分类： ·按照流的流向分，可以分为输入流和输出流； ·按照操作单元划分，可以划分为字节流和字符流； ·按照流的角色划分为节点流和处理流。 常见面试题 什么是IO流？ 它是一种数据的流从源头流到目的地。比如文件拷贝，输入流和输出流都包括了。输入流从文件中读取数据存储到进程(process)中，输出流从进程中读取数据然后写入到目标文件。 字节流和字符流的区别。 字节流在JDK1.0中就被引进了，用于操作包含ASCII字符的文件。JAVA也支持其他的字符如Unicode，为了读取包含Unicode字符的文件，JAVA语言设计者在JDK1.1中引入了字符流。ASCII作为Unicode的子集，对于英语字符的文件，可以可以使用字节流也可以使用字符流。 Java中流类的超类主要由那些？ java.io.InputStreamjava.io.OutputStreamjava.io.Readerjava.io.Writer FileInputStream和FileOutputStream是什么？ 这是在拷贝文件操作的时候，经常用到的两个类。在处理小文件的时候，它们性能表现还不错，在大文件的时候，最好使用BufferedInputStream (或 BufferedReader) 和 BufferedOutputStream (或 BufferedWriter) 字节流和字符流，你更喜欢使用拿一个？ 个人来说，更喜欢使用字符流，因为他们更新一些。许多在字符流中存在的特性，字节流中不存在。比如使用BufferedReader而不是BufferedInputStreams或DataInputStream，使用newLine()方法来读取下一行，但是在字节流中我们需要做额外的操作。 System.out.println()是什么？ println是PrintStream的一个方法。out是一个静态PrintStream类型的成员变量，System是一个java.lang包中的类，用于和底层的操作系统进行交互。 什么是Filter流？ Filter Stream是一种IO流主要作用是用来对存在的流增加一些额外的功能，像给目标文件增加源文件中不存在的行数，或者增加拷贝的性能。 有哪些可用的Filter流？ 在java.io包中主要由4个可用的filter Stream。两个字节filter stream，两个字符filter stream. 分别是FilterInputStream, FilterOutputStream, FilterReader and FilterWriter.这些类是抽象类，不能被实例化的。 有些Filter流的子类: LineNumberInputStream 给目标文件增加行号 DataInputStream 有些特殊的方法如readInt(), readDouble()和readLine() 等可以读取一个 int, double和一个string一次性的, BufferedInputStream 增加性能 PushbackInputStream 推送要求的字节到系统中 SequenceInputStream的作用？ 这个类的作用是将多个输入流合并成一个输入流，通过SequenceInputStream类包装后形成新的一个总的输入流。在拷贝多个文件到一个目标文件的时候是非常有用的。可用使用很少的代码实现 说说PrintStream和PrintWriter 他们两个的功能相同，但是属于不同的分类。字节流和字符流。他们都有println()方法。 在文件拷贝的时候，那一种流可用提升更多的性能？在字节流的时候，使用BufferedInputStream和BufferedOutputStream。在字符流的时候，使用BufferedReader 和 BufferedWriter 说说管道流(Piped Stream) 有四种管道流， PipedInputStream, PipedOutputStream, PipedReader 和 PipedWriter.在多个线程或进程中传递数据的时候管道流非常有用。 说说File类它不属于 IO流，也不是用于文件操作的，它主要用于知道一个文件的属性，读写权限，大小等信息。注意：Java7中文件IO发生了很大的变化，专门引入了很多新的类来取代原来的基于java.io.File的文件IO操作方式。 说说RandomAccessFile? 它在java.io包中是一个特殊的类，既不是输入流也不是输出流，它两者都可以做到。他是Object的直接子类。通常来说，一个流只有一个功能，要么读，要么写。但是RandomAccessFile既可以读文件，也可以写文件。 DataInputStream 和 DataOutStream有的方法，在RandomAccessFile中都存在。 NIO与AIO学习总结 简介Java NIO 是 java 1.4 之后新出的一套IO接口，这里的的新是相对于原有标准的Java IO和Java Networking接口。NIO提供了一种完全不同的操作方式。 NIO中的N可以理解为Non-blocking，不单纯是New。 它支持面向缓冲的，基于通道的I/O操作方法。 随着JDK 7的推出，NIO系统得到了扩展，为文件系统功能和文件处理提供了增强的支持。 由于NIO文件类支持的这些新的功能，NIO被广泛应用于文件处理。 NIO的特性/NIO与IO区别: 1)IO是面向流的，NIO是面向缓冲区的；2)IO流是阻塞的，NIO流是不阻塞的;3)NIO有选择器，而IO没有。 读数据和写数据方式: 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。 NIO核心组件简单介绍 ChannelsBuffersSelectors 在理解了NIO的基础上，看AIO，区别在于AIO是等读写过程完成后再去调用回调函数。 NIO是同步非阻塞的 AIO是异步非阻塞的 由于NIO的读写过程依然在应用线程里完成，所以对于那些读写过程时间长的，NIO就不太适合。 而AIO的读写过程完成后才被通知，所以AIO能够胜任那些重量级，读写过程长的任务。 小型网络服务器 http://www.importnew.com/21341.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java jvm 相关命令]]></title>
    <url>%2F2019%2F01%2F20%2Fjava-jvm-%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[概述程序运行中经常会遇到各种问题，定位问题时通常需要综合各种信息，如系统日志、堆dump文件、线程dump文件、GC日志等。通过虚拟机监控和诊断工具可以帮忙我们快速获取、分析需要的数据，进而提高问题解决速度。 本文将介绍虚拟机常用监控和问题诊断命令工具的使用方法，主要包含以下工具: jps: 显示系统中所有Hotspot虚拟机进程jstack：显示虚拟机的线程栈信息jstat：收集hotspot虚拟机各方面运行的数据jmap：用于生成虚拟机内存快照信息jinfo：显示虚拟机的配置信息jconsole：一个java GUI监视工具，可以以图表化的形式显示各种数据jvisualvm：一个基于图形化界面的、可以查看本地及远程的JAVA GUI监控工具jhat：用于对JAVA heap进行离线分析的工具Jdb：对core文件和正在运行的Java进程进行实时地调试 jps 命令格式 jps [ options ] [ hostid ] 和Linux的ps类似 常用参数说明 -q 忽略输出的类名、Jar名以及传递给main方法的参数，只输出pid。 -m 输出传递给main方法的参数，如果是内嵌的JVM则输出为null。 -l 输出应用程序主类的完整包名，或者是应用程序JAR文件的完整路径。 -v 输出传给JVM的参数。 -V 输出通过标记的文件传递给JVM的参数（.hotspotrc文件，或者是通过参数-XX:Flags=&lt;filename&gt;指定的文件）。 -J 用于传递jvm选项到由javac调用的java加载器中，例如，“-J-Xms48m”将把启动内存设置为48M，使用-J选项可以非常方便的向基于Java的开发的底层虚拟机应用程序传递参数。 jstack命令(Java Stack Trace)https://bijian1013.iteye.com/blog/2221340 jstathttps://bijian1013.iteye.com/blog/2221351 jmaphttps://bijian1013.iteye.com/blog/2221386 其他https://bijian1013.iteye.com/blog/2221334]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三次握手，四次挥手详解]]></title>
    <url>%2F2019%2F01%2F18%2F%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%EF%BC%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[介绍TCP是一种面向连接的单播协议，在发送数据前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服务器的内存里保存的一份关于对方的信息，如ip地址、端口号等。 TCP可以看成是一种字节流，它会处理IP层或以下的层的丢包、重复以及错误问题。在连接的建立过程中，双方需要交换一些连接的参数。这些参数可以放在TCP头部。 TCP提供了一种可靠、面向连接、字节流、传输层的服务，采用三次握手建立一个连接。采用4次挥手来关闭一个连接。 TCP服务模型在了解了建立连接、关闭连接的“三次握手和四次挥手”后，我们再来看下TCP相关的东西。 一个TCP连接由一个4元组构成，分别是两个IP地址和两个端口号。一个TCP连接通常分为三个阶段：启动、数据传输、退出（关闭）。 当TCP接收到另一端的数据时，它会发送一个确认，但这个确认不会立即发送，一般会延迟一会儿。ACK是累积的，一个确认字节号N的ACK表示所有直到N的字节（不包括N）已经成功被接收了。这样的好处是如果一个ACK丢失，很可能后续的ACK就足以确认前面的报文段了。 一个完整的TCP连接是双向和对称的，数据可以在两个方向上平等地流动。给上层应用程序提供一种双工服务。一旦建立了一个连接，这个连接的一个方向上的每个TCP报文段都包含了相反方向上的报文段的一个ACK。 序列号的作用是使得一个TCP接收端可丢弃重复的报文段，记录以杂乱次序到达的报文段。因为TCP使用IP来传输报文段，而IP不提供重复消除或者保证次序正确的功能。另一方面，TCP是一个字节流协议，绝不会以杂乱的次序给上层程序发送数据。因此TCP接收端会被迫先保持大序列号的数据不交给应用程序，直到缺失的小序列号的报文段被填满。 为什么要“三次握手，四次挥手”谢希仁版《计算机网络》中的例子是这样的，“已失效的连接请求报文段” 的产生在这样一种情况下：client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。” 但是在rfc中，也就是 TCP 的协议 RFC，你就会发现里面就讲到了为什么三次握手是必须的——TCP 需要 seq 序列号来做可靠重传或接收，而避免连接复用时无法分辨出 seq 是延迟或者是旧链接的 seq，因此需要三次握手来约定确定双方的 ISN（初始 seq 序列号）。 TCP 协议是不限制一个特定的连接（两端 socket 一样）被重复使用的。 所以这样就有一个问题：这条连接突然断开重连后，TCP 怎么样识别之前旧链接重发的包？——这就需要独一无二的 ISN（初始序列号）机制。 三次握手（A three way handshake）是必须的， 因为 sequence numbers（序列号）没有绑定到整个网络的全局时钟（全部统一使用一个时钟，就可以确定这个包是不是延迟到的）以及 TCPs 可能有不同的机制来选择 ISN（初始序列号）。接收方接收到第一个 SYN 时，没有办法知道这个 SYN 是是否延迟了很久了，除非他有办法记住在这条连接中，最后接收到的那个sequence numbers（然而这不总是可行的）。这句话的意思是：一个 seq 过来了，跟现在记住的 seq 不一样，我怎么知道他是上条延迟的，还是上上条延迟的呢？所以，接收方一定需要跟发送方确认 SYN。假设不确认 SYN 中的 SEQ，那么就只有：1) A –&gt; B SYN my sequence number is X 2) A &lt;– B ACK your sequence number is X SYN my sequence number is Y只有B确认了收到了 A 的 SEQ， A 无法确认收到 B 的。也就是说，只有 A 发送给 B 的包都是可靠的， 而 B 发送给 A 的则不是，所以这不是可靠的连接。这种情况如果只需要 A 发送给 B ，B 无需回应，则可以不做三次握手。 所以，正确的类比应该是这样的：TCP 传递信息可以理解为美国与中国用货船来传货物，但因为一首轮船穿放不下，货物要分开一只只轮船来发货。所以需要一个序列号来识别该货物是第几个，以便到达后将其拼接回原来的货物。因为同一条航道（也就是 tcp连接）上，可能会有多批货物发送（复用 tcp 连接）。发货时，双方需要通知对方这个序列号是从哪里开始（init seq）的，这样才能辨识过来的是不是一个对的货物，以及能拼接成完整的货物。货物运输拼接（tcp）最重要的是可靠性，如果没有用三次握手来确认双方都可以获得对方的 序列号（seq）的话，就无法知道当前航班（连接）中，对的货物序号是怎么样的了。 三次握手详细过程 TCP A TCP B​ CLOSED LISTEN​ SYN-SENT –&gt; –&gt; SYN-RECEIVED​ ESTABLISHED &lt;– &lt;– SYN-RECEIVED​ ESTABLISHED –&gt; –&gt; ESTABLISHED​ ESTABLISHED –&gt; –&gt; ESTABLISHED​Basic 3-Way Handshake for Connection Synchronization ​Figure 7. 在上图第二行中， A 发送了 SEQ 100，标志位是 SYN；第三行，B 发回了 ACK 101 与 SEQ 300，标志位是 SYN 与 ACK（两个过程合并了）。注意，ACK 是101意味着，B 希望接收到 101序列号开始的数据段。第四行，A 返回了空的数据，SEQ 101， ACK 301，标志位为 ACK。至此，双方的开始 SEQ （也就是 ISN）号100与300都被确认接收到了。第五行，开始正式发送数据包，注意的是 ACK 依旧是第四行的301，因为没有需要 ACK 的 SYN 了（第四行已经 ACK 完）。 换个易于理解的视角来看为什么要3次握手。客户端和服务端通信前要进行连接，“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。 从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。 第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。 经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的。之后就可以正常通信了。 每次都是接收到数据包的一方可以得到一些结论，发送的一方其实没有任何头绪。我虽然有发包的动作，但是我怎么知道我有没有发出去，而对方有没有接收到呢？ 而从上面的过程可以看到，最少是需要三次握手过程的。两次达不到让双方都得出自己、对方的接收、发送能力都正常的结论。其实每次收到网络包的一方至少是可以得到：对方的发送、我方的接收是正常的。而每一步都是有关联的，下一次的“响应”是由于第一次的“请求”触发，因此每次握手其实是可以得到额外的结论的。比如第三次握手时，服务端收到数据包，表明看服务端只能得到客户端的发送能力、服务端的接收能力是正常的，但是结合第二次，说明服务端在第二次发送的响应包，客户端接收到了，并且作出了响应，从而得到额外的结论：客户端的接收、服务端的发送是正常的。 四次挥手TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了。这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，等到发送完了所有的数据后，会发送一个FIN段来关闭此方向上的连接。接收方发送ACK确认关闭连接。注意，接收到FIN报文的一方只能回复一个ACK, 它是无法马上返回对方一个FIN报文段的，因为结束数据传输的“指令”是上层应用层给出的，我只是一个“搬运工”，我无法了解“上层的意志”。 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方ACK和FIN一般都会分开发送。 进阶syn flood攻击最基本的DoS攻击就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。syn flood属于Dos攻击的一种。 如果恶意的向某个服务器端口发送大量的SYN包，则可以使服务器打开大量的半开连接，分配TCB（Transmission Control Block）, 从而消耗大量的服务器资源，同时也使得正常的连接请求无法被相应。当开放了一个TCP端口后，该端口就处于Listening状态，不停地监视发到该端口的Syn报文，一 旦接收到Client发来的Syn报文，就需要为该请求分配一个TCB，通常一个TCB至少需要280个字节，在某些操作系统中TCB甚至需要1300个字节，并返回一个SYN ACK命令，立即转为SYN-RECEIVED即半开连接状态。系统会为此耗尽资源。 常见的防攻击方法有： 无效连接的监视释放监视系统的半开连接和不活动连接，当达到一定阈值时拆除这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，而且由于SYN Flood造成的半开连接数量很大，正常连接请求也被淹没在其中被这种方式误释放掉，因此这种方法属于入门级的SYN Flood方法。 延缓TCB分配方法消耗服务器资源主要是因为当SYN数据报文一到达，系统立即分配TCB，从而占用了资源。而SYN Flood由于很难建立起正常连接，因此，当正常连接建立起来后再分配TCB则可以有效地减轻服务器资源的消耗。常见的方法是使用Syn Cache和Syn Cookie技术。 Syn Cache技术系统在收到一个SYN报文时，在一个专用HASH表中保存这种半连接信息，直到收到正确的回应ACK报文再分配TCB。这个开销远小于TCB的开销。当然还需要保存序列号。 Syn Cookie技术Syn Cookie技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS(Maximum Segment Size，最大报文段大小，指的是TCP报文的最大数据报长度，其中不包括TCP首部长度。)、时间等，在收到对方 的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源。 使用SYN Proxy防火墙一种方式是防止墙dqywb连接的有效性后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c, 而真正的服务器回应的序列号为c’, 这样，在每个数据报文经过防火墙的时候进行序列号的修改。另一种方式是防火墙确定了连接的安全后，会发出一个safe reset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。 连接队列在外部请求到达时，被服务程序最终感知到前，连接可能处于SYN_RCVD状态或是ESTABLISHED状态，但还未被应用程序接受。 对应地，服务器端也会维护两种队列，处于SYN_RCVD状态的半连接队列，而处于ESTABLISHED状态但仍未被应用程序accept的为全连接队列。如果这两个队列满了之后，就会出现各种丢包的情形。 查看是否有连接溢出netstat -s | grep LISTEN半连接队列满了 在三次握手协议中，服务器维护一个半连接队列，该队列为每个客户端的SYN包开设一个条目(服务端在接收到SYN包的时候，就已经创建了request_sock结构，存储在半连接队列中)，该条目表明服务器已收到SYN包，并向客户发出确认，正在等待客户的确认包。这些条目所标识的连接在服务器处于Syn_RECV状态，当服务器收到客户的确认包时，删除该条目，服务器进入ESTABLISHED状态。 目前，Linux下默认会进行5次重发SYN-ACK包，重试的间隔时间从1s开始，下次的重试间隔时间是前一次的双倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s, 总共31s, 称为指数退避，第5次发出后还要等32s才知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 63s, TCP才会把断开这个连接。由于，SYN超时需要63秒，那么就给攻击者一个攻击服务器的机会，攻击者在短时间内发送大量的SYN包给Server(俗称SYN flood攻击)，用于耗尽Server的SYN队列。对于应对SYN 过多的问题，linux提供了几个TCP参数：tcp_syncookies、tcp_synack_retries、tcp_max_syn_backlog、tcp_abort_on_overflow 来调整应对。 全连接队列满当第三次握手时，当server接收到ACK包之后，会进入一个新的叫 accept 的队列。 当accept队列满了之后，即使client继续向server发送ACK的包，也会不被响应，此时ListenOverflows+1，同时server通过tcp_abort_on_overflow来决定如何返回，0表示直接丢弃该ACK，1表示发送RST通知client；相应的，client则会分别返回read timeout 或者 connection reset by peer。另外，tcp_abort_on_overflow是0的话，server过一段时间再次发送syn+ack给client（也就是重新走握手的第二步），如果client超时等待比较短，就很容易异常了。而客户端收到多个 SYN ACK 包，则会认为之前的 ACK 丢包了。于是促使客户端再次发送 ACK ，在 accept队列有空闲的时候最终完成连接。若 accept队列始终满员，则最终客户端收到 RST 包（此时服务端发送syn+ack的次数超出了tcp_synack_retries）。 服务端仅仅只是创建一个定时器，以固定间隔重传syn和ack到服务端 命令 netstat -s命令 [root@server ~]# netstat -s | egrep “listen|LISTEN” 667399 times the listen queue of a socket overflowed 667399 SYNs to LISTEN sockets ignored比如上面看到的 667399 times ，表示全连接队列溢出的次数，隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了。[root@server ~]# netstat -s | grep TCPBacklogDrop 查看 Accept queue 是否有溢出ss命令 [root@server ~]# ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 :6379 : LISTEN 0 128 :22 : 如果State是listen状态，Send-Q 表示第三列的listen端口上的全连接队列最大为50，第一列Recv-Q为全连接队列当前使用了多少。 非 LISTEN 状态中 Recv-Q 表示 receive queue 中的 bytes 数量；Send-Q 表示 send queue 中的 bytes 数值。小结 当外部连接请求到来时，TCP模块会首先查看max_syn_backlog，如果处于SYN_RCVD状态的连接数目超过这一阈值，进入的连接会被拒绝。根据tcp_abort_on_overflow字段来决定是直接丢弃，还是直接reset. 从服务端来说，三次握手中，第一步server接受到client的syn后，把相关信息放到半连接队列中，同时回复syn+ack给client. 第三步当收到客户端的ack, 将连接加入到全连接队列。 一般，全连接队列比较小，会先满，此时半连接队列还没满。如果这时收到syn报文，则会进入半连接队列，没有问题。但是如果收到了三次握手中的第3步(ACK)，则会根据tcp_abort_on_overflow字段来决定是直接丢弃，还是直接reset.此时，客户端发送了ACK, 那么客户端认为三次握手完成，它认为服务端已经准备好了接收数据的准备。但此时服务端可能因为全连接队列满了而无法将连接放入，会重新发送第2步的syn+ack, 如果这时有数据到来，服务器TCP模块会将数据存入队列中。一段时间后，client端没收到回复，超时，连接异常，client会主动关闭连接。 参考资料：简单的理解：https://juejin.im/post/5c078058f265da611c26c235 http://blog.51cto.com/changxy/751958]]></content>
      <categories>
        <category>计网</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[简介定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 作用：在我们的系统中，有一些对象其实我们只需要一个，比如说：线程池、缓存、对话框、注册表、日志对象、充当打印机、显卡等设备驱动程序的对象。事实上，这一类对象只能有一个实例，如果制造出多个实例就可能会导致一些问题的产生，比如：程序的行为异常、资源使用过量、或者不一致性的结果。 好处： · 对于频繁使用的对象，可以省略创建对象所花费的时间，对于重量级对象，是非常客观的一笔系统开销； · 由于new操作的次数减少，因而对系统内存的使用频率也会降低，减轻GC压力 为什么不使用全局变量确保一个类只有一个实例呢？ 我们知道全局变量分为静态变量和实例变量，静态变量也可以保证该类的实例只存在一个。只要程序加载了类的字节码，不用创建任何实例对象，静态变量就会被分配空间，静态变量就可以被使用了。 但是，如果说这个对象非常消耗资源，而且程序某次的执行中一直没用，这样就造成了资源的浪费。利用单例模式的话，我们就可以实现在需要使用时才创建对象，这样就避免了不必要的资源浪费。 不仅仅是因为这个原因，在程序中我们要尽量避免全局变量的使用，大量使用全局变量给程序的调试、维护等带来困难。 单例模式的实现通常单例模式在Java语言中，有两种构建方式： 饿汉方式。指全局的单例实例在类装载时构建懒汉方式。指全局的单例实例在第一次被使用时构建。 不管是那种创建方式，它们通常都存在下面几点相似处： 单例类必须要有一个 private 访问级别的构造函数，只有这样，才能确保单例不会在系统中的其他代码内被实例化;instance 成员变量和 uniqueInstance 方法必须是 static 的。 饿汉模式 （线程安全） 123456789public class Singleton&#123; private static Singleton uniqueSingleton = new Singleton(); private Singleton ()&#123; &#125; public static Singleton getInstance() &#123; return uniqueSingleton; &#125;&#125; 所谓 “饿汉方式” 就是说JVM在加载这个类时就马上创建此唯一的单例实例，不管你用不用，先创建了再说，如果一直没有被使用，便浪费了空间，典型的空间换时间，每次调用的时候，就不需要再判断，节省了运行时间。 懒汉式（非线程安全和synchronized关键字线程安全版本 ） 2.1 非线程安全 12345678910111213public class Singleton &#123; private static Singleton uniqueInstance; private Singleton ()&#123; &#125; //没有加入synchronized关键字的版本是线程不安全的 public static Singleton getInstance() &#123; //判断当前单例是否已经存在，若存在则返回，不存在则再建立单例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125; &#125; 所谓 “ 懒汉式” 就是说单例实例在第一次被使用时构建，而不是在JVM在加载这个类时就马上创建此唯一的单例实例。 但是上面这种方式很明显是线程不安全的，如果多个线程同时访问getInstance()方法时就会出现问题。 2.2 线程安全篇 123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; uniqueInstance = new Singleton(); &#125; return uniqueInstance; &#125; 我们知道synchronized关键字偏重量级锁。虽然在JavaSE1.6之后synchronized关键字进行了主要包括：为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升。 但是在程序中每次使用getInstance() 都要经过synchronized加锁这一层，这难免会增加getInstance()的方法的时间消费，而且还可能会发生阻塞。我们下面介绍到的 双重检查加锁版本 就是为了解决这个问题而存在的。 2.3 双重锁 1234567891011121314151617181920public class Singleton &#123; //volatile保证，当uniqueInstance变量被初始化成Singleton实例时，多个线程可以正确处理uniqueInstance变量 private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; //检查实例，如果不存在，就进入同步代码块 if (uniqueInstance == null) &#123; //只有第一次才彻底执行这里的代码 synchronized(Singleton.class) &#123; //进入同步代码块后，再检查一次，如果仍是null，才创建实例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次面试]]></title>
    <url>%2F2019%2F01%2F06%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[前言一次没有准备的面试，刚考完试，想放松几天，没想到昨天投的简历这么快就有面试。凉凉。 Java基础1.1 == 和 equals的区别在基本数据类型中== 比较的是值，在对象中比较的是内存地址equals有两种情况1）是没有重写equals方法，相当于==2）重写了equals方法，通常比较两个对象的内容，若想等返回true。 延申：hashCode() 和equals的关系 如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）结论：重写equals后必须重写hashCode，确保相同的对象有相同的hashCode。 以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode： 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals（）方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head fist java》第二版）。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 1.2 HashMap怎么实现https://github.com/Snailclimb/JavaGuide/blob/master/Java%E7%9B%B8%E5%85%B3/HashMap.mdHashSet怎么实现CourrentHashMap 怎么实现线程安全 Jdk的内存模型 程序计数器：较小的内存空间，他的作用看作是当前线程所执行的字节码的行号指示器，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个程序计数器。线程私有。 虚拟机栈：线程私有。描述的是Java方法执行的内存模型：每个方法被执行时都会创建一个栈帧用于存储局部变量表，操作栈、动态连接、方法出口等信息，每一个方法被调用直至到执行完成的过程，就对应着一个栈帧在虚拟机中从入栈到出栈的过程。会抛出StackOverflowError和OutOfMemoryError异常。 本地方法栈：为虚拟机使用到的Native方法服务。 Java堆：被所有线程共享的一块内存区域，在虚拟机启动时创建。唯一目的是存放对象实例，几乎所有的对象实例都在这里分配内存。垃圾收集器管理的主要区域，被叫做GC堆，分为新生代和老年代 方法区：线程共享，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码。别名：nonHeap。 运行时常量池时方法区的一部分 数据库两个引擎的区别MyISAM：默认的MySQL插件式存储引擎，它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。注意，通过更改STORAGE_ENGINE配置变量，能够方便地更改MySQL服务器的默认存储引擎。 InnoDB：用于事务处理应用程序，具有众多特性，包括ACID事务支持。(提供行级锁)一般来说不使用事务的话，请使用MyISAM引擎，使用事务的话，一般使用InnoDB 怎么优化数据库 选取最适用的字段属性MySQL可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小另外一个提高效率的方法是在可能的情况下，应该尽量把字段设置为NOT NULL，这样在将来执行查询的时候，数据库不用去比较NULL值。 、使用连接（JOIN）来代替子查询(Sub-Queries) 慢查询怎么实现 索引怎么分类有没有用过redis 计算机网络TCP的四次挥手 操作系统系统态和用户态的区别 框架Hibernate和MyBatics的区别Mybatis：小巧、方便、高效、简单、直接、半自动化 Hibernate：强大、方便、高效、复杂、间接、全自动化 两者对比总结两者相同点Hibernate与MyBatis都可以是通过SessionFactoryBuider由XML配置文件生成SessionFactory，然后由SessionFactory 生成Session，最后由Session来开启执行事务和SQL语句。其中SessionFactoryBuider，SessionFactory，Session的生命周期都是差不多的。如下图所示： Hibernate优势Hibernate的DAO层开发比MyBatis简单，Mybatis需要维护SQL和结果映射。 Hibernate对对象的维护和缓存要比MyBatis好，对增删改查的对象的维护要方便。 Hibernate数据库移植性很好，MyBatis的数据库移植性不好，不同的数据库需要写不同SQL。 Hibernate有更好的二级缓存机制，可以使用第三方缓存。MyBatis本身提供的缓存机制不佳。 Mybatis优势MyBatis可以进行更为细致的SQL优化，可以减少查询字段。 MyBatis容易掌握，而Hibernate门槛较高。 算法怎么识别一个链表有环top k问题怎么实现排序，最小堆，还有快速排序的方法eg：有1亿个浮点数，如果找出期中最大的10000个？ 1）直接排序最快复杂度为O(nlogn),在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。 2) 局部淘汰法用一个容器保存前10000个数，先让10000个数进容器排序，后续的数在一一与最小的数比较，大于就删去最小的，把新的元素插进去排序，最后得到结果，时间复杂度O(n+m^2)。 3)分治法参考快速排序的思想，将数据分成两堆，如果大的那堆个数N大于10000个，继续分成两堆，将数据分成两堆，如果大的那堆个数N大于10000个，继续分成两堆，如果大的那堆小于1w个，就在小的那堆快速排序一次，找到1w-n的大数字，每次需要的内存空间为10^6*4=4MB,一共需要101次这样的比较。 4）Hash法如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。 5）最小堆法（注意不是最大堆，我们要确认拿到的top是10000个中最小的）首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kmp详解]]></title>
    <url>%2F2018%2F12%2F08%2Fkmp%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[暴力匹配 如果用暴力匹配的思路，并假设现在文本串S匹配到 i 位置，模式串P匹配到 j 位置，则有： 如果当前字符匹配成功（即S[i] == P[j]），则i++，j++，继续匹配下一个字符；如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0。相当于每次匹配失败时，i 回溯，j 被置为0。 理清楚了暴力匹配算法的流程及内在的逻辑，咱们可以写出暴力匹配的代码，如下： 12345678910111213141516171819202122232425262728int ViolentMatch(char* s, char* p)&#123; int sLen = strlen(s); int pLen = strlen(p); int i = 0; int j = 0; while (i &lt; sLen &amp;&amp; j &lt; pLen) &#123; if (s[i] == p[j]) &#123; //①如果当前字符匹配成功（即S[i] == P[j]），则i++，j++ i++; j++; &#125; else &#123; //②如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0 i = i - j + 1; j = 0; &#125; &#125; //匹配成功，返回模式串p在文本串s中的位置，否则返回-1 if (j == pLen) return i - j; else return -1;&#125; kmp优化的是不匹配的时候字符串滑动到哪里。 int kmpSearch(String a,String b, int[] next) { int i = 0; int j = 0; int slen = a.length(); int plen = b.length(); char s[] = a.toCharArray(); char p[] = b.toCharArray(); while (i &lt; slen &amp;&amp; j &lt; plen) { if (j == -1 || s[i]== p[j]) { i++; j++; }else { j = next[j]; } } if (j==plen) { return i-j; } return -1; } next数组是前缀和后缀的最大匹配，运用k = next[k] 缩短寻找时间。 ``` int[] getNext(String s) { int []next = new int[s.length()]; next[0] = -1; int k = -1; int j = 0; char p[] = s.toCharArray(); while (j &lt; p.length-1) { if (k==-1 || p[j] == p[k]) { ++j; ++k; next[j] = k; }else{ k = next[k]; } } for ( int i = 0; i&lt; next.length; i++) { System.out.print(next[i] + &quot; &quot;); } return next; } 参考资料：https://blog.csdn.net/v_july_v/article/details/7041827 最全资料 https://www.bilibili.com/video/av11866460?from=search&amp;seid=12730654434238709250 视频]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程读写文件]]></title>
    <url>%2F2018%2F11%2F09%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[前言无意看到一道多线程的题目，据说是网易的面试题，试着网上的思路code一遍。 题目：一个文件中有10000个数，用Java实现一个多线程程序将这个10000个数输出到5个不用文件中（不要求输出到每个文件中的数量相同）。 要求启动10个线程，两两一组，分为5组。 每组两个线程分别将文件中的奇数和偶数输出到该组对应的一个文件中， 需要偶数线程每打印10个偶数以后，就将奇数线程打印10个奇数，如此交替进行。 同时需要记录输出进度，每完成1000个数就在控制台中打印当前完成数量，并在所有线程结束后，在控制台打印”Done”. 分析分析：可以将10000个数分成5份，每一份（2000个数）对应一组，即两个线程，来分别输出这一份的奇数和偶数，同时声明一个共享变量，用于统计当前所有线程输出的个数，反映记录的输出进度 源码 随机生成10000个数，并输出到文件，然后文件读取到字符串中， ‘ // 生成一个10000个数的文件 PrintWriter pw = new PrintWriter(new FileWriter(new File( “input.txt”), true)); Random random = new Random(); for (int i = 0; i &lt; 10000; i++) { pw.print(Math.abs(random.nextInt()) % 100 + “ “); } pw.flush(); pw.close(); // 读取文件中的数字，分5次读取，每次读取2000个 BufferedReader reader = new BufferedReader(new FileReader( &quot;input.txt&quot;)); String str = reader.readLine(); reader.close(); ‘ 把线程分成五组，然后两个两个执行，首先生成printWriter,再生成printThread，再生成两个线程来start ‘ // 将一行字符串全部解析为10000个数字 String[] strs = str.split(“ “); // 10000个数的索引计数 int j = 0; for (int i = 0; i &lt; 5; i++) { int[] records = new int[2000]; for (int k = 0; k &lt; 2000; k++) { records[k] = Integer.parseInt(strs[j]); j++; } // 定义输出文件 PrintWriter writer = new PrintWriter(new FileWriter(new File( “output” + i + “.txt”)), true); // 定义实现的方法 ThreadGroup group = new ThreadGroup(records, writer); // 开启一队线程 new Thread(group).start(); new Thread(group).start(); }‘ 每个线程共享的静态变量‘// 所有的ThreadGroup类对象共享一个count变量，用来记录输出的总数 private static int count; // 所有的ThreadGroup类对象共享一个锁，用于count变量的同步，任何一个线程需要修改count变量，必须取得该锁 private static Object lock = new Object(); // 用0代表偶数 public static final int EVEN = 0; // -1代表奇数 public static final int ODD = -1; // *以上静态变量，属于整个类所有*‘ run方法一直执行while(print()), 而print() 方法用synchronize锁定，并根据type判断奇偶数，其中锁定lock方便输出信息。当奇偶的位置都超过record.length()的时候，就返回false中止该线程，唤醒其他线程。执行完10次后，就进入等待，唤醒其他线程，等待唤醒。算法很简单，不多说，重点是多线程的运行。 ‘ // 线程实现方法 @Override public void run() { while (print()) ; } private synchronized boolean print() { for (int i = 0; i &lt; 10;) { // 如果奇数和偶数都打印完成以后，就直接停止打印循环，等待该线程自己结束 if (oddPoint &gt;= records.length &amp;&amp; evenPoint &gt;= records.length) { notifyAll(); return false; } // 如果该线程该打印奇数，但奇数已经打印晚了，就直接停止本次10个数的打印， // 同理偶数，等下次切换打印类型后，再开始打印另外一种类型 if ((oddPoint &gt;= records.length &amp;&amp; type == ODD) || (evenPoint &gt;= records.length &amp;&amp; type == EVEN)) { break; } // 判断开始打印偶数 if (type == EVEN) { if (records[evenPoint] % 2 == 0) { i++; writer.print(records[evenPoint] + &quot; &quot;); writer.flush(); // 锁定全局变量方便线程输出后计数 synchronized (lock) { count++; if (count % 1000 == 0) { System.out.println(&quot;当前完成数量：&quot; + count); if (count == 10000) { System.out.println(&quot;Done!&quot;); } } } } // 无论是否是偶数，打印成功一个后，偶数的起始位置都要后移 evenPoint++; } else { // 打印奇数 if (records[oddPoint] % 2 == 1) { i++; writer.print(records[oddPoint] + &quot; &quot;); writer.flush(); // 锁定全局变量方便线程输出后计数 synchronized (lock) { count++; if (count % 1000 == 0) { System.out.println(&quot;当前完成数量：&quot; + count); if (count == 10000) { System.out.println(&quot;Done!&quot;); } } } } // 无论是否是奇数，打印成功一个后，偶数的起始位置都要后移 oddPoint++; } } // 切换打印类型 type = ~type; // 一组中的任一线程打印完后唤醒另一个线程 notifyAll(); try { // 释放锁进入等待状态，等待另一线程打印 wait(); } catch (Exception e) { e.printStackTrace(); } return true; } ‘]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql基本知识]]></title>
    <url>%2F2018%2F09%2F09%2Fmysql%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言复习常用的sql命令，记录常用常考的。 基本命令进入mysql的方法mysql -hlocalhost -uroot -p 然后输入数据库密码就行。 数据库的基本操作use [database]; 进入该数据库show databases; 展示所有的数据库show tables; 展示该数据库下的所有tableshow columns from customers; 展示所有的列show status; 显示广泛的服务器状态信息；show grants; 显示授予用户的安全权限。show error; show warnings; 显示服务器错误或警告help show 查看更多功能 select的基本操作检查单列select prod_name from products; 检查多列select prod_id，prod_name, prod_price from products; 检查所有列select *from products 返回不同的值 distinct关键字select distinct vend_id from products； 限制返回结果 limit关键字select prod_name from products limit 5; 使用完全限定的表名select products.prod_name from products;select products.prod_name from cracourse.products; 排序检索数据按单个列排序select prod_name from products order by prod_name; 按多个列select prod_id, prod_price, prod_name from products order by prod_price,prod_name; 指定方向排序（降序）select prod_id, prod_price, prod_name from products order by prod_price desc; 多个列排序select prod_id, prod_price ,prod_name from products order by prod_price desc, prod_name desc; 与dsec相反的关键字asc，但默认是升序，没什么卵用。 在mysql中大小写不分 过滤数据where搜索过滤select prod_name,prod_price from products where prod_price=2.50;= &gt; &lt; != &lt;= &gt;= between 都可以 不匹配检查select vend_id, prod_name from products where vend_id &lt;&gt;1003; 范围检查select prod_name,prod_price from products where prod_price between 5 and 10; 空值检查select prod_name,prod_price from products where prod_price is null; AND操作符select prod_id,prod_price,prod_name from products where vend_id = 1003 and prod_price &lt;=10; OR 操作符select prod_name,prod_price from products where vend_id =1002 or vend_id =1003; IN操作符select prod_name,prod_price from products where vend_id IN(1002,1003) order by prod_name; Not 操作符select prod_name,prod_price from products where vend_id NOT IN(1002,1003) order by prod_name; 用通配符过滤like操作符%通配符，表示任何字符出现的任意次数select prod_id,prod_name from products where prod_name like ‘jet%’; 下划线通配符select prod_id,prod_name from products where prodname like ‘ ton anvil’; 正则表达式匹配select prod_id,prod_name from products where prod_name regexp ‘1000’ order by prod_name; 拼接select Concat(vend_name,’(‘,vend_country,’)’) from vendors order by vend_name;返回结果：| Concat(vend_name,’(‘,vend_country,’)’) |+—————————————-+| ACME(USA) || Anvils R Us(USA) || Furball Inc.(USA) || Jet Set(England) || Jouets Et Ours(France) || LT Supplies(USA) RTrim(去除空格select Concat(RTrim(vend_name),’(‘,RTrim(vend_country),’)’) from vendors order by vend_name; 使用别名select Concat(RTrim(vend_name),’(‘,RTrim(vend_country),’)’) as vend_title from vendors order by vend_name; 执行算数计算Select prod_id,quantity,item_price from orderitems where order_num = 20005; Select prod_id,quantity,item_price,quantity*item_price AS expanded_price from orderitems where order_num = 20005; 使用函数Upper()select vend_name,Upper(vend_name) as vend_name_upcase from vendors order by vend_name; 日期类函数Date()select cust_id,order_num from orders where Date(order_date) Between ‘2005-09-01’ and ‘2005-09-30’; 数值类函数 汇总数据avg()平均值select avg(prod_price) as avg_price from products;select avg(prod_price) as avg_price from products where vend_id = 1003; count()计数select count(*) as num_cust from customers;select count(cust_email) as num_cust from customers; Max()最大值,MIN()最小值select Max(prod_price) as max_price from products; sum()总计select sum(quantity) as items_ordered from orderitems where order_num =20005; 分组数据select vend_id, count(*) as num_prods from products group by vend_id; 过滤分组having关键字select cust_id,count() as orders from orders group by cust_id having count() &gt;=2; select order_num, sum(quantityitem_price) as ordertotal from orderitems group by order_num having sum(quantityitem_price)&gt;=50; 与order by组合select order_num, sum(quantityitem_price) as ordertotal from orderitems group by order_num having sum(quantityitem_price)&gt;=50 order by ordertotal; 使用子查询select cust_id from orders where order_num in (select order_num from orderitems where prod_id = ‘TNT2’); 连结表联结join创建联结，规定要联结的所有表以及它们如何关联即可。select vend_name,prod_name,prod_price from vendors,products where vendors.vend_id = products.vend_id order by vend_name,prod_name; 没有联结条件的表关系返回的结果为笛卡尔积。select vend_name,prod_name,prod_price from vendors,products order by vend_name,prod_name; 联结多个表(联结越多，性能下降得越厉害）select prod_name,vend_name,prod_price,quantity from orderitems,products,vendors where products.vend_id = vendors.vend_id and orderitems.prod_id = products.prod_id and order_num = 20005; 高级联结使用别名select cust_name,cust_contact from customers as c,orders as o,orderitems as oi where c.cust_id = o.order_num and prod_id = ‘TNT2’; 自联结(使用了子查询）select prod_id,prod_name from products where vend_id = (select vend_id from products where prod_id = ‘DTNTR’); select p1.prod_id,p1.prod_name from products as p1, products as p2 where p1.vend_id = p2.vend_id and p2.prod_id = ‘DINTR’; 外部联结select customers.cust_id,orders.order_num from customers left outer join orders on customers.cust_id = orders.cust_id; select customers.cust_id,orders.order_num from customers right outer join orders on customers.cust_id = orders.cust_id; 带聚集函数的联结 select customers.cust_name,customers.cust_id,count(orders,order_num)As num_ord from customers inner join orders on customers.cust_id = orders.cust_id group by customers.cust_id; 组合查询union 全文本搜索ENGINE=MYISAM; 更新删除数据update customers set cust_email = ‘elmer@fudd.com’ where cust_id = 10005; delete from customers where cust_id = 10006; 删除所有行truncate table 添加列alter table vendors add vend_phone char(20) 删除刚刚添加的列alter table vendors drop column vend_phone; 重命名表rename table customers2 to customers; 使用存储过程DELIMITER//CREATE PROCEDURE productpricing()BEGIN select Avg(prod_price) as priceaverage from products END//DELIMITER;]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 集合类和 JUC集合类]]></title>
    <url>%2F2018%2F09%2F04%2FJava-%E9%9B%86%E5%90%88%E7%B1%BB%E5%92%8C-JUC%E9%9B%86%E5%90%88%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[Java集合包LIst的实现类主要有： LInkedList， ArrayList， Vetcor，Stack（Stack继承自Vector） LInkedList是双向链表的实现的双端队列，他不是线程安全的，只适用于单线程。 ArrayList是数组的实现的队列，它是一个动态数组，也不是线程安全的，只适用于单线程。 Vector是数组实现的矢量队列，他也是一个动态数组，不过和ArrayList不同的是，Vector是支持并发的。 Stack是Vector实现的栈，和Vector一样，他也是线程安全。 Set实现类： HashSet和TreeSet。 HashSet是一个没有重复元素的集合，它通过HashMap实现的，HashSet不是线程安全的。 TreeSet也是一个没有重复元素的集合，其中的元素是有序的，她是通过TreeMap实现的，TreeSet也不是线程安全的，只适用于单线程。 Map的实现类主要有 HashMap，WeakHashMap, Hashtable和TreeMap HashMap是存储“键-值对”的哈希表；它不是线程安全的，只适用于单线程。 WeakHashMap是也是哈希表；和HashMap不同的是，HashMap的“键”是强引用类型，而WeakHashMap的“键”是弱引用类型，也就是说当WeakHashMap 中的某个键不再正常使用时，会被从WeakHashMap中被自动移除。WeakHashMap也不是线程安全的，只适用于单线程。 Hashtable也是哈希表；和HashMap不同的是，Hashtable是线程安全的，支持并发。 TreeMap也是哈希表，不过TreeMap中的“键-值对”是有序的，它是通过R-B Tree(红黑树)实现的；TreeMap不是线程安全的，只适用于单线程。 为了方便，我们将前面介绍集合类统称为”java集合包“。java集合包大多是“非线程安全的”，虽然可以通过Collections工具类中的方法获取java集合包对应的同步类，但是这些同步类的并发效率并不是很高。为了更好的支持高并发任务，并发大师Doug Lea在JUC(java.util.concurrent)包中添加了java集合包中单线程类的对应的支持高并发的类。例如，ArrayList对应的高并发类是CopyOnWriteArrayList，HashMap对应的高并发类是ConcurrentHashMap，等等。 JUC包在添加”java集合包“对应的高并发类时，为了保持API接口的一致性，使用了”Java集合包“中的框架。例如，CopyOnWriteArrayList实现了“Java集合包”中的List接口，HashMap继承了“java集合包”中的AbstractMap类，等等。得益于“JUC包使用了Java集合包中的类”，如果我们了解了Java集合包中的类的思想之后，理解JUC包中的类也相对容易；理解时，最大的难点是，对JUC包是如何添加对“高并发”的支持的！ JUC的集合类List和SetJUC集合包中的List和Set实现类包括: CopyOnWriteArrayList, CopyOnWriteArraySet和ConcurrentSkipListSet。ConcurrentSkipListSet稍后在说明Map时再说明，CopyOnWriteArrayList 和 CopyOnWriteArraySet的框架如下图所示： CopyOrWriteArrayList相当于线程安全的ArrayList，它实现了List接口，CopyOnWriteArrayList是支持高并发的。 CopyOnWriteArraySet相当于线程安全的HashSet，它继承于AbstractSet类。CopyOnWriteArraySet内部包含一个CopyOnWriteArrayList对象，它是通过CopyOnWriteArrayList实现的。 MapJUC集合包中Map的实现类包括: ConcurrentHashMap和ConcurrentSkipListMap。它们的框架如下图所示： ConcurrentHashMap是线程安全的哈希表(相当于线程安全的HashMap)；它继承于AbstractMap类，并且实现ConcurrentMap接口。（jdk7以前用锁分段实现，jdk8用CAS无锁算法实现） ConcurrentSkipListMap是线程安全的有序的哈希表(相当于线程安全的TreeMap); 它继承于AbstractMap类，并且实现ConcurrentNavigableMap接口。ConcurrentSkipListMap是通过“跳表”来实现的，它支持并发。 ConcurrentSkipListSet是线程安全的有序的集合(相当于线程安全的TreeSet)；它继承于AbstractSet，并实现了NavigableSet接口。ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，它也支持并发。 QueueJUC集合包中Queue的实现类包括: ArrayBlockingQueue， LinkedBlockQueue，LinkedBlockDeque，ConcurrentQueue和ConcurrentDeque。 ArrayBlockingQueue是数组实现线程安全的有节的阻塞队列； LinkedBLockingQueue是单向链表实现的（指定大小）阻塞对列，该队列按FIFO排序元素 LinkedBlockingDeque是双向链表实现的(指定大小)双向并发阻塞队列，该阻塞队列同时支持FIFO和FILO两种操作方式。 ConcurrentLinkedQueue是单向链表实现的无界队列，该队列按 FIFO（先进先出）排序元素。 ConcurrentLinkedDeque是双向链表实现的无界队列，该队列同时支持FIFO和FILO两种操作方式。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet 基础学习]]></title>
    <url>%2F2018%2F08%2F31%2FServlet-%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一、WEB应用的发展1.规律 由单机程序向网络程序发展 由CS程序向BS程序发展 2.CS和BS的区别CS Client Server 客户端服务程序，客户端由程序员开发，用户需要安装（安全性高，但 BS Browser Server 浏览器服务程序，不需要单独开发及安装 二、 Servlet介绍1.服务器如何给浏览器返回网页？1）返回静态网页 百度百科、新闻等 内容不变，任何人看都一样 服务器保存的一个HTML，访问时直接返回它 2）返回动态网页 微博、淘宝 每个人看的内容有差别 服务器保存一个组件，用它来拼一个动态网页 在Java项目中，这个组件就是Servlet 组件：就是满足规范的对象 2.Servlet具备的特征 Servlet是存储在服务器上的 Servlet满足sun的规范 它可以拼动态资源（网页、图片等） 可以处理HTTP协议 3.什么是Servlet 是sun推出的用来在服务器端处理HTTP协议的组件 三、服务器1.名称 Java服务器 WEB服务器 Java WEB服务器 Servlet容器 2.本质 是一个软件：能够运行Java项目的软件 和浏览器相对应、平级 3.举例 Tomcat JBoss WebLogic WebSphere 四、如何使用tomcat1.单独使用1)配置JAVA_HOME tomcat依赖于Java 2)下载及安装 在apache官网下载 直接解压缩(释放)即可，这是绿色免安装软件 3)启动tomcat Linux：打开/tomcat/bin目录，输入./startup.sh window：打开/tomcat/bin目录，双击startup.bat 给目录加权限：chmod +x *sh 4)访问tomcat 打开浏览器，输入http://localhost:8080 5)关闭tomcat Linux：打开/tomcat/bin目录，输入./shutdown.sh windows：打开/tomcat/bin目录，双击shutdown.bat 2.用Eclipse管理tomcat(开发时) 配置失败需要重来： window-&gt;preference-&gt;server-&gt;runtime 选择tomcat点击remove Eclipse左侧点击Servers项目将其删除 五、Servlet开发步骤1.创建WEB项目 WEB项目有标准的WEB目录： webapp/WEB-INF/web.xml 2.导入jar包1)用maven搜javaee 在搜索结果中选择javaee-api.jar 2)使用tomcat内置的jar包 右键项目-&gt;properties-&gt;targeted runtimes-&gt;勾选tomcat-&gt;apply 3.开发Servlet 继承于HttpServlet 间接实现了Servlet接口(sun的规范) 4.配置Servlet 在web.xml中加以配置 5.部署项目 在Servers下点击tomcat 右键点击Add and Remove 弹出框中将项目从左侧移动到右侧 启动tomcat 部署：就是拷贝 6.访问Servlet http://localhost:8080/servlet1/ts 源代码： https://github.com/8311431967/practiceCode/tree/master/src/servlet/servlet 六、代码执行过程及错误 补充一、端口占用错误1.出现问题的情况 报错：Address already in user,JVM_BIND:8080 2.原因及解决方案1)tomcat启动了2次，造成端口冲突 打开/tomcat/bin目录，执行shutdown命令，强制关闭它 2)其他软件占用了此端口(Oracle) 修改tomcat的端口 打开tomcat配置文件server.xml 在65行修改port=”8080”，建议改为8088、8089等 注意：关闭tomcat时修改，然后重新启动 在Servers项目下可以找到server.xml配置文件 一、HTTP协议1.什么是HTTP协议 就是一个规范(w3c) 规定了：浏览器和服务器如何通信及数据格式 2.如何通信 建立连接 发送请求 接收响应 关闭连接 3.数据格式1)请求数据(浏览器向服务器发送的数据) 请求行：请求的基本信息 消息头：请求数据的描述信息 实体内容：请求的业务数据 2)响应数据(服务器向浏览器发送的数据) 状态行：响应的基本信息 消息头：响应数据的描述信息 实体内容：响应的业务数据 4.对开发的要求1)不需要管的地方 通信的过程已经由浏览器和服务器实现了 请求数据的组装由浏览器实现了 响应数据的组装由服务器实现了 2)需要处理的地方 请求的业务数据由开发者提供 响应的业务数据由开发者提供 使用request处理请求数据，使用response处理响应数据 二、注册案例源代码： https://github.com/8311431967/practiceCode/tree/master/src/servlet/servlet2 三、Servlet运行原理 四、请求方式1.什么是请求方式 浏览器向服务器发送数据的方式 包括很多种方式，需要掌握的是GET和POST 2.GET和POST方式的区别1)GET 采用路径传参，参数在传递过程中可见(地址栏) 隐私性差 传参能力有限，只能传少量参数 所有的请求默认都是GET请求 2)POST 采用实体内容传参，参数在传递过程中不可见 隐私性好 实体内容专门用来传参，大小不受限制 在form上加method=”post” a、get是用来从服务器上获取数据，而post是用来向服务器传递数据； b、get将表单中数据按照variable=value的形式，添加到action所指向的URL后面，并且两者用”？”连接，变量之间用”&amp;”连接；而post是将表单中的数据放在form的数据体中，按照变量与值对应的方式，传递到action所指定的URL。 c、get是不安全的，因为在传输过程中，数据是被放在请求的URL中;而post的所有操作对用户来说都是不可见的。 d、get传输的数据量小，这主要应为受url长度限制;而post可以传输大量的数据，所有上传文件只能用post提交。 e、get限制form表单的数据集必须为ASCII字符；而post支持整个IS01 0646字符集。 f、get是form表单的默认方法。 3.如何选择请求方式 一般查询时使用GET请求，因为查询条件一般比较少 一般保存时使用POST请求，因为保存的数据一般较多 五、乱码解决方案 六、案例1.查询员工源代码： https://github.com/8311431967/practiceCode/tree/master/src/servlet/EmpManager 2.增加员工 补充1.什么是JavaBean 满足如下规范的类： 有package 有默认构造器 实现序列化接口 有get/set方法 一、重定向1.重定向在增加员工中的应用1response.sendRedirect(String url); 2.重定向的作用及原理在重定向的过程中，影响浏览器做出动作的关键点即响应中的状态码及Location这个消息头。302状态就像一道命令一样，使得浏览器做出新的一次请求，而请求的地址会从头信息中查找。由于这个新的请求动作是由浏览器发出的，所以浏览器的地址栏上的地址会变成Location消息头中的地址。 二、路径1.路径是什么 2.如何获取路径 项目名：req.getContextPath() Servlet路径：req.getServletPath() 绝对路径：req.getRequestURI() 完整路径：req.getRequestURL() 3.URI(Uniform Resource Identifier)和URL(Uniform Resource Locator)的区别1)狭义的理解(Java项目) URI(统一资源标识符)是绝对路径，而URL是完整路径 URL(全球资源定位器)包含了URI 2)广义的理解(Web项目) * URI是资源的名字 URL是资源的真名 URI包含了URL 真名只有一个，名字可以有多个 4.Servlet访问路径的配置方案1)精确匹配(/hello) 只有这一个路径可以访问此Servlet 此Servlet只能处理一个请求 2)通配符(/*) 所有的路径都可以访问此Servlet 此Servlet能处理所有请求 3)后缀(*.abc) 所有以abc为后缀的路径都可以访问此Servlet 此Serlvet能处理多个请求 4)用1个Servlet处理多个请求的方案 5)通配符和后缀的典型应用场景 Servlet容器如何创建Servlet对象、如何为Servlet对象分配、准备资源、如何调用对应的方法来处理请求以及如何销毁Servlet对象的整个过程即Servlet的生命周期。 1.生命周期相关方法的调用顺序 ###阶段一、实例化123456789&lt;servlet&gt; &lt;servlet-name&gt;someServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;test/SomeServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;someServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 配置文件中的load-on-startup节点用于设置该Servlet的创建时机。当其中的值大于等于0时，表示容器在启动时就会创建实例小于0时或没有指定时，代表容器在该Servlet被请求时再执行创建正数的值越小，优先级越高，应用启动时就越先被创建。 ###阶段二、初始化 在初始化阶段，init（）方法会被调用。这个方法在javax.servlet.Servlet接口中定义。其中，方法以一个ServletConfig类型的对象作为参数。ServletConfig对象由Servlet引擎负责创建，从中可以读取到事先在web.xml文件中通过节点配置的多个name-value名值对。ServletConfig对象还可以让Servlet接受一个ServletContext对象。一般情况下，init方法不需要编写，因GenericServlet已经提供了init方法的实现，并且提供了getServletConfig方法来获得ServletConfig对象。注：init方法只被执行一次。 ###阶段三、就绪 Servlet被初始化以后就处于能够响应请求的就绪状态。每个对Servlet的请求由一个ServletRequest对象代表，Servlet给客户端的响应由一个ServletResponse对象代表。当客户端有一个请求时，容器就会将请求与响应对象转给Servlet，以参数的形式传给service方法。service方法由javax.servlet.Servlet定义，由具体的Servlet实现。 ###阶段四、销毁 Servlet容器在销毁Servlet对象时会调用destroy方法来释放资源。通常情况下Servlet容器停止或者重新启动都会引起销毁Servlet对象的动作，但除此之外，Servlet容器也有自身管理Servlet对象的准则，整个生命周期并不需要人为进行干预。 2.config和context的联系和区别 3.ServletConfig 4.ServletContext 一、context的特殊用法1.使用场景 之前使用config和context读取的都是web.xml中配置的常量 有时候我们需要存取的可能是变量 context支持存取变量，给多个Servlet共用 2.案例 给软件做一个统计流量(访问量)的功能 流量是一个变量，无论访问哪个Servlet，流量+1 二、线程安全问题1.什么时候会出现线程安全问题 多人同时修改同一份数据时有此问题 局部变量存储在栈里，每个线程有自己的栈帧，没有问题 成员变量存储在堆里，所有线程共享这个数据，可能有问题 多个人同时修改成员变量 2.如何解决线程安全问题 加锁 三、HttpServlet介绍(了解) sun这样设计是为了让开发者有更多选择的空间 制定的这种规范在实际使用中发现，并不会扩展为HTTP协议之外，所以有了过度设计的缺陷，也为在编写HTTP协议的Web应用时添加了一些不必要的操作。 四、JSPJSP（Java Server Page）是Sun公司制定的一种服务器端动态页面技术的组件规范，以“.jsp”为后缀的文件中既包含HTML静态标记用于表现页面，也包含特殊的代码，用于生成动态内容。JSP作为简化Servlet开发的一种技术，实质上最终依然要转变为Servlet才可能运行，只不过这个转变过程由Servlet容器来完成。所以遵循JSP的编写规范才能使得JSP转变为需要的Servlet。 JSP页面中的Java代码###JSP表达式（方便输出）1234&lt;%=3+5%&gt;&lt;%=add()%&gt;&lt;%=xx.getName()%&gt;&lt;%=xx.getName()+“abc”%&gt; 这种形式的Java代码在转译成Servlet时，会成为service（）方法中使用out.print语句的输出。1234out.print(3+5);out.print(add());out.print(xx.getName());out.print(xx.getName()+“abc”)); ###JSP小脚本（完成相对较长的逻辑运算）12345678910111213table&gt;&lt;%List&lt;User&gt; allUser = (List&lt;User&gt;)request.getAttribute(“users“);for(User u : allUser)&#123;%&gt; &lt;tr&gt; &lt;td&gt; &lt;%=u.getId()%&gt; &lt;/td&gt; &lt;td&gt; &lt;%=u.getName()%&gt; &lt;/td&gt; &lt;/tr&gt;&lt;% &#125;%&gt;&lt;/table&gt; 123456789101112public void service(…)&#123;out.write(“&lt;table&gt;”);List&lt;User&gt; allUser = (List&lt;User&gt;)request.getAttribute(“users“);for(User u : allUser)&#123;out.write(“&lt;tr&gt; &lt;td&gt;”);out.print(u.getId());out.write(“&lt;/td&gt;&lt;td&gt;”);out.print(u.getName());out.write(“&lt;/td&gt;&lt;/tr&gt;”); &#125; out.write(“&lt;/table&gt;”);&#125; ###JSP声明（添加属性或方法）12345&lt;%! public void fun()&#123; //… 方法体&#125;%&gt; 1234567public class XXX_JSP extends JSPBase&#123;public void fun()&#123; // … 方法体 &#125; public void service(… …)&#123;&#125;&#125; ###JSP指令 ####page指令 #####导包123&lt;%-- 导包 --%&gt;&lt;%@ page import=“java.util.*“%&gt;&lt;%@ page import=“java.util.*,java.sql.*“%&gt; #####设置response.setContentType（）方法的参数值12&lt;%-- 设置response.setConentType方法的参数值 --%&gt;&lt;%@ page contentType=“text/html;charset=utf-8“%&gt; #####设置容器读取该文件时的解码方法12&lt;%-- 设置容器读取该文件时的解码方式 --%&gt;&lt;%@ page pageEncoding=“UTF-8“%&gt; ####include指令1&lt;%@ include file=“header.html” %&gt; JSP运行原理 隐含(内置)对象什么是隐含对象 就是在JSP上可以直接使用的对象 这些对象是在service方法一开始就声明的 有哪些隐含对象1) request HttpServletRequest 2) response HttpServletResponse 3) out JSPWriter 等价于PrintWriter 4) config ServletConfig 5) application ServletContext 6) exception Throwable 是JSP生成的Servlet所报的错 7) session HttpSession 8) page Object 相当于this 9) pageContext PageContext 管理者，引用了其他8个隐含对象 总结 上述9个对象的名字是固定的 它们都可以在JSP上直接使用 使用的例子12&lt;%String user = request.getParameter(&quot;user&quot;);%&gt;&lt;%=request.getParameter(&quot;user&quot;)%&gt; 一、开发模式1. Model 1 使用一个组件(Servlet/JSP)处理请求 缺点：该组件将java和HTML高度耦合在一起 2. Model 2(MVC) 使用2个组件协同处理请求 优点：将java和HTML代码解耦 二、转发和重定向1.它们的相同点 都是用来解决web组件之间的跳转问题 web组件：Servlet/JSP 2.它们的区别 3.它们的一般使用场景 一般查询时从查询Servlet转发到查询JSP 一般增加、修改、删除(Servlet)后重定向到查询(Servlet) 三、EL和JSTL1.作用 2.案例 3.JSTL运行原理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对婚姻，楼市，资本，文化的一些看法]]></title>
    <url>%2F2018%2F08%2F04%2F%E5%AF%B9%E5%A9%9A%E5%A7%BB%EF%BC%8C%E6%A5%BC%E5%B8%82%EF%BC%8C%E8%B5%84%E6%9C%AC%EF%BC%8C%E6%96%87%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9C%8B%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言近日发生的事情比较多，接触的信息也比较杂乱，思考也比较频繁，决定写一下当下感触。 婚姻的变迁从古代的拜堂成亲到现代的一夫一妻，恋爱和婚姻像其他文化一样，都是被塑造出来的社会关系。而一夫一妻制从某种程度上，保证屌丝也能也有娶上老婆的机会，但随着工业化，科技现代化的推进，结婚也成了一个人的累赘。听起以前我妈那个年代，彩礼也只是一头猪，到现在的车，房子的首付，甚至是房子。 知乎上有个有趣的提问，为什么男人越来越不想结婚，有个高票回答。男人觉得结婚吃亏所以不想结婚，女人也觉得结婚吃亏不想结婚，说明结婚内耗太大。 虚高的房价恋爱和婚姻是被塑造出来的一种社会关系，在资本的眼里，，就只能被资本改造和裹挟，成了绑架大众的工具。 资本先利用舆论把房价炒上天，然后告诉我们，没房没资格结婚。依靠着大众对婚姻的向往，逼迫年轻人掏空父母，用六个钱包，来接盘虚高的房价。我姐今年买房，首付不够，到处借钱，已经不止是六个钱包了，挤入了婚姻的门槛，却又过上了省吃俭用的生活。 仍旧是将婚姻和家庭作为人质，依靠着大众对婚姻和家庭的责任，资本逼迫着大众接受996，繁重而苦役的劳作。最后，到35岁的时候，资本还会将这些失去剥夺价值的劳工扫地出门，近来连续跳楼的中年程序员，给我敲响了警钟，要给自己留后路。 有能力接盘的被收割，而没有能力接盘，同样无法逃脱。在资本主导的舆论下，他们（可能就是我）要一辈子在社会的歧视下单独过活。更糟糕的是，现实里并不是看穿这场阴谋和骗局就能解决问题，钻石的营销手段广为人知，各种金融骗局的手段，也被暴露在阳光下，但人们看到了问题所在，却被利益驱使，主动迎合骗局，自愿地参与了这样的狂欢。 社会关系和观念的改造一旦完成，人们自发的成了体制的一部分，自发的维护着这个体系。 资本改造过后的婚姻婚姻和爱情已经被改造，大面积的表现出对资本的崇拜，对消费的依赖，对成员的绑架和裹挟。没钱不配结婚，没钱不配生孩子，没钱不配有家庭。 社会关系带给人们的痛苦，最终会驱使人们放弃社会关系。 发达国家广泛的不婚不育，慢性自杀，是生命自发的反抗。 日本和韩国的不婚率和不育率将是我国的未来。 结语什么人才会发这样的牢骚呢，对，就是我这样的穷人。老家的今年房价由于碧桂园的强势介入，上限已经突破了8000元/平方米(垃圾五线城市），哥又买了房，又刚生了小孩，两个小孩，吃力。而听师兄说他们认识的几个技术大牛，都没能留在一线城市，去了二三线城市，玩技术的终究是玩不过玩资本的，我又何去何从,怀疑人生。8/4/2018 1:18:12 AM]]></content>
      <categories>
        <category>杂文</category>
      </categories>
      <tags>
        <tag>感触</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的反射]]></title>
    <url>%2F2018%2F05%2F24%2FJava%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[什么是反射反射是动态加载对象，并对对象进行剖析。在运行状态中，对于任意的一个类，都能够知道这个类的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法，这种动态获取信息以及动态调用对象方法的功能成为Java反射机制。 反射的基本操作获取类中的所有方法1234567891011121314151617181920212223242526272829303132public class Student &#123; private long id; private String name; public long getId() &#123; return id; &#125; public void setId(long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public static void main(String[] args) &#123; try &#123; Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;); Method[] methods = clz.getMethods(); for (Method method : methods) &#123; System.out.println(&quot;方法名：&quot; + method.getName()); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Class.forName(“reflect.Student”)：初始化指定的类 clz。getMethods():获取勒种所有的方法 如果只需要获取加载类中的方法，不要父类的方法，可以使用下面的代码： `Method[] methods = clz.getDeclaredMethods();` Method是方法类，可以获取方法相关的信息，除了我们上面的方法名称，我们还可以获取其他的一些信息，比如： 方法返回类型：method.getReturnType().getName() 方法修饰符：Modifier.toString(method.getModifiers()) 方法参数信息： method.getParameters() 方法上的注解： method.getAnnotations() 等等……. 通过反射来调用方法12345678910try &#123; Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;); Student stu = (Student) clz.newInstance(); System.out.println(stu.getName()); Method method = clz.getMethod(&quot;setName&quot;, String.class); method.invoke(stu, &quot;kun&quot;); System.out.println(stu.getName()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; 通过class的newInstance()方法构造一个Student对象，然后调用getName()方法，这个时候输出的是null,然后通过方法名获取到setName方法，通过invoke调用方法，传入参数，然后调用getName()方法可以看到输出的就是我们设置的值“kun”. 获取类中的所有属性12345Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;);Field[] fields = clz.getFields();for (Field field : fields) &#123; System.out.println(&quot;属性名：&quot; + field.getName());&#125; clz.getFields()只能获取public的属性，包括父类的。 如果需要获取自己声明的各种字段，包括public，protected，private得用clz.getDeclaredFields() Field是属性类，可以获取属性相关的信息，比如： 属性类型：field.getType().getName() 属性修饰符：Modifier.toString(field.getModifiers()) 属性上的注解： field.getAnnotations() 等等……. 通过clz.getDeclaredField(“name”);获取name属性，调用get方法获取属性的值，第一次肯定是没有值的，然后调用set方法设置值，最后再次获取就有值了，在get之前有field.setAccessible(true);这个代码，如果不加的话就会报下面的错误信息： &apos;Class fs.Test can not access a member of class fs.Student with modifiers &quot;private&quot; &apos; setAccessible(true);以取消Java的权限控制检查，让我们在用反射时可以访问访问私有变量 反射的优缺点优点 反射提高了程序的灵活性和扩展性,在底层框架中用的比较多，业务层面的开发过程中尽量少用。 缺点： 性能不好 反射是一种解释操作,用于字段和方法接入时要远慢于直接代码，下面通过2段简单的代码来比较下执行的时间就可以体现出性能的问题 直接创建对象，时间787ms#### 12345678long start = System.currentTimeMillis(); for (int i = 0; i &lt; 100000; i++) &#123; Student stu = new Student(); stu.setName(&quot;kun&quot;); System.out.println(stu.getName()); &#125; long end = System.currentTimeMillis(); System.out.println(end - start); 利用反射来实现上面的功能，时间在2982ms左右，我是在我本机测试的#### 1234567891011121314long start1 = System.currentTimeMillis(); for (int i = 0; i &lt; 100000; i++) &#123; try &#123; Class&lt;?&gt; clz = Class.forName(&quot;reflect.Student&quot;); Student stu = (Student) clz.newInstance(); Method method = clz.getMethod(&quot;setName&quot;, String.class); method.invoke(stu, &quot;kun&quot;); System.out.println(stu.getName()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; long end1 = System.currentTimeMillis(); System.out.println(end1 - start1); 反射的使用场景 实现RPC框架 实现ORM框架 拷贝属性值（BeanUtils.copyProperties） …… 就先这样，又空再看一下相关源码。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组中出现次数超过一半的数字]]></title>
    <url>%2F2018%2F05%2F12%2F%E6%95%B0%E7%BB%84%E4%B8%AD%E5%87%BA%E7%8E%B0%E6%AC%A1%E6%95%B0%E8%B6%85%E8%BF%87%E4%B8%80%E5%8D%8A%E7%9A%84%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[题意：现在有一数组存放int型整数，数字有重复，且有一数字出现的频率超过了50%，请找出这个数字。 乍一看，这是个水题，但如何提高查找性能也是很有意思的。 方法一将数组排序，然后中间的数一定是要求的。排序最小的时间复杂度（快速排序）O(NlogN)，加上遍历。不过Jvm的sort也是很快的。 1234public int MoreHalf_1(int[] nums) &#123; Arrays.sort(nums); return nums[nums.length/2]; &#125; 方法二用一个Map来存储，大于数组的一半就找到。这个方法的时间复杂度是O(N)，空间复杂度是O(n)。 123456789101112131415public int MoreHalf_2(int[] nums) &#123; HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); int i =0; for (;i &lt; nums.length; i++)&#123; if (map.containsKey(nums[i]))&#123; map.put(nums[i],map.get(nums[i])+1); if (map.get(nums[i]) &gt;=nums.length/2)&#123; break; &#125; &#125;else&#123; map.put(nums[i],1); &#125; &#125; return nums[i]; &#125; 方法三出现的次数超过数组长度的一半，表明这个数字出现的次数比其他数出现的次数的总和还多。 考虑每次删除两个不同的数，那么在剩下的数中，出现的次数仍然超过总数的一般，不断重复该过程，排除掉其他的数，最终找到那个出现次数超过一半的数字。这个方法的时间复杂度是O(N)，空间复杂度是O(1)。但删除开销大，可以用标记代替。 在遍历数组的过程中，保存两个值，一个是数组中数字，一个是出现次数。当遍历到下一个数字时，如果这个数字跟之前保存的数字相同，则次数加1，如果不同，则次数减1。如果次数为0，则保存下一个数字并把次数设置为1，由于我们要找的数字出现的次数比其他所有数字出现的次数之和还要多，那么要找的数字肯定是最后一次把次数设为1时对应的数字。 1234567891011121314151617181920212223242526public int MoreHalf_3(int[] nums) &#123; int result = 0; int count = 1; if (nums.length == 0) return -1; result = nums[0]; for (int i = 1 ; i &lt; nums.length; i++)&#123; if (count==0)&#123; result = nums[i]; count = 1; continue; &#125; if (nums[i]==result)&#123; count++; &#125;else &#123; count--; &#125; &#125; count = 0; for (int i = 1; i &lt; nums.length; i++) &#123; if(result == nums[i])count++; &#125; if(count &gt; nums.length/2) return result ; return 0; &#125; 方法四改进快排，利用Partition来确定index，然后mid比较，等于mid就找到了。（Partition确定的是index左边的数比nums[index]小，右边的数比nums[index]大） 12345678910111213141516171819202122232425262728293031323334353637public int MoreThanHalf_4(int[] nums)&#123; if(nums.length==0) return -1; int start = 0; int end = nums.length-1; int index = Partition(nums, start, end); int mid = nums.length/2; while(index!=mid)&#123; if(index&gt;mid) //如果调整数组以后获得的index大于middle，则继续调整start到index-1区段的数组 index = Partition(nums, start, index-1); else&#123; //否则调整index+1到end区段的数组 index = Partition(nums, index+1, end); &#125; &#125; return nums[index]; &#125; public int Partition(int[] nums,int start,int end)&#123; int pivotkey = nums[start]; int origin = start; while(start&lt;end)&#123; while(start&lt;end&amp;&amp;nums[end]&gt;=pivotkey) end--; while(start&lt;end&amp;&amp;nums[start]&lt;pivotkey) start++; swap(nums,start,end); &#125; swap(nums,start,end); swap(nums,origin,end); return end; &#125; public int[] swap(int[] ints, int x, int y) &#123; int temp = ints[x]; ints[x] = ints[y]; ints[y] = temp; return ints; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库的四大特性以及隔离级别]]></title>
    <url>%2F2018%2F05%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7%E4%BB%A5%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[今天有空来了解一下数据的事务四大特性，以及它的隔离级别。下周线代考试，明天再复习吧。 事务的四大特性原子性（Atomicity) 原子性是指事务包含的操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果失败则不能对数据库有任何影响。 一致性（Consisitency) 一致性是指必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说完一个事务行之前和执行之后都必须处于一致性状态。 一个比较好的例子就是转账，假设用户A和用户B两者的前加起来一共是10000，那不管A和B之间如何转账，转多少次账，事务结束后两个用户的钱相加还是10000，这就是事务的一致性。 隔离性（Isolation）隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作干扰，多个并发的事务之间要相互隔离。 即要达到一种效果，对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束了，要么在T1结束后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 持久性（Durability）持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 以上四大事务简称ACID 事务隔离级别Read uncommitted 读未提交 公司发工资了，领导把5000元打到singo的账号上，但是该事务并未提交，而singo正好去查看账户，发现工资已经到账，是5000元整，非常高兴。可是不幸的是，领导发现发给singo的工资金额不对，是2000元，于是迅速回滚了事务，修改金额后，将事务提交，最后singo实际的工资只有2000元，singo空欢喜一场。 出现上述情况，即我们所说的脏读，两个并发的事务，“事务A：领导给singo发工资”、“事务B：singo查询工资账户”，事务B读取了事务A尚未提交的数据。 当隔离级别设置为Read uncommitted时，就可能出现脏读，如何避免脏读，请看下一个隔离级别。 Read commited 读已提交 singo拿着工资卡去消费，系统读取到卡里确实有2000元，而此时她的老婆也正好在网上转账，把singo工资卡的2000元转到另一账户，并在singo之前提交了事务，当singo扣款时，系统检查到singo的工资卡已经没有钱，扣款失败，singo十分纳闷，明明卡里有钱，为何…… 出现上述情况，即我们所说的不可重复读，两个并发的事务，“事务A：singo消费”、“事务B：singo的老婆网上转账”，事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。 当隔离级别设置为Read committed时，避免了脏读，但是可能会造成不可重复读。 大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。如何解决不可重复读这一问题，请看下一个隔离级别。 Repeat read 重复读 当隔离级别设置为Repeatable read时，可以避免不可重复读。当singo拿着工资卡去消费时，一旦系统开始读取工资卡信息（即事务开始），singo的老婆就不可能对该记录进行修改，也就是singo的老婆不能在此时转账。 虽然Repeatable read避免了不可重复读，但还有可能出现幻读。 singo的老婆工作在银行部门，她时常通过银行内部系统查看singo的信用卡消费记录。有一天，她正在查询到singo当月信用卡的总消费金额（select sum(amount) from transaction where month = 本月）为80元，而singo此时正好在外面胡吃海塞后在收银台买单，消费1000元，即新增了一条1000元的消费记录（insert transaction … ），并提交了事务，随后singo的老婆将singo当月信用卡消费的明细打印到A4纸上，却发现消费总额为1080元，singo的老婆很诧异，以为出现了幻觉，幻读就这样产生了。 注：Mysql的默认隔离级别就是Repeatable read。 Serializable 序列化Serializable是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arrays.sort和Collections.sort实现原理探究]]></title>
    <url>%2F2018%2F05%2F04%2FArrays-sort%E5%92%8CCollections-sort%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[前言一直对Arrays.sort()和Collections.sort()的有什么区别好奇，有时间就对源码分析一下。 Arrays.sort()先看Arrays.sort()，一进去是这样的。果然没有那么简单，DualPivotQuicksort翻译过来就是双轴快速排序，关于双轴排序可以去这里http://www.cnblogs.com/nullzx/p/5880191.html 看看。那再次点进去，可以发现有这么一段代码 1234if (right - left &lt; QUICKSORT_THRESHOLD) &#123; sort(a, left, right, true); return;&#125; 可以发现如果数组的长度小于QUICKSORT_THRESHOLD的话就会使用这个双轴快速排序，而这个值是286。 那如果大于286呢，它就会坚持数组的连续升序和连续降序性好不好，如果好的话就用归并排序，不好的话就用快速排序，看下面这段注释就可以看出 The array is not highly structured, use Quicksort instead of merge sort. 那现在再回到上面的决定用双轴快速排序的方法上，再点进去，发现又会多一条判断 // Use insertion sort on tiny arraysif (length &lt; INSERTION_SORT_THRESHOLD) 所以总结一下Arrays.sort()方法，如果数组长度大于等于286且连续性好的话，就用归并排序，如果大于等于286且连续性不好的话就用双轴快速排序。如果长度小于286且大于等于47的话就用双轴快速排序，如果长度小于47的话就用插入排序。 Collections.sort() Collections.sort()底层调用的是array.sort(). 写个demo跟踪下 ** 123456789101112public class TestSort &#123; public static void main(String[] args) &#123; List&lt;String&gt; strings = Arrays.asList(&quot;6&quot;, &quot;1&quot;, &quot;3&quot;, &quot;1&quot;,&quot;2&quot;); Collections.sort(strings);//sort方法在这里 for (String string : strings) &#123; System.out.println(string); &#125; &#125;&#125; 然后发现Collections.sort()调用的是list.sort() 而在list.sort()中调用了Arrays.sort() 然后发现里面调用的Arrays.sort(a, c); a是list,c是一个比较器，我们来看一下这个方法 由网上查得，LegacyMergeSort是一个老的归并排序，不过不用管了现在默认是关的。 我们走的是sort(a)这个方法，接着进入这个 5.最后就是TimSort()的源码了 12345678910111213141516171819202122232425262728293031323334353637383940414243static void sort(Object[] a, int lo, int hi, Object[] work, int workBase, int workLen) &#123; assert a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // array的大小为0或者1就不用排了 // 当数组大小小于MIN_MERGE(32)的时候，就用一个&quot;mini-TimSort&quot;的方法排序，jdk1.7新加 if (nRemaining &lt; MIN_MERGE) &#123; //这个方法比较有意思，其实就是将我们最长的递减序列，找出来，然后倒过来 int initRunLen = countRunAndMakeAscending(a, lo, hi); //长度小于32的时候，是使用binarySort的 binarySort(a, lo, hi, lo + initRunLen); return; &#125; //先扫描一次array，找到已经排好的序列，然后再用刚才的mini-TimSort，然后合并，这就是TimSort的核心思想 ComparableTimSort ts = new ComparableTimSort(a, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1; &#125; TimSort的算法性能分析详见：https://blog.csdn.net/yangzhongblog/article/details/8184707]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Jdk源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合框架总结与分析(二)]]></title>
    <url>%2F2018%2F04%2F25%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E6%80%BB%E7%BB%93%E4%B8%8E%E5%88%86%E6%9E%90-%E4%BA%8C%2F</url>
    <content type="text"></content>
      <categories>
        <category>集合框架</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合框架总结与思考（一）]]></title>
    <url>%2F2018%2F04%2F24%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E6%80%BB%E7%BB%93%E4%B8%8E%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[前言对Java的集合框架用得比较频繁，但疏于总结，今天就从源码来分析一波。 集合框架（Collection Framework）首先要明确，集合代表了一组对象（和数组一样，但数组长度不能变，而集合能）。Java中的集合框架定义了一套规范，用来表示、操作集合，使具体操作与实现细节解耦。 先来整体来分析 简单说明 ： 集合接口：6个接口（短虚线表示），表示不同集合类型，是集合框架的基础。 抽象类：5个抽象类（长虚线表示），对集合接口的部分实现。可扩展为自定义集合类。 实现类：8个实现类（实线表示），对接口的具体实现。 Collection 接口是一组允许重复的对象。 Set 接口继承 Collection，集合元素不重复。 List 接口继承 Collection，允许重复，维护元素插入顺序。 Map接口是键－值对象，与Collection接口没有什么关系。 . Set 接口继承 Collection，集合元素不重复。 List 接口继承 Collection，允许重复，维护元素插入顺序。 Map接口是键－值对象，与Collection接口没有什么关系。 .Set、List和Map可以看做集合的三大类： List集合是有序集合，集合中的元素可以重复，访问集合中的元素可以根据元素的索引来访问。 Set集合是无序集合，集合中的元素不可以重复，访问集合中的元素只能根据元素本身来访问（也是集合里元素不允许重复的原因）。 Map集合中保存Key-value对形式的元素，访问时只能根据每项元素的key来访问其value。 两大基类Collection与Map在集合框架的类继承体系中，最顶层有两个接口 Collection表示一组纯数据 Map表示一组key-value对 一般继承自Collection或Map的集合类，会提供两个“标准”的构造函数 没有参数的构造函数，创建一个空的集合类 有一个类型与基类（Collection或Map）相同的构造函数，创建一个与给定参数具有相同元素的新集合类Collection 如上图所示，Collection类主要有三个接口： Set表示不允许有重复元素的集合（A collection that contains no duplicate elements） List表示允许有重复元素的集合（An ordered collection (also known as a sequence)） Queue JDK1.5新增，与上面两个集合类主要是的区分在于Queue主要用于存储数据，而不是处理数据。（A collection designed for holding elements prior to processing.） Map 接口说明Collection接口除了Map接口，其他集合都是Collection的子类，并且在我们的实际编程中，由于多态的原因，我们一般都会使用这个的编码方式，如：Inter i1 = new ImplementInter();(其中，Inter表示一个接口，ImplementInter表示对此接口的实现)，此时i1调用的方法只能是Inter接口中的方法，无法调用ImplementInter中新增的方法（除非进行向下类型转化）。所以，很有必要了解一下Collection根接口中都有哪些方法。 1234567891011121314151617181920212223242526272829303132333435363738394041public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; &#123; int size(); boolean isEmpty(); boolean contains(Object o); Iterator&lt;E&gt; iterator(); Object[] toArray(); &lt;T&gt; T[] toArray(T[] a); boolean add(E e); boolean remove(Object o); boolean containsAll(Collection&lt;?&gt; c); boolean addAll(Collection&lt;? extends E&gt; c); boolean removeAll(Collection&lt;?&gt; c); boolean retainAll(Collection&lt;?&gt; c); void clear(); boolean equals(Object o); int hashCode(); // jdk1.8添加的方法 default boolean removeIf(Predicate&lt;? super E&gt; filter) &#123; Objects.requireNonNull(filter); boolean removed = false; final Iterator&lt;E&gt; each = iterator(); while (each.hasNext()) &#123; if (filter.test(each.next())) &#123; each.remove(); removed = true; &#125; &#125; return removed; &#125; @Override default Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0); &#125; default Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false); &#125; default Stream&lt;E&gt; parallelStream() &#123; return StreamSupport.stream(spliterator(), true); &#125;&#125; 其中，有几个比较常用的方法，比如方法add()添加一个元素到集合中，addAll()将指定集合中的所有元素添加到集合中，contains()方法检测集合中是否包含指定的元素，toArray()方法返回一个表示集合的数组。 另外，Collection中有一个iterator()函数，它的作用是返回一个Iterator接口。通常，我们通过Iterator迭代器来遍历集合。ListIterator是List接口所特有的，在List接口中，通过ListIterator()返回一个ListIterator对象。 Collection接口有两个常用的子接口，下面详细介绍。 1.List接口 List集合代表一个有序集合，集合中每个元素都有其对应的顺序索引。List集合允许使用重复元素，可以通过索引来访问指定位置的集合元素。 List接口继承于Collection接口，它可以定义一个允许重复的有序集合。因为List中的元素是有序的，所以我们可以通过使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。 List接口为Collection直接接口。List所代表的是有序的Collection，即它用某种特定的插入顺序来维护元素顺序。用户可以对列表中每个元素的插入位置进行精确地控制，同时可以根据元素的整数索引（在列表中的位置）访问元素，并搜索列表中的元素。实现List接口的集合主要有：ArrayList、LinkedList、Vector、Stack。 （1）ArrayList ArrayList是一个动态数组，也是我们最常用的集合。它允许任何符合规则的元素插入甚至包括null。每一个ArrayList都有一个初始容量（10），该容量代表了数组的大小。随着容器中的元素不断增加，容器的大小也会随着增加。在每次向容器中增加元素的同时都会进行容量检查，当快溢出时，就会进行扩容操作。所以如果我们明确所插入元素的多少，最好指定一个初始容量值，避免过多的进行扩容操作而浪费时间、效率。 size、isEmpty、get、set、iterator 和 listIterator 操作都以固定时间运行。add 操作以分摊的固定时间运行，也就是说，添加 n 个元素需要 O(n) 时间（由于要考虑到扩容，所以这不只是添加元素会带来分摊固定时间开销那样简单）。 ArrayList擅长于随机访问。同时ArrayList是非同步的。 （2）LinkedList 同样实现List接口的LinkedList与ArrayList不同，ArrayList是一个动态数组，而LinkedList是一个双向链表。所以它除了有ArrayList的基本操作方法外还额外提供了get，remove，insert方法在LinkedList的首部或尾部。 由于实现的方式不同，LinkedList不能随机访问，它所有的操作都是要按照双重链表的需要执行。在列表中索引的操作将从开头或结尾遍历列表（从靠近指定索引的一端）。这样做的好处就是可以通过较低的代价在List中进行插入和删除操作。 与ArrayList一样，LinkedList也是非同步的。如果多个线程同时访问一个List，则必须自己实现访问同步。一种解决方法是在创建List时构造一个同步的List：List list = Collections.synchronizedList(new LinkedList(…)); （3）Vector 与ArrayList相似，但是Vector是同步的。所以说Vector是线程安全的动态数组。它的操作与ArrayList几乎一样。 （4）Stack Stack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。 2.Set接口 Set是一种不包括重复元素的Collection。它维持它自己的内部排序，所以随机访问没有任何意义。与List一样，它同样允许null的存在但是仅有一个。由于Set接口的特殊性，所有传入Set集合中的元素都必须不同，同时要注意任何可变对象，如果在对集合中元素进行操作时，导致e1.equals(e2)==true，则必定会产生某些问题。Set接口有三个具体实现类，分别是散列集HashSet、链式散列集LinkedHashSet和树形集TreeSet。 Set是一种不包含重复的元素的Collection，无序，即任意的两个元素e1和e2都有e1.equals(e2)=false，Set最多有一个null元素。需要注意的是:虽然Set中元素没有顺序，但是元素在set中的位置是由该元素的HashCode决定的，其具体位置其实是固定的。 此外需要说明一点，在set接口中的不重复是有特殊要求的。 举一个例子:对象A和对象B，本来是不同的两个对象，正常情况下它们是能够放入到Set里面的，但是如果对象A和B的都重写了hashcode和equals方法，并且重写后的hashcode和equals方法是相同的话。那么A和B是不能同时放入到Set集合中去的，也就是Set集合中的去重和hashcode与equals方法直接相关。 （1）HashSet HashSet 是一个没有重复元素的集合。它是由HashMap实现的，不保证元素的顺序(这里所说的没有顺序是指：元素插入的顺序与输出的顺序不一致)，而且HashSet允许使用null 元素。HashSet是非同步的，如果多个线程同时访问一个哈希set，而其中至少一个线程修改了该set，那么它必须保持外部同步。 HashSet按Hash算法来存储集合的元素，因此具有很好的存取和查找性能。 HashSet的实现方式大致如下，通过一个HashMap存储元素，元素是存放在HashMap的Key中，而Value统一使用一个Object对象。 HashSet使用和理解中容易出现的误区: a.HashSet中存放null值 HashSet中是允许存入null值的，但是在HashSet中仅仅能够存入一个null值。 b.HashSet中存储元素的位置是固定的 HashSet中存储的元素的是无序的，这个没什么好说的，但是由于HashSet底层是基于Hash算法实现的，使用了hashcode，所以HashSet中相应的元素的位置是固定的。 c.必须小心操作可变对象（Mutable Object）。如果一个Set中的可变元素改变了自身状态导致Object.equals(Object)=true将导致一些问题。 （2）LinkedHashSet LinkedHashSet继承自HashSet，其底层是基于LinkedHashMap来实现的，有序，非同步。LinkedHashSet集合同样是根据元素的hashCode值来决定元素的存储位置，但是它同时使用链表维护元素的次序。这样使得元素看起来像是以插入顺序保存的，也就是说，当遍历该集合时候，LinkedHashSet将会以元素的添加顺序访问集合的元素。 （3）TreeSet TreeSet是一个有序集合，其底层是基于TreeMap实现的，非线程安全。TreeSet可以确保集合元素处于排序状态。TreeSet支持两种排序方式，自然排序和定制排序，其中自然排序为默认的排序方式。当我们构造TreeSet时，若使用不带参数的构造函数，则TreeSet的使用自然比较器；若用户需要使用自定义的比较器，则需要使用带比较器的参数。 注意：TreeSet集合不是通过hashcode和equals函数来比较元素的.它是通过compare或者comparaeTo函数来判断元素是否相等.compare函数通过判断两个对象的id，相同的id判断为重复元素，不会被加入到集合中。 其中在jdk1.8后添加的方法对我们的分析不会产生影响，添加的方法有关键字default修饰，为缺省方法，是一个新特性。 对集合而言，都会包含添加、删除、判断、清空、大小等基本操作。 Map接口对于Map接口而言，是键值对集合，特别适用于那种情形，一个主属性，另外一个副属性（如：姓名，性别；kr,男），添加元素时，若存在相同的键，则会用新值代替旧值。方法如下 ： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188public interface Map&lt;K,V&gt; &#123; int size(); boolean isEmpty(); boolean containsKey(Object key); boolean containsValue(Object value); V get(Object key); V put(K key, V value); V remove(Object key); void putAll(Map&lt;? extends K, ? extends V&gt; m); void clear(); Set&lt;K&gt; keySet(); Collection&lt;V&gt; values(); Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); interface Entry&lt;K,V&gt; &#123; K getKey(); V getValue(); V setValue(V value); boolean equals(Object o); int hashCode(); // jdk1.8 后添加的方法 public static &lt;K extends Comparable&lt;? super K&gt;, V&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByKey() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getKey().compareTo(c2.getKey()); &#125; public static &lt;K, V extends Comparable&lt;? super V&gt;&gt; Comparator&lt;Map.Entry&lt;K,V&gt;&gt; comparingByValue() &#123; return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; c1.getValue().compareTo(c2.getValue()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByKey(Comparator&lt;? super K&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getKey(), c2.getKey()); &#125; public static &lt;K, V&gt; Comparator&lt;Map.Entry&lt;K, V&gt;&gt; comparingByValue(Comparator&lt;? super V&gt; cmp) &#123; Objects.requireNonNull(cmp); return (Comparator&lt;Map.Entry&lt;K, V&gt;&gt; &amp; Serializable) (c1, c2) -&gt; cmp.compare(c1.getValue(), c2.getValue()); &#125; &#125; boolean equals(Object o); int hashCode(); default V getOrDefault(Object key, V defaultValue) &#123; V v; return (((v = get(key)) != null) || containsKey(key))? v: defaultValue; &#125; default void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Objects.requireNonNull(action); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; action.accept(k, v); &#125; &#125; default void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Objects.requireNonNull(function); for (Map.Entry&lt;K, V&gt; entry : entrySet()) &#123; K k; V v; try &#123; k = entry.getKey(); v = entry.getValue(); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; // ise thrown from function is not a cme. v = function.apply(k, v); try &#123; entry.setValue(v); &#125; catch(IllegalStateException ise) &#123; // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); &#125; &#125; &#125; default V putIfAbsent(K key, V value) &#123; V v = get(key); if (v == null) &#123; v = put(key, value); &#125; return v; &#125; default boolean remove(Object key, Object value) &#123; Object curValue = get(key); if (!Objects.equals(curValue, value) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; remove(key); return true; &#125; default boolean replace(K key, V oldValue, V newValue) &#123; Object curValue = get(key); if (!Objects.equals(curValue, oldValue) || (curValue == null &amp;&amp; !containsKey(key))) &#123; return false; &#125; put(key, newValue); return true; &#125; default V replace(K key, V value) &#123; V curValue; if (((curValue = get(key)) != null) || containsKey(key)) &#123; curValue = put(key, value); &#125; return curValue; &#125; default V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) &#123; V newValue; if ((newValue = mappingFunction.apply(key)) != null) &#123; put(key, newValue); return newValue; &#125; &#125; return v; &#125; default V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue; if ((oldValue = get(key)) != null) &#123; V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) &#123; put(key, newValue); return newValue; &#125; else &#123; remove(key); return null; &#125; &#125; else &#123; return null; &#125; &#125; default V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); V oldValue = get(key); V newValue = remappingFunction.apply(key, oldValue); if (newValue == null) &#123; // delete mapping if (oldValue != null || containsKey(key)) &#123; // something to remove remove(key); return null; &#125; else &#123; // nothing to do. Leave things as they were. return null; &#125; &#125; else &#123; // add or replace old mapping put(key, newValue); return newValue; &#125; &#125; default V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) &#123; remove(key); &#125; else &#123; put(key, newValue); &#125; return newValue; &#125;&#125; 1.HashMap 以哈希表数据结构实现，查找对象时通过哈希函数计算其位置，它是为快速查询而设计的，其内部定义了一个hash表数组（Entry[] table），元素会通过哈希转换函数将元素的哈希地址转换成数组中存放的索引，如果有冲突，则使用散列链表的形式将所有相同哈希地址的元素串起来，可能通过查看HashMap.Entry的源码它是一个单链表结构。 2.LinkedHashMap LinkedHashMap是HashMap的一个子类，它保留插入的顺序，如果需要输出的顺序和输入时的相同，那么就选用LinkedHashMap。 LinkedHashMap是Map接口的哈希表和链接列表实现，具有可预知的迭代顺序。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 LinkedHashMap实现与HashMap的不同之处在于，后者维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。 根据链表中元素的顺序可以分为：按插入顺序的链表，和按访问顺序(调用get方法)的链表。默认是按插入顺序排序，如果指定按访问顺序排序，那么调用get方法后，会将这次访问的元素移至链表尾部，不断访问可以形成按访问顺序排序的链表。 注意，此实现不是同步的。如果多个线程同时访问链接的哈希映射，而其中至少一个线程从结构上修改了该映射，则它必须保持外部同步。 由于LinkedHashMap需要维护元素的插入顺序，因此性能略低于HashMap的性能，但在迭代访问Map里的全部元素时将有很好的性能，因为它以链表来维护内部顺序。 3.TreeMap TreeMap 是一个有序的key-value集合，非同步，基于红黑树（Red-Black tree）实现，每一个key-value节点作为红黑树的一个节点。TreeMap存储时会进行排序的，会根据key来对key-value键值对进行排序，其中排序方式也是分为两种，一种是自然排序，一种是定制排序，具体取决于使用的构造方法。 自然排序：TreeMap中所有的key必须实现Comparable接口，并且所有的key都应该是同一个类的对象，否则会报ClassCastException异常。 定制排序：定义TreeMap时，创建一个comparator对象，该对象对所有的treeMap中所有的key值进行排序，采用定制排序的时候不需要TreeMap中所有的key必须实现Comparable接口。 TreeMap判断两个元素相等的标准：两个key通过compareTo()方法返回0，则认为这两个key相等。 如果使用自定义的类来作为TreeMap中的key值，且想让TreeMap能够良好的工作，则必须重写自定义类中的equals()方法，TreeMap中判断相等的标准是：两个key通过equals()方法返回为true，并且通过compareTo()方法比较应该返回为0。 简单说明： Map接口有一个内部接口Entry,对集合中的元素定义了一组通用的操作，维护这键值对，可以对键值对进行相应的操作，通过Map接口的entrySet可以返回集合对象的视图集，方便对集合对象进行遍历等操作。 对Map而言，也会包含添加、删除、判断、清空、大小等基本操作。]]></content>
      <categories>
        <category>集合框架</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之decorator模式]]></title>
    <url>%2F2018%2F04%2F10%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8Bdecorator%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言如果把程序中的对象比作蛋糕，然后想不断地向装饰蛋糕一样地不断地对其增加功能，它就变成了使用目的更加明确的对象。像这种不断为对象添加装饰的设计模式称之为decorator模式。 示例UML图 代码在https://github.com/8311431967/practiceCode Display类abstract class Display &#123;123456789 public abstract int getColumns(); // 获取横向字符数 public abstract int getRows(); // 获取纵向行数 public abstract String getRowText(int row); // 获取第row行的字符串 public void show() &#123; // 全部显示 for (int i = 0; i &lt; getRows(); i++) &#123; System.out.println(getRowText(i)); &#125; &#125;&#125; StringDisplay类用于显示单行字符串的类，肩负着实现Display类中的声明的抽象方法的重任。其相当于生日蛋糕中的核心蛋糕。 class StringDisplay extends Display &#123;123456789101112131415161718 private String string; // 要显示的字符串 public StringDisplay(String string) &#123; // 通过参数传入要显示的字符串 this.string = string; &#125; public int getColumns() &#123; // 字符数 return string.getBytes().length; &#125; public int getRows() &#123; // 行数是1 return 1; &#125; public String getRowText(int row) &#123; // 仅当row为0时返回值 if (row == 0) &#123; return string; &#125; else &#123; return null; &#125; &#125;&#125; Border作为装饰边框的抽象类 abstract class Border extends Display &#123;12345 protected Display display; // 表示被装饰物 protected Border(Display display) &#123; // 在生成实例时通过参数指定被装饰物 this.display = display; &#125;&#125; SideBorder类在两侧在上”|” class SideBorder extends Border &#123;123456789101112131415 private char borderChar; // 表示装饰边框的字符 public SideBorder(Display display, char ch) &#123; // 通过构造函数指定Display和装饰边框字符 super(display); this.borderChar = ch; &#125; public int getColumns() &#123; // 字符数为字符串字符数加上两侧边框字符数 return 1 + display.getColumns() + 1; &#125; public int getRows() &#123; // 行数即被装饰物的行数 return display.getRows(); &#125; public String getRowText(int row) &#123; // 指定的那一行的字符串为被装饰物的字符串加上两侧的边框的字符 return borderChar + display.getRowText(row) + borderChar; &#125;&#125; FullBorder类添加上下左右边框 class FullBorder extends Border &#123;1234567891011121314151617181920212223242526 public FullBorder(Display display) &#123; super(display); &#125; public int getColumns() &#123; // 字符数为被装饰物的字符数加上两侧边框字符数 return 1 + display.getColumns() + 1; &#125; public int getRows() &#123; // 行数为被装饰物的行数加上上下边框的行数 return 1 + display.getRows() + 1; &#125; public String getRowText(int row) &#123; // 指定的那一行的字符串 if (row == 0) &#123; // 上边框 return &quot;+&quot; + makeLine(&apos;-&apos;, display.getColumns()) + &quot;+&quot;; &#125; else if (row == display.getRows() + 1) &#123; // 下边框 return &quot;+&quot; + makeLine(&apos;-&apos;, display.getColumns()) + &quot;+&quot;; &#125; else &#123; // 其他边框 return &quot;|&quot; + display.getRowText(row - 1) + &quot;|&quot;; &#125; &#125; private String makeLine(char ch, int count) &#123; // 生成一个重复count次字符ch的字符串 StringBuffer buf = new StringBuffer(); for (int i = 0; i &lt; count; i++) &#123; buf.append(ch); &#125; return buf.toString(); &#125;&#125; Main类class Main &#123;123456789101112131415161718192021222324 public static void main(String[] args) &#123; Display b1 = new StringDisplay(&quot;Hello, world.&quot;); Display b2 = new SideBorder(b1, &apos;#&apos;); Display b3 = new FullBorder(b2); b1.show(); b2.show(); b3.show(); Display b4 = new SideBorder( new FullBorder( new FullBorder( new SideBorder( new FullBorder( new StringDisplay(&quot;你好，世界。&quot;) ), &apos;*&apos; ) ) ), &apos;/&apos; ); b4.show(); &#125;&#125; 结果如下： 要点接口的透明性1.在decorator模式中，装饰边框和装饰物具有一致性，也就是说Border类（及其子类）与表示被装饰物的Display类具有相同的接口。这样即使被装饰物被边框装饰起来，接口API也不会被隐藏起来，其他类依然可以调用getColumn(),getRows(),show()方法，这就是API接口的“透明性”。 2.得益于接口的透明化，Decorator模式中形成了类似Composite模式中的递归结构，装饰边框里面的被装饰物实际上又是别的物体的“装饰边框”。 在不改变被装饰物的前提下增加功能虽然接口是相同的，但是越装饰，功能则越多，eg，用sideborder装饰display后，在字符串两侧可以加上装饰字符，也可在加上FullBorder。此时，我们完全不需要对被装饰的类做任何修改。 decorator模式中使用了委托，它使类之间形成弱关联关系，因此不必改变框架代码，就可以生成一个与其他对象具有不同关系的新对象。 Java.io包与Decorator模式首先如读取文件的示例：Reader reader = new FileReader(“datafile.txt”); 然后我们可以向下面这样在读取文件时将文件内容放入缓冲区中。 Reader reader = new BufferReader(new FileReader(“data.txt”)); 还可以Reader reader = new LineNumberReader(new BufferReader(new FileReader(“data.txt”))); 无论是LineNumReader类的构造函数还是BufferedReader类的构造函数，都可以接受Reader类（子类）的实例作为参数，因此我们可以像上面那样自由的进行各种自由组合。 缺点导致程序中增加许多功能类似的很小的类，Java.io包的类我就还没记完，orz。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>装饰模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之抽象工厂模式]]></title>
    <url>%2F2018%2F04%2F04%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[抽象工厂模式抽象工厂的工作就是将抽象零件组装为抽象产品，也就是我们并不关心零件的具体实现，而是只关心接口（API）。 示例抽象的零件：Item类abstract class Item &#123;123456 protected String caption; public Item(String caption) &#123; this.caption = caption; &#125; public abstract String makeHTML();//抽象方法由子类实现&#125; 抽象的零件：Link类abstract class Link extends Item &#123;123456 protected String url; public Link(String caption, String url) &#123; super(caption); this.url = url; &#125;&#125; 抽象的零件：Tray类abstract class Tray extends Item &#123;12345678 protected ArrayList tray = new ArrayList(); public Tray(String caption) &#123; super(caption); &#125; public void add(Item item) &#123; tray.add(item); &#125;&#125; 抽象的产品：Page类abstract class Page &#123;1234567891011121314151617181920212223 protected String title; protected String author; protected ArrayList content = new ArrayList(); public Page(String title, String author) &#123; this.title = title; this.author = author; &#125; public void add(Item item) &#123; content.add(item); &#125; public void output() &#123; try &#123; String filename = title + &quot;.html&quot;; Writer writer = new FileWriter(filename); writer.write(this.makeHTML()); writer.close(); System.out.println(filename + &quot; 编写完成。&quot;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public abstract String makeHTML();&#125; 抽象的工厂：Factory类getFactory()通过调用Class类的forName方法动态地读取类信息，接着用newInstance方法生成该类的实例，并将其作为返回值返回调用者。 请注意：虽然getFactory()方法生成的是具体工厂的实例，但是返回值是抽象工厂类型的。 abstract class Factory &#123;123456789101112131415 public static Factory getFactory(String classname) &#123; Factory factory = null; try &#123; factory = (Factory)Class.forName(classname).newInstance(); &#125; catch (ClassNotFoundException e) &#123; System.err.println(&quot;没有找到 &quot; + classname + &quot;类。&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return factory; &#125; public abstract Link createLink(String caption, String url); public abstract Tray createTray(String caption); public abstract Page createPage(String title, String author);&#125; 具体的工厂：ListFactory类class ListFactory extends Factory &#123;12345678910 public Link createLink(String caption, String url) &#123; return new ListLink(caption, url); &#125; public Tray createTray(String caption) &#123; return new ListTray(caption); &#125; public Page createPage(String title, String author) &#123; return new ListPage(title, author); &#125;&#125; 具体的零件：ListLink类class ListLink extends Link &#123;1234567 public ListLink(String caption, String url) &#123; super(caption, url); &#125; public String makeHTML() &#123; return &quot; &lt;li&gt;&lt;a href=\&quot;&quot; + url + &quot;\&quot;&gt;&quot; + caption + &quot;&lt;/a&gt;&lt;/li&gt;\n&quot;; &#125;&#125; 具体的零件：ListTray类划重点：通过使用迭代器，调用Item的makeHTML()，请注意，这里并不关心变量Item中保存的实例究竟是ListLink的实例还是ListTray的实例，只是简单的调用makeHTML(),之后item会帮我们处理，这是面向对象编程的好处。 class ListTray extends Tray &#123;123456789101112131415161718 public ListTray(String caption) &#123; super(caption); &#125; public String makeHTML() &#123; StringBuffer buffer = new StringBuffer(); buffer.append(&quot;&lt;li&gt;\n&quot;); buffer.append(caption + &quot;\n&quot;); buffer.append(&quot;&lt;ul&gt;\n&quot;); Iterator it = tray.iterator(); while (it.hasNext()) &#123; Item item = (Item)it.next(); buffer.append(item.makeHTML()); &#125; buffer.append(&quot;&lt;/ul&gt;\n&quot;); buffer.append(&quot;&lt;/li&gt;\n&quot;); return buffer.toString(); &#125;&#125; 具体的产品：ListPage类class ListPage extends Page &#123;1234567891011121314151617181920 public ListPage(String title, String author) &#123; super(title, author); &#125; public String makeHTML() &#123; StringBuffer buffer = new StringBuffer(); buffer.append(&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;&quot; + title + &quot;&lt;/title&gt;&lt;/head&gt;\n&quot;); buffer.append(&quot;&lt;body&gt;\n&quot;); buffer.append(&quot;&lt;h1&gt;&quot; + title + &quot;&lt;/h1&gt;\n&quot;); buffer.append(&quot;&lt;ul&gt;\n&quot;); Iterator it = content.iterator(); while (it.hasNext()) &#123; Item item = (Item)it.next(); buffer.append(item.makeHTML()); &#125; buffer.append(&quot;&lt;/ul&gt;\n&quot;); buffer.append(&quot;&lt;hr&gt;&lt;address&gt;&quot; + author + &quot;&lt;/address&gt;&quot;); buffer.append(&quot;&lt;/body&gt;&lt;/html&gt;\n&quot;); return buffer.toString(); &#125;&#125; 使用工厂将零件组装成为产品：Main类该类只是引入了factory包，并没有使用任何具体的零件，产品和工厂 class Main &#123;12345678910111213141516171819202122232425262728293031323334353637 public static void main(String[] args) &#123; if (args.length != 1) &#123; System.out.println(&quot;Usage: java Main class.name.of.ConcreteFactory&quot;); System.out.println(&quot;Example 1: java Main listfactory.ListFactory&quot;); System.out.println(&quot;Example 2: java Main tablefactory.TableFactory&quot;); System.exit(0); &#125; // Factory factory = Factory.getFactory(&quot;abstractFactory.listfactory.ListFactory&quot;); Factory factory = Factory.getFactory(args[0]); Link people = factory.createLink(&quot;People Daily&quot;, &quot;http://www.people.com.cn/&quot;); Link gmw = factory.createLink(&quot;GuangMing Daily&quot;, &quot;http://www.gmw.cn/&quot;); Link us_yahoo = factory.createLink(&quot;Yahoo!&quot;, &quot;http://www.yahoo.com/&quot;); Link jp_yahoo = factory.createLink(&quot;Yahoo!Japan&quot;, &quot;http://www.yahoo.co.jp/&quot;); Link excite = factory.createLink(&quot;Excite&quot;, &quot;http://www.excite.com/&quot;); Link google = factory.createLink(&quot;Google&quot;, &quot;http://www.google.com/&quot;); Tray traynews = factory.createTray(&quot;NewsPaper&quot;); traynews.add(people); traynews.add(gmw); Tray trayyahoo = factory.createTray(&quot;Yahoo!&quot;); trayyahoo.add(us_yahoo); trayyahoo.add(jp_yahoo); Tray traysearch = factory.createTray(&quot;searchEngine&quot;); traysearch.add(trayyahoo); traysearch.add(excite); traysearch.add(google); Page page = factory.createPage(&quot;LinkPage&quot;, &quot;kr&quot;); page.add(traynews); page.add(traysearch); page.output(); &#125;&#125; 抽象工厂的优劣点####易于增加具体的工厂 这里说的容易是指需要编写哪些类和需要实现哪些方法都非常清楚。假设我们要在示例中增加新的具体工厂，那么需要做的就是编写Factory，Link，Tray，Page这四个类的子类，并实现他们定义的抽象方法。这样一来，无论要增加多少个具体工厂（或者是修改具体工厂的BUG），都无需修改抽象工厂。 ####难于增加新的零件 如果要增加新的零件时，就必须要对所有的具体工厂进行相应的修改。例如要在factory包中增加一个表示图像的Picture零件，就要在listfactory中作如下修改： 在ListFactory中加入createPicture； 新增ListPicture类 而且编写完成的具体工厂越多，修改的工作量越多。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式 抽象工厂</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对抖音和快手的体验与分析]]></title>
    <url>%2F2018%2F04%2F02%2F%E5%AF%B9%E6%8A%96%E9%9F%B3%E5%92%8C%E5%BF%AB%E6%89%8B%E7%9A%84%E4%BD%93%E9%AA%8C%E4%B8%8E%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[序言虽然以前就听过快手和抖音了，但好似对我的作用不大，就一直没有上手。But，快手和抖音都在2018的春节期间大放异彩，逐步占领市场。还有看到了中央颁布的互联网独角兽公司，我惊奇地发现快手竟然排到了61，而抖音也是有前一百的，被学生党喜闻乐见的知乎排在了110+。果然人民群众相对于.txt,.jpg,更喜欢*.avi啊。所以决定下载抖音和快手，来体验一下，顺便来为我拓宽一下设计思路。 界面和交互设计抖音的界面初始只有一个视频，不用点击就自动播放，双击点赞，上下滑下一个视频，很简单方便，但可选率低。而快手初始界面四张图片，需要点击进去才能播放，下滑可以看更多的缩略图。抖音的设计必须依靠强大的推荐系统，不然滑了几个视频都是不好看的就gg了。 推荐系统和算法毕竟一开始还是要给三无用户作推荐，大概是推荐点赞比较多的和关注度比较高的大v吧。而抖音请了明星入驻，一点开的都是明星的视频，而快手更多的是妹纸的，不过标题真的太太太尴尬了。那么如何给新用户增加曝光机会呢？ 在视频推荐中会穿插一些新用户的视频，我的观察大概是10条有1条。这样保证了在用户不会觉得烦的同时，也给了新的创作者一定流量。当新的视频达到一定的赞后，可能会被推送更多用户，而没有达到某个标准的视频可能会“进入冷宫“。这样的设计防止了像微博这类网站的大V把持流量所造成的马太效应，越来越多的平台在采取相同的策略 这样就能吸引新用户，增加优质资源的同时防止大v的流量劫持。 内容抖音的内容还算是积极向上，明星们都比较接地气，而且配上特定的BGM真的很魔性，还有一些人拍的情景剧，也就十秒左右，后来发现还是续集来的，orz。 而快手的内容就比较接地气，或者是少部分人说的俗，视频里主要是妹子跳舞，泳装…..还有农村里面的奇人异事，工厂妹的一天之类的。我觉得快手是切入点很准，面向二线三线四线的人，得屌丝者得天下啊。 不过上一次的十四岁怀孕少女的视频引起了人们的关注，进而对快手的鄙视，我还在live中发现了色情引流，虽然说可以举报，但管理员根本忙不过来啊。 监管这一方面还要加强吧，感觉要变成直播软件了。共青团入驻快手和抖音，我还特意搜了账号看作品，作品量低啊。 推荐广告这种流量软件当然少不了广告的，不然怎生存，穿插于视频中，用户不仔细看可能就已经当成一个普通视频看完了。我刚注册，广告遇见率不高，可能还是杀熟吧。再者听说抖音和快手的广告费是比知乎高几倍的，果然还是学生党比屌丝更穷啊。 结语抖音和快手的界面和交互设计都做得很好，也很快（只是我的辣鸡校园网不给力），智能推荐也很好，但过于沉溺于某个方面就会错过外面精彩的世界。就好像快手现在就只推荐都是妹纸的视频给我了，明明我本意是用快手和抖音记单词的。我觉得俗或不俗都是人民群众说了算，快手和抖音都是一个成功的app，既满足了人民的需求也从中捞到了利益。]]></content>
      <categories>
        <category>杂文</category>
      </categories>
      <tags>
        <tag>杂文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之Iterator模式]]></title>
    <url>%2F2018%2F04%2F02%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BIterator%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Iterator模式刚看完23种设计模式，就先来总结一下Iterator模式。重点是掌握使用抽象类和接口来编程。先来回忆一下这个例子： 定义Aggregate接口（集合）interface Aggregate &#123;12 public abstract Iterator iterator();&#125; 定义Iterator接口（迭代器）interface Iterator &#123;123public abstract boolean hasNext();public abstract Object next();&#125; 定义Book类class Book &#123;12345678private String name;public Book(String name) &#123; this.name = name;&#125;public String getName() &#123; return name;&#125;&#125; 定义BookSelf类（具体的集合）class BookShelf implements Aggregate &#123;1234567891011121314151617private ArrayList books; public BookShelf(int initialsize) &#123; this.books = new ArrayList(initialsize); &#125; public Book getBookAt(int index) &#123; return (Book)books.get(index); &#125;public void appendBook(Book book) &#123; books.add(book); &#125;public int getLength() &#123; return books.size(); &#125;public Iterator iterator() &#123; return new BookShelfIterator(this);&#125;&#125; 这里用了ArrayList来实现动态数组，避免当书本过多时而受到限制，有时间在分析ArrayList的源码 定义BookShelfIterator（具体的迭代器）class BookShelfIterator implements Iterator &#123;12345678910111213141516171819private BookShelf bookShelf;private int index;public BookShelfIterator(BookShelf bookShelf) &#123; this.bookShelf = bookShelf; this.index = 0;&#125;public boolean hasNext() &#123; if (index &lt; bookShelf.getLength()) &#123; return true; &#125; else &#123; return false; &#125;&#125;public Object next() &#123; Book book = bookShelf.getBookAt(index); index++; return book;&#125;&#125; 因为BookShelfIterator类要发挥Iterator的作用，so实现了Iterator的接口 UML图如下： 使用Iterator的作用引入Iterator模式后把遍历和实现分离开来，如下 (it.hasNext()) &#123;123 Book book = (Book)it.next(); System.out.println(book.getName());&#125; 这里只使用了Iterator的next和hasNext，并没有调用Bookshelf的方法，也就是说，这里的while循环并不依赖Bookshelf的实现。 如果Bookshelf的开发人员放弃ArrayList来管理书本，而是用vector来取而代之，不管Bookshelf如何变化，只要Bookshelf的iterator方法能够正确返回Iterator的实例，即使不对while的循环作任何修改，代码都可以正常工作。 如果只使用具体的类来解决问题，很容易导致类之间的强耦合，这些类也难以作为组件被再次利用。为了弱化类之间的耦合，进而使得类更加容易作为组件被再次利用，我们需要引入抽象类和接口。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫分析微信好友]]></title>
    <url>%2F2017%2F12%2F10%2Findex%2F</url>
    <content type="text"><![CDATA[昨晚了解到Python的itchat包，很强，已经完成了wechat的个人账号API接口，就可以用他来做很多数据分析的有趣事情了。首先引入各个包 itchat # itchat documentation -- https:/ itchat.readthedocs.io/zh/latest/api/1234567891011import matplotlib.pyplot as pltimport seaborn as snsimport numpy as npimport pandas as pdimport refrom wordcloud import WordCloud, ImageColorGeneratorimport PIL.Image as Image # pillowimport jieba # chinese word segementation toolfrom matplotlib.font_manager import FontProperties# since matplotlib and pandas.plot cannot display chinesefont = FontProperties(fname=&apos;./data/test.ttf&apos;, size=14) # load chinese font 引入包时遇到很多麻烦，首先很多包不支持3.7，然后我又下了个3.6的，应该把2.7的也下载，Python的版本啊~~~~ 我一般直接用Pycharm的直接下载，但到了wordcloud却不支持了，经过我不懈的查找，踩了很多坑，在stackOverflow查到了 download wordcloud‑1.3.2‑cp36‑cp36m‑win_amd64.whl from http://www.lfd.uci.edu/~gohlke/pythonlibs/#wordcloud Copy the file to your current working directory Open command prompt from Tools python -m pip install wordcloud-1.3.2-cp36-cp36m-win_amd64.whl 然后登陆网页版微信获取好友数据#login, default a QR code will be generated, scan for login itchat.login() friends = itchat.get_friends(update=True)[0:] # get all friends print(friends[0]) # the first one is yourself 扫描二维码来登陆即可对我好友的男女比例进行统计`male, female, others = get_male_female_count(friends[1:]) total = len(friends[1:]) print(&apos;Male population: {:d}, ratio: {:.4f}&apos;.format(male, male / float(total))) print(&apos;Female population: {:d}, ratio: {:.4f}&apos;.format(female, female / float(total))) print(&apos;Others: {:d}, ratio: {:.4f}&apos;.format(others, others / float(total)))` 函数： `def get_male_female_count(friends): male = 0 female = 0 others = 0 for friend in friends: sex = friend[&apos;Sex&apos;] if sex == 1: male += 1 elif sex == 2: female += 1 else: others += 1 return male, female, others` 用PIL画图 `# plot male-female-ratio index = np.arange(3) genders = (male, female, others) bar_width = 0.35 plt.figure(figsize=(14, 7)) plt.bar(index, genders, bar_width, alpha=0.6, color=&apos;rgb&apos;) plt.xlabel(&apos;Gender&apos;, fontsize=16) plt.ylabel(&apos;Population&apos;, fontsize=16) plt.title(&apos;Male-Female Population&apos;, fontsize=18) plt.xticks(index, (&apos;Male&apos;, &apos;Female&apos;, &apos;Others&apos;), fontsize=14, rotation=20) plt.ylim(0, 220) for idx, gender in zip(index, genders): plt.text(idx, gender + 0.1, &apos;%.0f&apos; % gender, ha=&apos;center&apos;, va=&apos;bottom&apos;, fontsize=14, color=&apos;black&apos;) plt.show()` 结果嘛为什么这么少呢，哦，好像前阵子删除了很多无联系的账号，重点是比例，ozx。 对好友城市的分布也做了分析`# extract the variables: NickName, Sex, City, Province, Signature def get_features(friends): features = [] for friend in friends: feature = {&apos;NickName&apos;: friend[&apos;NickName&apos;], &apos;Sex&apos;: friend[&apos;Sex&apos;], &apos;City&apos;: friend[&apos;City&apos;], &apos;Province&apos;: friend[&apos;Province&apos;], &apos;Signature&apos;: friend[&apos;Signature&apos;]} features.append(feature) return pd.DataFrame(features) features = get_features(friends[1:]) print(features.columns) features.head() locations = features.loc[:, [&apos;Province&apos;, &apos;City&apos;]] # get location columns locations = locations[locations[&apos;Province&apos;] != &apos;&apos;] # clean empty city or province records data = locations.groupby([&apos;Province&apos;, &apos;City&apos;]).size().unstack() # group by and count count_subset = data.take(data.sum(1).argsort())[-20:] # obtain the 20 highest data # plot subset_plot = count_subset.plot(kind=&apos;bar&apos;, stacked=True, figsize=(24, 24))` 结果都是广东的多，其他的几乎没有。 将好友的个性签名用wordcloud生成词云` set fonts xtick_labels = subset_plot.get_xticklabels() for label in xtick_labels: label.set_fontproperties(font) legend_labels = subset_plot.legend().texts for label in legend_labels: label.set_fontproperties(font) label.set_fontsize(10) plt.xlabel(&apos;Province&apos;, fontsize=20) plt.ylabel(&apos;Number&apos;, fontsize=20) plt.show() sigature_list = [] for signature in features[&apos;Signature&apos;]: signature = signature.strip().replace(&apos;span&apos;, &apos;&apos;).replace(&apos;class&apos;, &apos;&apos;).replace(&apos;emoji&apos;, &apos;&apos;) # re.compile(ur&apos;[^a-zA-Z0-9\u4e00-\u9fa5 ]&apos;).sub(&apos;&apos;, signature) signature = re.compile(&apos;1f\d+\w*|[&lt;&gt;/=]&apos;).sub(&apos;&apos;, signature) if (len(signature) &gt; 0): sigature_list.append(signature) text = &apos;&apos;.join(sigature_list) # print(text) word_list = jieba.cut(text, cut_all=True) words = &apos; &apos;.join(word_list) # print(words) coloring = np.array(Image.open(&apos;./data/wechat3.png&apos;)) wc = WordCloud(background_color=&apos;white&apos;, max_words=2000, mask=coloring, max_font_size=60, random_state=42, font_path=&apos;./data/test.ttf&apos;, scale=2).generate(words) image_color = ImageColorGenerator(coloring) plt.figure(figsize=(32, 16)) plt.imshow(wc.recolor(color_func=image_color)) plt.imshow(wc) plt.axis(&apos;off&apos;) plt.show()` 结果啊 我的好友还是很积极向上的，学习奋斗和努力还是有一定比例的，喜欢也可以理解，但为何生活人生世界这么大比例，ozx，这么多人看破尘世了？还是鸡汤看多了。 参考 https://github.com/amueller/word_cloud https://github.com/littlecodersh/ItChat http://www.36dsj.com/archives/88199 https://isaacchanghau.github.io/2017/09/10/Python-itchat%E5%8C%85%E5%88%86%E6%9E%90%E5%BE%AE%E4%BF%A1%E6%9C%8B%E5%8F%8B/]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[热度榜]]></title>
    <url>%2F2017%2F12%2F10%2Fpage%2F</url>
    <content type="text"><![CDATA[AV.initialize("", "");热度排行Top： var time=0 var title="" var url="" var query = new AV.Query('Counter');//表名 query.notEqualTo('id',0); //id不为0的结果 query.descending('time'); //结果按阅读次数降序排序 query.limit(20); //最终只返回10条结果 query.find().then(function (todo) { for (var i=0;i]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F12%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[优秀的人，不是不合群，而是他们合群的人里面没有你Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 最近访客]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>杂文</tag>
      </tags>
  </entry>
</search>
